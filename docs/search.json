[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The statistics of online experiments",
    "section": "",
    "text": "Introduction\nOnline experiments are widely used for product development in the tech industry.\nAs a result, a large literaure on best-prectices and increasingly advancede methods has developed over the past 20 years. Furthermore, there is now also a thriving small community of practitioners who discuss new ideas on LinkedIn. Finally, there is a number of textbooks, both online (here, here) and in print, as well as class notes that cover aspects of the statistical foundations in depth.\nThe aim of these notes is twofold: to cover the statistical foundations of online experiments without any shortcuts – including step-by-step proofs of the key results, and to cover that content as concisely as possible. Apart from the line-by-line proofs little of the content here is new. But the resources mentioned above don’t usually cover all the same content in on place and often provide abbreviated profs and have more elaborate discussions.\nI created them mailnly for personal reference because I forget stuff. But if you find the notes helpful, find any errors, or have any suggestions, please get in touch by writing to fa.gunzinger@gmail.com.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/stats_of_online_experiments.html",
    "href": "chapters/stats_of_online_experiments.html",
    "title": "4  The stats of online experiments",
    "section": "",
    "text": "4.1 Setup\nWe study a sample of \\(n\\) units, indexed by \\(i = 1, \\dots, n\\), to learn about the effect of a binary treatment on these units.1 The sample of units might be all visitors to an e-commerce app and the treatment a new UX feature. The treatment is “binary” because we only consider two treatment conditions: a unit either experiences the active treatment and is exposed to the new feature or experiences the control treatment and is exposed to the status-quo. We often refer to the two treatment conditions simply as “treatment” and “control”.\nEach unit has two potential outcomes: \\(Y_i(1)\\) is the outcome for unit \\(i\\) if they are in treatment and \\(Y_i(0)\\) is the outcome if they are in control. To simplify notation, we collect all unit-level potential outcomes in the \\(n \\times 1\\) vectors \\(\\mathbf{Y(1)}\\) and \\(\\mathbf{Y(0)}\\). These outcomes are “potential outcomes” because before the start of the experiment, each unit could be exposed to either treatment condition so that they can potentially experience either outcome. Once the experiment has started and units are assigned to treatment, only one of the two outcomes will be observed.\nThe causal effect of the treatment for unit \\(i\\) is the difference between the two potential outcomes:2\n\\[\n\\tau_i = Y_i(1) - Y_i(0).\n\\]\nBecause a unit can only ever be in either treatment or control, we can only ever observe one of the two potential outcomes, which means that directly observing unit-level treatment effects is impossible. This is the fundamental problem of causal inference (Holland 1986).\nAn experiment is one solution to the fundamental problem:3 randomly assigning units from a population to either treatment or control allows us to estimate average (unit-level) treatment effects. In the words of Holland (1986, 947):4\nHence, instead of trying to observe unit-level causal effects, the quantity of interest – the estimand – in an experiment is an average across a sample of units. We are usually interested in the effect of a universal policy, a comparison between a state of the world where everyone is exposed to the treatment and one where nobody is. While we can capture the difference between these two states of the world in many different ways, we typically focus on the difference in the averages of all these unit-level causal effects over the entire sample:\n\\[\n\\begin{align}\n\\tau\n= \\frac{1}{n}\\sum_{i=1}^n \\left(Y_i(1) - Y_i(0)\\right)\n= \\frac{1}{n}\\sum_{i=1}^n Y_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0).\n\\end{align}\n\\tag{4.1}\\]\nThis is the estimand, the statistical quantity we are trying to estimate in our experiment.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The stats of online experiments</span>"
    ]
  },
  {
    "objectID": "chapters/stats_of_online_experiments.html#setup",
    "href": "chapters/stats_of_online_experiments.html#setup",
    "title": "4  The stats of online experiments",
    "section": "",
    "text": "“The important point is that [an experiment] replaces the impossible-to-observe causal effect of [a treatment] on a specific unit with the possible-to-estimate average causal effect of [the treatment] over a population of units.”",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The stats of online experiments</span>"
    ]
  },
  {
    "objectID": "chapters/stats_of_online_experiments.html#assignment-mechanism",
    "href": "chapters/stats_of_online_experiments.html#assignment-mechanism",
    "title": "2  The stats of online experiments",
    "section": "2.3 Assignment mechanism",
    "text": "2.3 Assignment mechanism\nThe procedure we use the allocate units to treatment conditions is the assignment mechanism. In online experiments, we typically assign units to treatment conditions dynamically as they visit our site and use an assignment mechanism where the assignment of each unit is determined by a process that is equivalent to a coin-toss, such that \\(P(W_i) = q\\), where \\(q \\in [0, 1]\\). Throughout, I’ll focus on the most common case where \\(q=\\frac{1}{2}\\), so that we have:\n\\[\nP(W_i = 1) = P(W_i = 0) = \\frac{1}{2}.\n\\]\nBecause of their coin-toss-like nature assignments follow a Bernoulli distribution and the type of experiment is called a Bernoulli Randomised Experiment. Formally, we have:\n\\[\n\\begin{align}\nW_i &\\sim \\text{Bernoulli}(1/2) \\\\\n\\mathbb{E}[{W_i}] &= 1/2 \\\\\n\\end{align}\n\\]\nand\n\\[\n\\begin{align}\nn_t &\\sim \\text{Binomial}(n, 1/2) \\\\\n\\mathbb{E}[{n_t}] &= n(1/2).\n\\end{align}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The stats of online experiments</span>"
    ]
  },
  {
    "objectID": "chapters/stats_of_online_experiments.html#analysis",
    "href": "chapters/stats_of_online_experiments.html#analysis",
    "title": "2  The stats of online experiments",
    "section": "2.3 Analysis",
    "text": "2.3 Analysis\nThere are different approaches we could take to formally analyse our experiment.\nDecisions:\n\nWe could either take a superpopulation or fixed sample perspective. Because for all but the largest companies, most online experiments are eventually run on the entire population of interest, I focus on the latter. This means that the goal of our experiment is to estimate the average treatment effect of the treatment on our \\(n\\) units, rather than using the estimate for our \\(n\\) units to infer the average treatment effect on a larger population from which the \\(n\\) units are drawn. I thus use a fully design-based approach (see Chapter 6 for details)\nWe can analyse the Bernoulli Randomised Experiment treating \\(n_t\\) as a Binomial random variable or taking it as given. Because by the time of the analysis it is, in fact, given, I follow the latter approach. This approach also has the advantage of considerably simplifying the math.\n\nImplications:\n\nOur sample of \\(n\\) units and the associated potential outcomes \\(\\mathbf{Y(1)}\\) and \\(\\mathbf{Y(0)}\\) are fixed (because units are non-random but determined by sample I have). I refer to the potential outcomes collectively as \\(\\mathbf{Y(w)} = (\\mathbf{Y(1)}, \\mathbf{Y(0)})\\).\nOnce randomisation is complete the number of units in treatment and control, \\(n_t\\) and \\(n_c\\) are given. I refer to them collectively as \\(\\mathbf{n} = (n_t, n_c)\\).\nThe assignment mechanism is also such that units treatment assignment is independent of the treatment assignment of all other units.\n\nIn the next two sections we show that \\(\\hat{\\tau}^{\\text{dm}}\\) is an unbiased estimator of \\(\\tau\\) and calculate its variance. (My approach is based on Ding (2023). For an alternative, see Appendix 6.B. in Imbens and Rubin (2015).)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The stats of online experiments</span>"
    ]
  },
  {
    "objectID": "chapters/stats_of_online_experiments.html#unbiasedness",
    "href": "chapters/stats_of_online_experiments.html#unbiasedness",
    "title": "4  The stats of online experiments",
    "section": "4.3 Unbiasedness",
    "text": "4.3 Unbiasedness\nand calculate its variance. My approach is based on Ding (2023). For an alternative, see Appendix 6.B. in Imbens and Rubin (2015).\n\nGiven that our sample is fixed, the two vectors of potential outcomes, \\(\\mathbf{Y(1)}\\) and \\(\\mathbf{Y(0)}\\) are also fixed. potential outcomes collectively as \\(\\mathbf{Y(w)} = (\\mathbf{Y(1)}, \\mathbf{Y(0)})\\)\nOnce randomisation is complete the number of units in treatment and control, \\(n_t\\) and \\(n_c\\) are given. I refer to them collectively as \\(\\mathbf{n} = (n_t, n_c)\\).\n\nAn estimator is unbiased if its expected value equals the estimand. To show that the difference in means estimator is unbiased we thus have to show that:\n\\[\n\\begin{align}\n\\mathbb{E}\\left[\n\\hat{\\tau}^{\\text{dm}}\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n=\\tau.\n\\end{align}\n\\]\nGiven our definitions above this is means showing that\n\\[\n\\begin{align}\n\\mathbb{E}\\left[\n\\hat{\\tau}^{\\text{dm}}\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n\\\\[5pt]\n&=\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n- \\mathbb{E}\\left[\n\\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n\\\\[5pt]\n&\n\\enspace\n\\overset{!}{=}\n\\enspace\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n&=\n\\tau\n\\end{align}\n\\]\nThere are two pieces we need for this:\n\nLink observed to potential outcomes so that \\(Y_i = Y_i(W_i)\\). This requires the Stable Unit Treatment Value Assumption (SUTVA).\nLink treatment group averages to sample averages so that \\(\\mathbb{E}\\left[\\frac{1}{n_t}\\sum_{W_i=w}Y_i(w)\\right] = \\frac{1}{n}\\sum_{i=1}^{n}Y_i(w)\\). This requires randomisation.\n\nLet’s tackle them in turn.\n\n4.3.1 SUTVA links observed outcomes to potential outcomes\nWe want to learn something about unit-level differences in potential outcomes \\[\n\\tau_i = Y_i(1) - Y_i(0),\n\\] where a potential outcome is a unit-indexed function of the treatment level, with the treatment levels in our case simply being “treatment” and “control”, captured by the assignment indicator \\(W_i \\in {0, 1}\\).\nNow say we run an experiment and unit \\(i\\) is allocated to treatment. The \\(i\\)-th element of the assignment vector \\(\\mathbf{W}\\) of that experiment is thus \\(W_i = 1\\), and we refer to this assignment vector as \\(\\mathbf{W}^{(i=1)}\\).\nWe know we can’t observe both \\(Y_i(0)\\) and \\(Y_i(1)\\), but given that \\(i\\) is in treatment we can observe the potential outcome under treatment, \\(Y_i(1)\\), which will help us estimate \\(\\hat{\\tau}\\). So we need\n\\[\nY_i = Y_i(1).\n\\]\nWhat we directly observe, however, is \\[\nY_i = Y_i\\left(\\mathbf{W}^{(i=1)}\\right).\n\\] In words: the outcome we observe for unit \\(i\\) in our experiment is not the potential outcome for \\(i\\) under treatment, but the potential outcome for \\(i\\) under the specific assignment vector of our experiment, \\(\\mathbf{W}^{(i=1)}\\). What does this mean concretely? It means that the observed outcome is a function not only of \\(i\\)’s treatment assignment but of:\n\nThe assignment of all units in the experiment\nThe precise form of the assigned treatment level received by \\(i\\)\nThe way in which said assigned treatment level is administered to \\(i\\)\n\nWe need: \\[\nY_i = Y_i\\left(\\mathbf{W}^{(i=1)}\\right) \\overset{!}{=} Y_i(1).\n\\] The only way to make progress is to assume what we need: that potential outcomes for unit \\(i\\) are a function only of the treatment level unit \\(i\\) itself receives and independent of (i) treatment assignment of other units and (ii) the form and administration of the treatment level. (i) above is referred to as “no interference” in the literature, (ii) as “no hidden variations of treatment”.\nThat assumption is SUTVA, the Stable Unit Treatment Value Assumption. It ensures that the potential outcomes for each unit and each treatment level are well-defined functions of the unit index and the treatment level only – that for a given unit and treatment level, the potential outcome is well-defined and, thus, “stable” (Rubin 1980).\nNote that (ii) does not mean that a treatment level has to take the same form for all units, even though it is often misinterpreted to mean that. What we need is that \\(Y_i(W_i)\\) is a clearly defined function for all \\(i\\) and all possible treatment levels \\(W_i \\in \\{0, 1\\}\\). For this to be the case, it must be the case that there are no different forms of possible treatments, the potential outcome for each for is the same so that the differences are irrelevant, or that the experienced form is random so that the expected outcome across all units remains stable.\nIn the context of our e-commerce app experiment, the non-interference part of SUTVA means that potential outcomes for all customers are independent of treatment assignment of all other customers – very much including family members and friends and the no-hidden-variation part means that there their precise experience is pinned down by their mobile device and remains stable over time: there are no accidental server-side bugs that creates different background colours and the it is either clear whether a customer uses an Android or iOS app (or the experience is identical). But, again, SUTVA does not require that the active treatment looks exactly the same on iOS and Android apps just that for each unit in our experiment, their experience if they are part of the active treatment is pinned down.\nWhy is this important? We want to know what happened if we rolled out our policy to everyone compared to if we didn’t roll it out to anyone. To have any hope of estimating this we can’t have treatment level’s vary over time or depending on circumstances, but need them to be pinned down for each unit. (In the context of Tech, this would mean that the experience of a feature for a given user is pinned down by, say, the size of their phone screen and the app version they use, which, by and large, is plausible.)\nSUTVA is a strong assumption and can be violated in a number of ways. I’ll discuss these, together with solutions, in Chapter 5.\nIf SUTVA holds we have:\n\\[\nY_i = Y_i(W_i) = \\begin{cases}\n   Y_i(1) & \\text{if } W_i = 1 \\\\\n   Y_i(0)       & \\text{if } W_i = 0,\n  \\end{cases}\n\\]\nor, more compactly:\n\\[\nY_i = W_iY_i(1) + (1 - W_i)Y_i(0).\n\\]\nThis is the link between observed and potential outcomes we need, and makes clear that we observe \\(Y_i(1)\\) for units in treatment and \\(Y_i(0)\\) for units in control.\nIn our unbiasedness proof, we now have \\[\n\\begin{align}\n\\mathbb{E}\\left[\n\\hat{\\tau}^{\\text{dm}}\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n\\\\[5pt]\n&=\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n- \\mathbb{E}\\left[\n\\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{E}\\left[\\frac{1}{n_t}\\sum_{W_i=1}Y_i(1)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]\n- \\mathbb{E}\\left[\\frac{1}{n_c}\\sum_{W_i=0}Y_i(0)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]\n\\\\[5pt]\n&\n\\enspace\n\\overset{!}{=}\n\\enspace\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n&=\n\\tau\n\\end{align}\n\\]\nWhat remains is to show that \\(\\mathbb{E}\\left[\\frac{1}{n_t}\\sum_{W_i=w}Y_i(w)\\right] = \\frac{1}{n}\\sum_{i=1}^{n}Y_i(w)\\). This requires randomisation.\n\n\n4.3.2 Randomisation links treatment groups to the population\nSteps:\n\nWe use the definition of \\(W_i\\) to write \\(\\sum_{W_i=1}Y_i(1)\\) as \\(\\sum_{i=1}^{n} W_iY_i(1)\\) and similarly for control units.\nWe use the linearity of \\(\\mathbb{E}\\) to move \\(\\mathbb{E}\\) inside the summation, where the only random element is \\(W_i\\).\nUse Lemma 1 (randomisation) to replace expectations with expected values.\n\n\\[\n\\begin{align}\n\\mathbb{E}\\left[\n\\hat{\\tau}^{\\text{dm}}\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n\\\\[5pt]\n&=\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n- \\mathbb{E}\\left[\n\\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{E}\\left[\\frac{1}{n_t}\\sum_{W_i=1}Y_i(1)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]\n- \\mathbb{E}\\left[\\frac{1}{n_c}\\sum_{W_i=0}Y_i(0)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]\n\\\\[5pt]\n&=\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{i=1}^{n}W_iY_i(1)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n-\n\\mathbb{E}\\left[\n\\frac{1}{n_c}\\sum_{i=1}^{n}(1-W_i)Y_i(0)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n\\\\[5pt]\n&=\n\\frac{1}{n_t}\\sum_{i=1}^{n}\n\\mathbb{E}[W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\nY_i(1)\n-\n\\frac{1}{n_c}\\sum_{i=1}^{n}\n\\mathbb{E}[1-W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\nY_i(0)\n\\\\[5pt]\n&\\text{Randomisation (Lemma 1)}\n\\\\[5pt]\n&=\n\\frac{1}{n_t}\\sum_{i=1}^{n}\n\\left(\\frac{n_t}{n}\\right)\nY_i(1)\n-\n\\frac{1}{n_c}\\sum_{i=1}^{n}\n\\left(\\frac{n_c}{n}\\right)\nY_i(0)\n\\\\[5pt]\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n&=\n\\tau\n\\end{align}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The stats of online experiments</span>"
    ]
  },
  {
    "objectID": "chapters/stats_of_online_experiments.html#variance",
    "href": "chapters/stats_of_online_experiments.html#variance",
    "title": "4  The stats of online experiments",
    "section": "4.4 Variance",
    "text": "4.4 Variance\nFor the variance calculation below we need a few more definitions. We can define sample means and variances of the potential outcomes as:\n\\[\n\\begin{align}\n\\overline{Y}(1) = \\frac{1}{n}\\sum_{i=1}^n Y_i(1),\n\\qquad\nS_1^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n\\\\[5pt]\n\\overline{Y}(0) = \\frac{1}{n}\\sum_{i=1}^n Y_i(0),\n\\qquad\nS_0^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n\\\\[5pt]\n\\end{align}\n\\]\nWe have already defined the sample average treatment effect in Equation 4.1. I rewrite it here for convenience and expand the definition using the above expressions:\n\\[\n\\begin{align}\n\\tau\n&= \\frac{1}{n}\\sum_{i=1}^n \\tau_i\n\\\\[5pt]&= \\frac{1}{n}\\sum_{i=1}^n \\left(Y_i(1) - Y_i(0)\\right)\n\\\\[5pt]&= \\frac{1}{n}\\sum_{i=1}^n Y_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]&= \\overline{Y}(1) - \\overline{Y}(0).\n\\end{align}\n\\]\nThe variance of the individual-level causal effects is:\n\\[\n\\begin{align}\nS_{\\tau_i}^2\n&= \\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - Y_i(0)\n- \\left(\\overline{Y}(1) - \\overline{Y}(0)\\right)\\right)^2\n\\\\[5pt]\n&= \\frac{1}{n-1}\\sum_{i=1}^{n}\\left(\\tau_i - \\tau\\right)^2 \\\\[5pt]\n\\end{align}\n\\] The covariance of potential outcomes is: \\[\n\\begin{align}\nS_{0, 1} &= \\frac{1}{n-1}\\sum_{i=1}^{n}\n\\left(Y_i(1) - \\overline{Y}(1)\\right)\n\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\end{align}\n\\]\nAll lemmas referred to below are here.\nWe can then calculate the variance as (I do not explicitly condition on \\(\\mathbf{n}\\) and \\(\\mathbf{Y(w)}\\) here to keep the notation lighter):\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1)\n- \\frac{1}{n_c}\\sum_{i=1}^n Y_i(0)\n+ \\frac{1}{n_c}\\sum_{i=1}^n W_iY_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i\\frac{Y_i(1)}{n_t}\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n+ \\sum_{i=1}^n W_i\\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&\\text{Dropping constant term}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n\\right)\n\\\\[5pt]\n&\\text{Demeaning (leaves variance unchanged)}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c} - \\left(\\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Using shorthands } Y_i^+ = Y_i(1)/n_t + Y_i(0)/n_c \\text{ and } \\overline{Y}^+ = \\overline{Y}(1)/n_t - \\overline{Y}(0)/n_c\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Rewriting variance in terms of covariance}\n\\\\[5pt]\n&=\n\\text{Cov}\\left(\n\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\\right),\n\\sum_{j=1}^n W_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(\nW_i \\left(Y_i^+ - \\overline{Y}^+\\right),\nW_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i^2\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 2}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 3}\n\\\\[5pt]\n&=\n\\sum_{i=1}^{n}\\left(\\frac{n_tn_c}{n^2}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\sum_{i=1}^{n}\\sum_{j \\neq i}\\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\\sum_{j \\neq i}\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&\\text{Lemma 4}\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+ \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2} + \\frac{n_tn_c}{n^2(n-1)}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c(n-1) + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{nn_tn_c - n_tn_c + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&\\text{Reverting to full notation and expanding square term}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\n- \\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\left(\\frac{Y_i(1)}{n_t} - \\frac{\\overline{Y}(1)}{n_t}\\right)\n+ \\left(\\frac{Y_i(0)}{n_c} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t}\\left(Y_i(1) - \\overline{Y}(1)\\right)\n+ \\frac{1}{n_c}\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t^2}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\frac{1}{n_t^2}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{n_t}{n n_c}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}2S_{0,1}\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 5}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}\\left(S_1^2 + S_0^2 - S_{\\tau_i}^2\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\left(\\frac{n_c}{n n_t} + \\frac{1}{n}\\right)S_1^2\n+ \\left(\\frac{n_t}{n n_c} + \\frac{1}{n}\\right) S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c + n_t}{n n_t} S_1^2\n+ \\frac{n_t + n_c}{n n_c} S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{S_1^2}{n_t}\n+ \\frac{S_0^2}{n_c}\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n\\end{align}\n\\tag{4.2}\\]\nThis is the sampling variance of \\(\\hat{\\tau}^{\\text{dm}}\\). It’s a theoretical quantity we cannot directly observe. However, we can observe treatment group means:\n\\[\n\\begin{align}\n\\overline{Y}_t = \\frac{1}{n_t}\\sum_{i=1}^n W_iY_i\n\\qquad\n\\overline{Y}_c = \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\end{align}\n\\] and treatment group variances:\n\\[\n\\begin{align}\ns_t^2 = \\frac{1}{n_t-1}\\sum_{i=1}^{n}W_i\\left(Y_i - \\overline{Y}_t\\right)^2\n\\qquad\ns_c^2 = \\frac{1}{n_c-1}\\sum_{i=1}^{n}(1-W_i)\\left(Y_i - \\overline{Y}_c\\right)^2.\n\\end{align}\n\\] It can be shown that the observed treatment group variances \\(s_t^2\\) and \\(s_c^2\\) are unbiased estimators of the sample variances \\(S_1^2\\) and \\(S_0^2\\) (see, for instance, Appendix A in Chapter 6 of Imbens and Rubin (2015)). The last term in\n\n\\(S_{\\tau_i}^2\\), is the variance of unit-level treatment effects, which is impossible to observe.\nAs a result, the most widely used estimator in practice is: \\[\n\\hat{\\mathbb{V}}\n= \\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}.\n\\] In our context, the main advantages of this estimator are:\n\nIf treatment effects are constant across units, then this is an unbiased estimator of the true sampling variance since in this case, \\(S^2_{\\tau_i} = 0\\).\nIf treatment effects are not constant, then this is a conservative estimator of the sampling variance (since \\(S_{\\tau_i}^2\\) is non-negative).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The stats of online experiments</span>"
    ]
  },
  {
    "objectID": "chapters/stats_of_online_experiments.html#standard-error",
    "href": "chapters/stats_of_online_experiments.html#standard-error",
    "title": "4  The stats of online experiments",
    "section": "4.5 Standard error",
    "text": "4.5 Standard error\nThe standard error of an estimator is simply the square root of its sampling variance. From\n\nwe thus have:\n\\[\n\\widehat{SE}\n= \\sqrt{\\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}}.\n\\tag{4.3}\\]\nBecause in online experiments sample sizes are large and treatment effects are usually small, it is sometimes convenient to assume equal sample sizes, so that the sample size for each variant is \\(n_t = n_c = n_v\\), and equal variances, so that \\(s_t^2 = s_c^2 = s^2\\). The common variance \\(s^2\\) is estimated by “pooling” the treatment group variances to create a degrees-of-freedom-weighted estimator of the form: \\[\ns^2 = \\frac{(n_t - 1) s_t^2 + (n_c - 1) s_c^2}{n_t + n_c - 2}.\n\\] Substituting in Equation 4.3 we then have: \\[\n\\widehat{SE}^{\\text{equal}}\n= \\sqrt{\\frac{s^2}{n_v} + \\frac{s^2}{n_v}}\n= \\sqrt{\\frac{2s^2}{n_v}}.\n\\tag{4.4}\\]\nFinally, for the purpose of experiment design it is sometimes useful to express the standard error in terms of the proportion of units allocated to the treatment group. Hence, instead of assuming equal sample sizes, we use \\(p\\) to denote that proportion and \\(n\\) to denote total sample size, while maintaining the assumption of equal variance. Again substituting in Equation 4.3 we can then write: \\[\n\\widehat{SE}^{\\text{prop}}\n= \\sqrt{\\frac{s^2}{pn} + \\frac{s^2}{(1-p)n}}\n= \\sqrt{\\frac{s^2}{np(1-p)}}.\n\\tag{4.5}\\]\nFor \\(p=0.5\\), this formulation is equivalent to Equation 4.4 as expected.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The stats of online experiments</span>"
    ]
  },
  {
    "objectID": "chapters/stats_of_online_experiments.html#qa",
    "href": "chapters/stats_of_online_experiments.html#qa",
    "title": "1  The stats of online experiments",
    "section": "1.7 Q&A",
    "text": "1.7 Q&A\n\n1.7.0.0.1 Question 1\nWhy do we need potential outcomes at all? Can’t we interpret the difference from a simple comparison of averages as the causal effect?\n\n\n1.7.0.0.2 Question 2\nWhy do randomised trials not require the excludability assumption in order to lead to unbiased results?\n\n\n1.7.0.0.3 Answer 1\nWhy potential outcomes? - Clarifies what precisely we are trying to estimate: average individual treatment effect - Makes explicit the assumptions we need to make to do so: - SUTVA: What we need is to be able to write Y-i = WY1 + (1-W)Y0. For this we need i) independence from other’s assignment, and ii) clearly defined meaning of Wi =1 and Wi = 0, because if they are not clearly defined then Y1/Y0 might not be stable. SUTVA handles both of these. - Randomisation: to make sure that EY0 for W=1 equals EY0 W=0 Material - ding2023first footnote 2 in chapter 4 and\n\nWhat is definition of causal effect in suggested comparison?\nWhat is source of randomisation?\nDiscuss textbook iid approach and why it’s not a good model for our purpose.\nShow that in practice, variance is the same\n\nIn the classic two-sample problem, observations in the treatment group {y1s} and control group {y0s} are assumed to be IID draws from two separate distributions. Treatment observations are assumed to be IID draws from a distribution with mean \\(\\mu_t\\) and variance \\(\\sigma_t^2\\) and similar for control, and the variance of the difference in means estimator is given by:\n\\[\n\\mathbb{V}(\\hat{\\tau}) = \\frac{\\sigma_t^2}{n_t} + \\frac{\\sigma_c^2}{n_c}.\n\\] That is, there is no third term for the variance of the individual-level potential outcomes.\nIn contrast, Rubin points out that for proper causal inference, {y1, y0} pairs are from the same distribution but we observe only one item of the pair.\nDifferences: - Sampling based vs randomisation based variation: makes sense given that in IID case we are assumed to sample from population, whereas in FS case we are assumed to have all units, but randomise which item of the PO pair is observed. - Hence: the variance in IID is taken over the randomness of the outcomes because uncertainty is sampling based, whereas in the potential outcomes framework, where potential outcomes are fixed, the variance is taken over the randomisation distribution. - As a result: there is no correlation between two groups in IID case (covar = 0) and hence no third term, whereas in FS case there is – why precisely? Because there is correlation between y1s and y2s – if there isn’t, then the third term vanishes. See ding derivation. However, ultimately it’s because there is heterogeneity in individual-level treatment effects. Why is that? Is that the same as PO correlation at individual level? - Weird, though, that Ding lemmas seem to be based on IID case!\n\n\n1.7.0.0.4 Answer 2\n…",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The stats of online experiments</span>"
    ]
  },
  {
    "objectID": "chapters/stats_of_online_experiments.html#references",
    "href": "chapters/stats_of_online_experiments.html#references",
    "title": "4  The stats of online experiments",
    "section": "4.6 References",
    "text": "4.6 References\n\n\n\n\nDing, Peng. 2023. “A First Course in Causal Inference.” https://arxiv.org/abs/2305.18793.\n\n\nHolland, Paul W. 1986. “Statistics and Causal Inference.” Journal of the American Statistical Association 81 (396): 945–60.\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.\n\n\nRubin, Donald B. 1980. “Randomization Analysis of Experimental Data: The Fisher Randomization Test Comment.” Journal of the American Statistical Association 75 (371): 591–93.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The stats of online experiments</span>"
    ]
  },
  {
    "objectID": "chapters/stats_of_online_experiments.html#footnotes",
    "href": "chapters/stats_of_online_experiments.html#footnotes",
    "title": "4  The stats of online experiments",
    "section": "",
    "text": "Our \\(n\\) units are not a sample of a larger population that we hope to learn about but the entire population of units of interest. We thus use a finite sample rather than a super-population approach. For a discussion on the difference between these approaches see Chapter 7.↩︎\nIn principle, the unit-level level causal effect can be any comparison between the potential outcomes, such as the difference \\(Y_i(1) - Y_i(0)\\) or the ratio \\(Y_i(1)/Y_i(0)\\). In online experiments, we usually focus on the difference.↩︎\nHolland (1986) discusses two solutions to the Fundamental Problem: one is the statistical solution, which relies on estimating average treatment effects across a large population of units while the other is the scientific solution, which uses homogeneity or invariance assumptions. The scientific solution works as follows: say we have one measurement of a units outcome under treatment from today and another measurement of their outcome under control from yesterday. If we are prepared to assume that control measurements are homogenous and invariant to time – that yesterday’s control measurement equals the control measurement we would have taken today – then we can calculate the individual level causal effect by comparing the two measurements taken at different points in time. Our assumption is untestable, of course, but in lab experiments it is sometimes possible to make a strong case that it is plausible. It is also the approach we informally use in daily life, whenever we conclude that taking Paracetamol helps against headaches or that going to sleep early makes us feel better the next morning.↩︎\nI have taken a slight shortcut here by treating experiments as being synonymous with the statistical solution (see previous footnote) even though observational studies can serve the same purpose (albeit with additional assumptions). I do this because my focus here is on experiments. See, for instance, Imbens and Rubin (2015) for an extensive discussion of experimental and observational approaches.↩︎\nTo denote the sum over all units in a given treatment group \\(w\\) I use \\(\\sum_{W_i=w}\\) as a shorthand for \\(\\sum_{i:W_i=w}\\) to keep the notation compact.↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The stats of online experiments</span>"
    ]
  },
  {
    "objectID": "chapters/power.html",
    "href": "chapters/power.html",
    "title": "7  Power",
    "section": "",
    "text": "7.1 What is power and how do we measure it?\n$$\n$$",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#required-sample-size",
    "href": "chapters/power.html#required-sample-size",
    "title": "7  Power",
    "section": "7.2 Required sample size",
    "text": "7.2 Required sample size\nThe required sample size is determined by four factors:\n\nThe probability of making a Type I error, denoted by \\(\\alpha\\), corresponds to the significance level of the test and has an associated with the upper-tail critical value \\(z_{\\alpha/2}\\) in a two-sided test.\nThe probability of making a Type II error, denoted by \\(\\beta\\), determines the power of the test, \\(1-\\beta\\), and has associated critical value given by \\(z_{1 - \\beta}\\).\nThe standard deviation of the outcome variable, \\(s\\).\nThe minimal detectable effect size, \\(\\Delta\\).\n\nIn the context of online experiments, we usually fix the significance level and desired power, calculate the estimate the outcome variable’s standard deviation from historical data, fix the minimal detectable effect, and then calculate required sample size. Given these inputs, and assuming equal sample sizes and variances for treatment and control variants, that required sample size per variant is given by: \\[\n\\begin{align}\nn_v = 2(z_{\\alpha/2} + z_{1 - \\beta})^2\\frac{s^2}{\\Delta^2},\n\\end{align}\n\\tag{7.1}\\]\nThe power formula can be intimidating and confusing, all the more so since there are different and sometimes incorrect versions presented in different articles. Here, I want to derive the formula to demystify it.\n\n7.2.1 Bloom approach\n\nBloom (1995) introduces the concept of MDE to measure and compare power and provides a useful heuristic approach to perform sample size calculations.\n\n\n\n\ntitle\n\n\n\nIn above figure, which is taken from Duflo, Glennerster, and Kremer (2007), the left hand curve is the sampling distribution of the estimator under \\(H_0\\), where the true effect size is 0, and the right hand curve its sampling distribution under \\(H_A\\), where the true effect size is \\(\\Delta\\). Because in online experiments sample sizes are usually large, these sampling distributions are well approximated by a standard normal distribution.\nFor a given significance level \\(\\alpha\\), the critical value \\(z_{a/2}\\) in a two-sided test is the point in the \\(H_0\\) distribution that has \\(\\alpha/2\\) of the probability mass to its right. We can also think of that critical critical value as a distance between the center of the distribution and the critical value.\nFor a given level of power, \\(1-\\beta\\), the critical value \\(z_{1-\\beta}\\) is the point in the \\(H_A\\) distribution that has \\(1-\\beta\\) of the probability mass to its right. It, too, can be thought of as a distance.\n\nlh curve …this is sampling dist of tee, know shape from sampling theory reject h0 if value larger than za rhs is sampling distr under ha what is zk? now derive bloom formula…\nBloom (1995) introduces the notion of the MDE as a useful way to quantify power. In the process, he also uses an intuitive way to derive the power formula based on an illustration of a typical hypothesis-testing scenario.\n\n\n\n\n\n\nFigure 7.1: Source: Duflo, Glennerster, and Kremer (2007), based on Bloom (1995).\n\n\n\nLet’s start by understanding Figure 7.1, which visualises the setup of a one-sided hypothesis test where the true effect equals 0 under the null hypothesis and some positive constant \\(\\te\\) under the alternative hypothesis. Note that the curves are not the standard normal distribution, but the sampling distribution of our estimator \\(\\tee\\). This means that the standard deviation of the curves is given by the standard error of \\(\\tee\\), which is \\(\\se\\). Under the assumption of a homogenous treatment effect, the standard error is identical under \\(\\hn\\) and \\(\\ha\\), which is why the two curves have the same shape\n\nthe distribution will be the same under both the null and the alternative hypothesis, with the center of each distribution given by our hypothesised value of \\(\\te\\) – zero under \\(\\hn\\) and a positive constant under \\(\\ha\\).\nWe reject \\(\\hn\\) if \\(\\tee\\) is to the right of the critical value \\(\\za\\). Also, for a given level of power \\(\\beta\\),\nLargely based on (duflo2007randomization?)\nPower basics\n\\[\nn = \\frac{(f(\\alpha) + f(\\beta))}{\\text{Sample allocation}}\\frac{\\sigma}{\\delta}\n\\]\n\nIn the simplest possible, we randomly draw a sample of size \\(N\\) from an identical population, so that our observations can be assumed to be i.i.d, and we allocate a fraction \\(P\\) of our sample to treatment. We can then estiamte the treatment effect using the OLS regression\n\n\\[ y = \\alpha + \\beta T + \\epsilon\\]\n\nwhere the standard error of \\(\\beta\\) is given by \\(\\sqrt{\\frac{1}{P(1-P)}\\frac{\\sigma^2}{N}}\\).\nstd error derivation (from standard variance result of two independent samples, using population fractions):\n\n\\[\nstd = \\sqrt{\\frac{\\sigma^2}{N_t} + \\frac{\\sigma^2}{N_c}} = \\sqrt{\\frac{\\sigma^2}{PN} + \\frac{\\sigma^2}{(1-P)N}} = ... = \\sqrt{\\frac{1}{P(1-P)}\\frac{\\sigma^2}{N}}\n\\]\n\nThe distribution on the left hand side below shows the distribution of our effect size estimator \\(\\hat{\\beta}\\) if the null hypothesis is true.\nWe reject the null hypothesis if the estimated effect size is larger than the critical value \\(t_{\\alpha}\\), determined by the significance level \\(\\alpha\\). Hence, for this to happen we need \\(\\hat{\\beta} &gt; t_{\\alpha} * SE(\\hat{\\beta})\\) (follows from rearranging the t-test formula).\nOn the right is the distribution of \\(\\hat{\\beta}\\) if the true effect size is \\(\\beta\\).\nThe power of the test for a true effect size of \\(\\beta\\) is the area under this curve that falls to the right of \\(t_{\\alpha}\\). This is the probability that we reject the null hypothesis given that it is false.\nHence, to attain a power of \\(\\kappa\\) it must be that \\(\\beta &gt; (t_a + t_{1-\\kappa}) * SE(\\hat{\\beta})\\), where \\(t_{1-\\kappa}\\) is the value from a t-distribution that has \\(1-\\kappa\\) of its probability mass to the left (for \\(\\kappa = 0.8\\), \\(t_{1-\\kappa} = 0.84\\)).\nThis means that the minimum detectable effect (\\(\\delta\\)) is given by:\n\n\\[ \\delta = (t_a + tq_{1-\\kappa}) * \\sqrt{\\frac{1}{P(1-P)}\\frac{\\sigma^2}{N}} \\]\n\nRearranding for the minimum required sample size we get:\n\n\\[ N =  \\frac{(t_a + t_{1-\\kappa})^2}{P(1-P)}\\left(\\frac{\\sigma}{\\delta}\\right)^2 \\]\n\nSo that the required sample size is inversely proportional to the minimal effect size we wish to detect. This makes sense, it means that the smaller an effect we want to detect, the larger the samle size we need. In particular, given that \\(N \\propto \\delta^{-2}\\), to detect an effect of half the size we need a sample four times the size.\nSE(\\(\\beta\\)) also includes measurement error, so this is also a determinant of power.\n\n\n\n7.2.2 Two-equations approach\n\n\n7.2.3 First-principles approach\nPower is the probability that we reject the null hypothesis if there exists a true effect of size \\(\\Delta\\).\nWe thus have: \\[\n\\begin{align}\n&H_0: \\tau = 0 \\\\[5 pt]\n&H_A: \\tau = \\Delta.\n\\end{align}\n\\]\nWe test the null hypothesis by constructing the test statistic \\[\nZ =\n\\frac{\\hat{\\tau}^{\\text{dm}}}\n{\\widehat{SE}},\n\\]\nand reject \\(H_0\\) if if falls into the rejection region beyond the critical value \\(z_{\\alpha/2}\\). Because the standard normal distribution is symmetric, for a two-sided test we thus reject \\(Z\\) if $$ \\[\\begin{align}\n|Z| &&gt; z_{\\alpha/2} \\\\[5pt]\n\n\\left|\\frac{\\hat{\\tau}^{\\text{dm}}}{\\widehat{SE}}\\right|\n&&gt; z_{\\alpha/2} \\\\[5pt]\n\n\\left|\\hat{\\tau}^{\\text{dm}}\\right|\n&&gt; z_{\\alpha/2}\\widehat{SE}.\n\\end{align}\\] $$\nThe power \\(1-\\beta\\) of the test given that \\(\\tau = \\Delta\\) is the probability that the test statistic \\(Z\\) falls into the rejection region, which is: \\[\n1 - \\beta = P\\left[\n\\left|\\hat{\\tau}^{\\text{dm}}\\right|\n&gt; z_{\\alpha/2}\\widehat{SE}\n\\&gt;\\middle|\\&gt; H_A\n\\right].\n\\]\nThe test statistic falling into the lower or upper rejection region are mutually exclusive events, so the above is equal to \\[\n1 - \\beta\n= P\\left[\n\\hat{\\tau}^{\\text{dm}}\n&gt; z_{\\alpha/2}\\widehat{SE}\\&gt;\\middle|\\&gt; H_A\n\\right]\n+ P\\left[\n\\hat{\\tau}^{\\text{dm}}\n&lt; -z_{\\alpha/2}\\widehat{SE}\\&gt;\\middle|\\&gt; H_A\n\\right]\n\\]\nWe can calculate these probabilities by standardising, which gives us:\n$$ \\[\\begin{align}\n1 - \\beta\n&= P\\left[\n\\frac{\\hat{\\tau}^{\\text{dm}} - \\Delta}{\\widehat{SE}}\n&gt;\n\\frac{z_{\\alpha/2}\\widehat{SE} - \\Delta}{\\widehat{SE}}\n\\right]\n\n+ P\\left[\n\\frac{\\hat{\\tau}^{\\text{dm}} - \\Delta}{\\widehat{SE}}\n&lt;\n\\frac{-z_{\\alpha/2}\\widehat{SE} - \\Delta}{\\widehat{SE}}\n\\right]\n\n\\\\[5pt]\n\n&=\nP\\left[Z &gt; \\frac{z_{\\alpha/2}\\widehat{SE} - \\Delta}{\\widehat{SE}}\n\\right]\n\n+ P\\left[Z &lt; \\frac{-z_{\\alpha/2}\\widehat{SE} - \\Delta}{\\widehat{SE}}\n\\right]\n\n\\\\[5pt]\n\n&=\nP\\left[Z &gt; z_{\\alpha/2} - \\frac{\\Delta}{\\widehat{SE}}\n\\right]\n\n+ P\\left[Z &lt; - z_{\\alpha/2} - \\frac{\\Delta}{\\widehat{SE}}\n\\right].\n\\end{align}\\] $$\nUsing the standard normal CDF, \\(\\Phi(z)\\), we get:\n\\[\n\\begin{align}\n1 - \\beta\n=1 - \\Phi\\left(z_{\\alpha/2} - \\frac{\\Delta}{\\widehat{SE}}\\right)\n+ \\Phi\\left(- z_{\\alpha/2} - \\frac{\\Delta}{\\widehat{SE}}\\right).\n\\end{align}\n\\]\nThe probability that we reject the null hypothesis for the wrong reason, because the test statistic falls below the lower critical value for a true positive effect or above the upper critical value for a true negative effect – sometimes called a Type III error –, is very small. Hence, as the true effect size deviates from zero, one of the two terms in the expression above becomes vanishingly small and can be ignored. For the rest of this chapter, I assume we have a true positive effect and omit the second of the two terms above. We thus have:\n\\[\n\\begin{align}\n1 - \\beta\n=\n1 - \\Phi\\left(z_{\\alpha/2} - \\frac{\\Delta}{\\widehat{SE}}\\right)\n\\end{align}\n\\]\nUsing the symmetry of the standard normal distribution, which implies that \\(1 - \\Phi(k) = \\Phi(-k)\\), we can simplify this to\n\\[\n\\begin{align}\n1 - \\beta\n=\n\\Phi\\left(\\frac{\\Delta}{\\widehat{SE}} - z_{\\alpha/2}\\right).\n\\end{align}\n\\tag{7.2}\\]\nNext, remember that \\(\\Phi(z)\\) takes z-values and returns probabilities (the probability that a standard normal variable is less than a given z value), so its inverse, \\(\\Phi^{-1}(p)\\), takes probabilities and returns z-values (the \\(z\\) value with \\(p\\) probability mass to its left). Hence, \\(\\Phi^{-1}(1-\\beta)\\) refers to the upper-tail critical value of the standard normal distribution that has \\(1-\\beta\\) probability mass to its right, and which we defined above as \\(z_{1-\\beta}\\). Using this, we get:\n$$ \\[\\begin{align}\n\n\\Phi^{-1}(1 - \\beta)\n&=\n\\Phi^{-1}\\left(\n\\Phi\\left(\\frac{\\Delta}{\\widehat{SE}} - z_{\\alpha/2}\\right)\n\\right) \\\\[5pt]\n\nz_{1-\\beta}\n&=\n\\frac{\\Delta}{\\widehat{SE}} - z_{\\alpha/2} \\\\[5pt]\n\n\\Delta\n&= \\widehat{SE}\\left(z_{\\alpha/2} + z_{1-\\beta}\\right).\n\\end{align}\\] $${#eq-mde}\nThis last line is in itself useful because it shows how the MDE is determined by the standard error and our choice of Type I and Type II probabilities.\nDepending on the context, we can plug in any of the standard error versions we defined earlier. To arrive at the above version, we use Equation 5.2, which gives us:\n$$ \\[\\begin{align}\n\n\\Delta\n&= \\widehat{SE}\\left(z_{\\alpha/2} + z_{1-\\beta}\\right) \\\\[5pt]\n\n\\Delta\n&= \\sqrt{\\frac{2s^2}{n_v}}\\left(z_{\\alpha/2} + z_{1-\\beta}\\right) \\\\[5pt]\n\n\\Delta^2\n&= \\frac{2s^2}{n_v}\\left(z_{\\alpha/2} + z_{1-\\beta}\\right)^2 \\\\[5pt]\n\nn_v\n&= 2\\left(z_{\\alpha/2} + z_{1-\\beta}\\right)^2\\frac{s^2}{\\Delta^2}\n\\end{align}\\] $$\nIf, instead of using Equation 5.2 we use the standard error expressed in terms of sample proportions from Equation 5.3, we get: \\[\n\\begin{align}\nn &= \\frac{(z_{\\alpha/2} + z_{1-\\beta})^2}{p(1-p)} \\frac{s^2}{\\Delta^2},\n\\end{align}\n\\] where the left-hand side, \\(n\\) now refers to the total sample size in the experiment rather than the sample size per variant.\nFinally, if we do not assume equal variance then we have: $$ \\[\\begin{align}\n\n\\Delta\n&= \\widehat{SE}\\left(z_{\\alpha/2} + z_{1-\\beta}\\right) \\\\[5pt]\n\n\\Delta\n&= = \\sqrt{\\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}}\\left(z_{\\alpha/2} + z_{1-\\beta}\\right) \\\\[5pt]\n\n\\Delta^2\n&= \\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}\\left(z_{\\alpha/2} + z_{1-\\beta}\\right)^2 \\\\[5pt]\n\nn_v\n&= 2\\left(z_{\\alpha/2} + z_{1-\\beta}\\right)^2\\frac{s^2}{\\Delta^2}\n\\end{align}\\] $$\n\n\n7.2.4 Starting from Type I and Type II error conditions\nUse List, Sadoff, and Wagner (2011)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#relative-effects",
    "href": "chapters/power.html#relative-effects",
    "title": "7  Power",
    "section": "7.3 Relative effects",
    "text": "7.3 Relative effects\nSee zhou2023all ## Correlated data\nSee zhou2023all, hesterberg2024power",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#effective-sample-size-of-test",
    "href": "chapters/power.html#effective-sample-size-of-test",
    "title": "7  Power",
    "section": "7.4 Effective sample size of test",
    "text": "7.4 Effective sample size of test\n\n7.4.1 Effective Sample Size in a Two-Sample Test (Equal Variances Assumed)\nWhen comparing two groups — treatment (size \\(N_T\\)) and control (size \\(N_C\\)) — and assuming equal variances, the effective sample size for estimating the variance of the difference in means is given by the harmonic mean:\n\\[\nN_{\\text{eff}} = \\frac{1}{\\frac{1}{N_T} + \\frac{1}{N_C}}\n\\]\nThis arises because the variance of the difference in means is:\n\\[\n\\text{Var}(\\bar{Y}_T - \\bar{Y}_C) = \\sigma^2 \\left( \\frac{1}{N_T} + \\frac{1}{N_C} \\right)\n\\]\nIf we treat this as equivalent to the variance under a single sample of size \\(N_{\\text{eff}}\\), then:\n\\[\n\\text{Var}(\\text{difference}) = \\frac{2\\sigma^2}{N_{\\text{eff}}}\n\\]\nMatching both sides gives the harmonic mean as the effective sample size.\n\n\n7.4.2 Interpretation\n\nThe harmonic mean weights smaller group sizes more heavily.\nIt reflects the information content for estimating differences — imbalanced samples reduce power.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#rule-of-thumb",
    "href": "chapters/power.html#rule-of-thumb",
    "title": "7  Power",
    "section": "7.5 Rule of thumb",
    "text": "7.5 Rule of thumb\nBlog post on 16 or 32 power confusion: - Reliably looking posts who get it wrong: (https://towardsdatascience.com/probing-into-minimum-sample-size-formula-derivation-and-usage-8db9a556280b — starts with the wrong std error with N for total instead of variant sample size), there is also Kohavi book or paper that gets it wrong\n\nThere is another way to express the variance, which has led to massive confusion.\nI’m pretty sure its the 1/N vs 1/(N/2) error that accounts for the wrong result, and nobody seems to derive this from first principles to check.\nIs original wrong? Check in book – access through WBS.\n\nPopular experiment textbooks and countless sources on the internet often refer to the rule-of thumb for the total sample size calculation that is given by:\n\\[\n\\N \\approx \\frac{32\\vpe}{\\tee^2}.\n\\]\nUsing formula XXX we can see that the rule of thumb straightforwardly results from using the default parameters.\nAssuming equal sample size, so that \\(P=0.5\\) gives us\n\\[\nN = 4 (z_{1 - \\beta} + z_{\\alpha/2})^2\\left(\\frac{\\sev}{\\te}\\right)^2.\n\\]\nSetting the false positive rate to 5% and the false negative rate at 20% for a two-sided hypothesis test, as we commonly do, we get\n\\[\n\\begin{align}\nN &= 4 (0.84 + 1.96)^2\\left(\\frac{\\sev}{\\te}\\right)^2 \\\\\n&\\approx \\left(\\frac{32\\sev}{\\te}\\right)^2\n\\end{align}\n\\]\nGive also per variant, as this is more useful to calculate sample size for experiments with n arms.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#how-to-choose-key-parameters",
    "href": "chapters/power.html#how-to-choose-key-parameters",
    "title": "7  Power",
    "section": "7.6 How to choose key parameters",
    "text": "7.6 How to choose key parameters\n\n7.6.1 MDE\n\nWhat are you balancing here? The size of the effect you are able to identify and the time it takes to do it.\nAll else equal, the smaller a change you want to be able to detect, the longer it will take for the experiment to run because you need more sample size.\nThe relevant question to ask here is “what counts as a practically relevant change?”\nTo answer that, consider:\n\nMaturity of service (the more mature, the smaller a change can be expected)\nSize of service (the larger, the smaller a change still generates a lot of revenue)\nCost of change that need ot be covered\n\nCost of fully building out feature for launch (can be 0 when fully built out for experiment or high if we use painted door)\nCost of maintaining new code (new code has higher bugs, may increase code complexity and maintenance)\nOther costs: e.g. does CPU utilization increase?\n\n\n\n\n\n7.6.2 Significance level\n\nWhat are you balancing here? The probabilities of making a type I and type II error.\nThe higher significance level, the less likely we are to implement useless features (to make a Type I error) but the more likely we are to no implement useful features (to make a Type II error).\nHence, gotta balance cost of implementing useless feature and cost of not implementing useful feature.\nThings that play into this:\n\nHow long will feature be in effect (less long lowers risk of implementing)?\nHow widely will it be deployed (less widely lowers risk of implementing)?\nHow many users will see it / where in the funnel is it (later in funnel lowers risk of implementation)\n\nWhat to do in practice:\n\nStart from baseline values (\\(alpha = 0.05\\))\nAdjust depending on balance of risks\n\n\n\n\n7.6.3 Power\n\nWhat are you balancing here? The risk of making a Type II error and the time you have to wait for your results.\nAll else equal, the higher a level or power you want, the longer you’ll have to run the experiment to accumulate the requried sample size.\nFactors to consider:\n\nHow costly is it to not implement a useful feature.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#measuring-power",
    "href": "chapters/power.html#measuring-power",
    "title": "3  Power",
    "section": "3.7 Measuring power",
    "text": "3.7 Measuring power",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#what-determines-power",
    "href": "chapters/power.html#what-determines-power",
    "title": "7  Power",
    "section": "7.7 What determines power",
    "text": "7.7 What determines power\n\nSignificance level\nEffect size\nStandard error\n\nSample size\nVariant allocation proportion\nMetric variance",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#how-to-increase-power",
    "href": "chapters/power.html#how-to-increase-power",
    "title": "7  Power",
    "section": "7.8 How to increase power",
    "text": "7.8 How to increase power\n\nfor framing on how to increase power, Integrate larsen2023statistical section 2\nPower can be increased trivially by lowering the significance level, which we often don’t want to do, or by increasing sample size, which we’re often trying to avoid.\nIncrease effect size\n\nEnsure that only users who are exposed to the change are in the data to avoid dilution of the effect\n\nOptimally allocate variance proportions\n\nUsually equal for highest power\nShow why with many treatment variants, higher share in control is better\n\nReduce metric variance\n\nChoose metric with low variance\n\nIndicator variables\nAvoid count variables which have have increasing variance as experiment duration progresses\n\nUse variance reduction technique\nTrim outliers\nOnly include triggered users\n\nUse a one-sided test\nEffect of one-sided testing on required sample size.\nIn general: \\[\n  N =  \\frac{(t_a + t_{1-\\kappa})^2}{P(1-P)}\\left(\\frac{\\sigma}{\\delta}\\right)^2\n  \\]\nFor \\(\\alpha = 0.05\\), we have \\(t_{\\alpha}^{ts} = 1.96\\) and \\(t_{\\alpha}^{os} = 1.65\\), while for \\(\\kappa = 0.8\\) we have \\(t_{1 - \\kappa} = 0.84\\). Hence: \\[\n  \\frac{N^{os}}{N^{ts}} = \\frac{ (1.64 + 0.84)^2}{(1.96 + 0.84)^2} = \\frac{6.2}{7.84} = 0.79\n  \\]\nHence, for given levels of power and significance, a one-sided test requires about 21 percent fewer observations.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#problems-with-low-power",
    "href": "chapters/power.html#problems-with-low-power",
    "title": "7  Power",
    "section": "7.9 Problems with low power",
    "text": "7.9 Problems with low power\n\nTruth inflation: underpowered studies only find a significant effect it the effect size is larger than the true effect size, leading to inflated claims of effect sizes.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#power-in-online-experiments",
    "href": "chapters/power.html#power-in-online-experiments",
    "title": "7  Power",
    "section": "7.10 Power in online experiments",
    "text": "7.10 Power in online experiments\n\nKohavi et al. (2014) point out (in rule 7) that while general advice suggets that the CLT provides a good approximation for n larger than 30, the large skew in online metrics often requires many moer users. They recomment 355 * (skewness coefficient)^2.\n\nThe theory for power calculation was developed for metrics with fixed values such as hight or weight.\n\n(During an experiment, the treatment will still change the metric values, but in practice we often make the sensible assumption that the treatment effect will be small, so that the variance between treatment and control are the same. This, in turn, then justifies use of pre-experiment data under the assumption that pre-experiment and experiment data will be very similar.)\nIn online experiments, we often experiment with metrics that are only defined for a specific period of time (e.g. conversion during a 1-month period starting on 15 March 2024).\nThis makes power calculation more complicated.\nWhen calculating required sample size (and/or experiment duration) for an experiment we want to make sure that a Z-test performed at the end of the experiment with the required number of unique units has a certain pre-specified level of power.\nTo calculate that required sample size we input a baseline metric value and the metric standard deviation.\nWith metrics defined only for specific periods, how to calculate these two values is not straightforward.\nLet’s see what we generally do when a metric value is fixed.\nActually, writing this and thinking of an example for the above makes me think that this might be an issue inherent to causal inference analysis.\nAn example where we don’t have the problem is if we want to compare the height of Londoners to the height of Berliners. Here, we’d do the following:\n\nDraw a random sample of Londoners and measure mean and variance of their heights.\nDo the same for a random sample of Berliners.\nPerform a Z-test and calculate its power.\n\nWriting the above makes me realise that the issue is inherent in ex-ante power calculations:\n\nEven in the Londoners and Berliners height example above we’d run into the same problem if we wanted to calculate, before taking any samples, how many samples we’d have to take to have our Z-test be adequately powered.\n\nThe problem arises once we rearrange the power formula from\n\n\\[\n1 - \\beta = f(\\sigma^2, \\delta, P, z_\\alpha, z_{1-\\beta})\n\\] to \\[\nN = \\frac{z_\\alpha + z_{1-\\beta}}{P(1-P)}\\frac{\\sigma^2}{\\delta^2}\n\\] - Because we would use the first version at the time we perform the analysis when we have all the required inputs, whereas we perform the second one before the analysis when we have to estimate \\(\\sigma\\) and \\(\\delta\\).\n\nThe core of the problem is that for many online experiment metrics baseline metric mean and variance change depending on (1) the size of the sample they are calculated from and (2) the period of time and period location they are calculated based on.\n\nis always the case, even in the Londoners and Berliners example above. It’s inherent in performing power calculations.\n\n\nis an additional complications in many online experiments. The two components are period length and period location (i.e. do we measure period of length \\(t\\) in January of September).\n\nOutside of periods that are non-representative because of seasonality reasons, ignoring period location should usually not be a big problem.\nHowever, period duration might make a difference.\nSo, the core problem is that in online experiments, in addition to approximating the sample we calculate metrics based on we also have to approximate the time period.\nHow big a difference does calculating means and stds based on different time periods make? The difference can be substantial. The below table shows means and std for order visit conversion for a set of UK users based on different period lengths.\n\n![[order-conversion-visit-different-periods.png|300]]\n\nRequired sample size is directly proportional to the sample variance, which means that using the variance based on one week instead of 1 month of data would increase required sample size by a factor of \\(\\frac{0.36^2}{0.31^2} = 1.35\\).\nHow hard is it to decently estimate an appropriate time-period? There are two parts we have to estimate: required number of unique units, and how long it takes to gather data from these many units.\nThe required number of units is determined by:\n\nMetric value mean (for experiment-period-length long period)\nMetric value variance (for experiment-period-length long period)\n\nTo amount of time it takes us to gather data for the required number of units depends on traffic to the precise point of the user-funnel/app where the bucketing for the experiment takes place.\n\nSolution: - To ensure that analysis is correctly powered, calculate power every day and stop once adequately powered. - If you want ex-ante guidance, use sensible approximations.\n\nFirst best: to know when analysis is sufficiently powered, calculate power daily and stop experiment when required level of power reached. This ensures that we have both (1) sample we use for analysis and (2) period used for analysis.\nSecond best, if we performed power using data from, say, the first 7-days of the experiment period, we would have a subset of (1) and could intelligently estimate (2) because the observed traffic would take into account the bucketing point and we could estimate future traffic based on it (e.g. we can estimate unique user visits based on unique visits during first week, with different traffic being the result of different bucketing points, but we can estimate path for all bucketing points).\nThird best, if we want to perform power calculation before the experiment starts (i.e. because we want to provide duration estimate during experiment config), we could use data from recent history (e.g. calculated monthly), and calculated separately for each metric, market, and based on other relevant dimensions such as different time period. Though, here, taking into account bucketing points might be challenging and hard to scale. So think about good approximations.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#best-practices",
    "href": "chapters/power.html#best-practices",
    "title": "7  Power",
    "section": "7.11 Best practices",
    "text": "7.11 Best practices\n\nWhen aiming to estimate a precise effect size rather than just being interested in statistical significance, use assurance instead of power: instead of choosing a sample size to attain a given level of power, choose sample size so that confidence interval will be suitably narrow 99 percent of the time (Sample-Size Planning for More Accurate Statistical Power: A Method Adjusting Sample Effect Sizes for Publication Bias and Uncertainty and Understanding the new statistics.)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#experiment-duration",
    "href": "chapters/power.html#experiment-duration",
    "title": "7  Power",
    "section": "7.12 Experiment duration",
    "text": "7.12 Experiment duration\n\nWe usually care about power because it determines experiment runtime.\nThere we walk about how to translate required N into runtime.\nSimon Johnson – Four Customer Characteristics That Should Change Your Experiment Runtime",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#useful-resources",
    "href": "chapters/power.html#useful-resources",
    "title": "7  Power",
    "section": "7.13 Useful resources",
    "text": "7.13 Useful resources\n\nLarsen et al. (2023) for general overview\nZhou, Lu, and Shallah (2023) for comprehensive overview of how to calculate power\nBojinov, Simchi-Levi, and Zhao (2023), section 5, for simulation results for switchbacks and generally good approach to simulation to emulate\nReich et al. (2012) power calcs for cluster-randomised experiments\nPower Analysis for Experiments with Clustered Data, Ratio Metrics, and Regression for Covariate Adjustment\nStatsig sample size calculation formula\n\n\n\n\n\nBloom, Howard S. 1995. “Minimum Detectable Effects: A Simple Way to Report the Statistical Power of Experimental Designs.” Evaluation Review 19 (5): 547–56.\n\n\nBojinov, Iavor, David Simchi-Levi, and Jinglong Zhao. 2023. “Design and Analysis of Switchback Experiments.” Management Science 69 (7): 3759–77.\n\n\nDuflo, Esther, Rachel Glennerster, and Michael Kremer. 2007. “Using Randomization in Development Economics Research: A Toolkit.” Handbook of Development Economics 4: 3895–3962.\n\n\nKohavi, Ron, Alex Deng, Roger Longbotham, and Ya Xu. 2014. “Seven Rules of Thumb for Web Site Experimenters.” In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1857–66.\n\n\nLarsen, Nicholas, Jonathan Stallrich, Srijan Sengupta, Alex Deng, Ron Kohavi, and Nathaniel T Stevens. 2023. “Statistical Challenges in Online Controlled Experiments: A Review of a/b Testing Methodology.” The American Statistician, 1–15.\n\n\nList, John A, Sally Sadoff, and Mathis Wagner. 2011. “So You Want to Run an Experiment, Now What? Some Simple Rules of Thumb for Optimal Experimental Design.” Experimental Economics 14: 439–57.\n\n\nReich, Nicholas G, Jessica A Myers, Daniel Obeng, Aaron M Milstone, and Trish M Perl. 2012. “Empirical Power and Sample Size Calculations for Cluster-Randomized and Cluster-Randomized Crossover Studies.” PloS One 7 (4): e35564.\n\n\nZhou, Jing, Jiannan Lu, and Anas Shallah. 2023. “All about Sample-Size Calculations for a/b Testing: Novel Extensions and Practical Guide.” arXiv Preprint arXiv:2305.16459.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#qa",
    "href": "chapters/power.html#qa",
    "title": "4  Power",
    "section": "4.14 Q&A",
    "text": "4.14 Q&A\nQuestions:\n\nLonger experiment duration generally increases power. Can you think of a scenario where this is not the case?\nAn online shopping site ranks products according to their average rating. Why might this be suboptimal? What could the site do instead?\n\nAnswers:\n\nWhen using a cumulative metric such as number of likes, the variance of which will increase the longer the experiment runs, which will increase the standard error of our treatment effect estimate and lower our power. Remember that \\(SE(\\hat{\\tau}) = \\sqrt{\\frac{1}{P(1-P)}\\frac{\\sigma^2}{N}}\\). So, whether this happens depends on what happens to \\(\\frac{\\sigma^2}{N}\\), as experiment duration increases. A decrease in power is plausible – likely, even! – because \\(N\\) will increase in a concave fashion over the course of the experiment duration (some users keep coming back), while \\(\\sigma^2\\) is likely to grow faster than linearly, which causes the ratio to increase and power to decrease.\nThe approach is suboptimal because products with few ratings will have much more variance than products with many ratings, and their average rating is thus less reliable. The problem is akin to small US states having the highest and lowest rates of kidney cancer, or small schools having highest and lowest average pupil performance. Fundamentally, it’s a problem of low power – the sample size is too low to reliably detect a true effect. The solution is to use a shrinkage method: use a weighted average of the product average rating and some global product rating, with the weight of the product average rating being proportional to the number of ratings. This way, products with few ratings will be average, while products with many ratings will reflect their own rating.\n\n\n\n\n\nBloom, Howard S. 1995. “Minimum Detectable Effects: A Simple Way to Report the Statistical Power of Experimental Designs.” Evaluation Review 19 (5): 547–56.\n\n\nBojinov, Iavor, David Simchi-Levi, and Jinglong Zhao. 2023. “Design and Analysis of Switchback Experiments.” Management Science 69 (7): 3759–77.\n\n\nDuflo, Esther, Rachel Glennerster, and Michael Kremer. 2007. “Using Randomization in Development Economics Research: A Toolkit.” Handbook of Development Economics 4: 3895–3962.\n\n\nKohavi, Ron, Alex Deng, Roger Longbotham, and Ya Xu. 2014. “Seven Rules of Thumb for Web Site Experimenters.” In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1857–66.\n\n\nLarsen, Nicholas, Jonathan Stallrich, Srijan Sengupta, Alex Deng, Ron Kohavi, and Nathaniel T Stevens. 2023. “Statistical Challenges in Online Controlled Experiments: A Review of a/b Testing Methodology.” The American Statistician, 1–15.\n\n\nList, John A, Sally Sadoff, and Mathis Wagner. 2011. “So You Want to Run an Experiment, Now What? Some Simple Rules of Thumb for Optimal Experimental Design.” Experimental Economics 14: 439–57.\n\n\nReich, Nicholas G, Jessica A Myers, Daniel Obeng, Aaron M Milstone, and Trish M Perl. 2012. “Empirical Power and Sample Size Calculations for Cluster-Randomized and Cluster-Randomized Crossover Studies.” PloS One 7 (4): e35564.\n\n\nZhou, Jing, Jiannan Lu, and Anas Shallah. 2023. “All about Sample-Size Calculations for a/b Testing: Novel Extensions and Practical Guide.” arXiv Preprint arXiv:2305.16459.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/threats_to_validity.html",
    "href": "chapters/threats_to_validity.html",
    "title": "8  Threats to validity",
    "section": "",
    "text": "8.0.1 Selection bias\nCommon types of selection bias in data science:\nWays to guard against selection bias:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Threats to validity</span>"
    ]
  },
  {
    "objectID": "chapters/threats_to_validity.html#threats-to-reliability",
    "href": "chapters/threats_to_validity.html#threats-to-reliability",
    "title": "8  Threats to validity",
    "section": "8.1 Threats to reliability",
    "text": "8.1 Threats to reliability",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Threats to validity</span>"
    ]
  },
  {
    "objectID": "chapters/threats_to_validity.html#threats-to-internal-validity",
    "href": "chapters/threats_to_validity.html#threats-to-internal-validity",
    "title": "8  Threats to validity",
    "section": "8.2 Threats to internal validity",
    "text": "8.2 Threats to internal validity\n\nInternal validity refers to the ability of a study to measure the causal effect within the study population.\n\n\n8.2.1 Misc effects (some of them relevant only for field experiments)\n\nHawthorne effect: the treatment group works harder than normal.\nJohn Henry effect: the comparison group competes with the treatment group.\nResentment and demoralising effect: not getting the treatment changes behaviour negatively.\nDemand effect: treatment units more likely to do what they think is wanted from them.\nAnticipation effect: control group changes behaviour in anticipation of future treatment.\nSurvey effect: being surveyed changes behaviour.\n\n\n\n8.2.2 Interference\n\nBasically, all violations to SUTVA\nInterference can happen due to\n\nNetwork effects\nCannibalisation of resources in marketplaces\nShared resources (i.e. treatment slowing down site for everyone)\n\n\n\n\n8.2.3 Interaction effects\n\nUsers can be simultaneously part of multiple experiments, so that what we measure for reach of them is really the effect of the interaction of all of them. This means that, if only some features are implemented, the results after roll out could be different from those observed during the experiment period.\nHowever, with large sample sizes, this should not generally be a problem because effects of different experiments average out between treatment and control group.\nWhile the above may be true statistically, interaction effects can still lead to extremely poor user experiences (blue background interacted with blue font), which is why mature platforms aim to avoid them.\n\n\n\n8.2.4 Non-representative users\nPossible scenarios:\n\nOur marketing department launches an add campaign and attracts a lot of unusual users to the site temporarily.\nA competitor does the same and temporarily takes a ways users from our site.\nHeavy-user bias: heavy users are more likely to be bucketed in an experiment, biasing the results relative to the overall effect of a feature. Depending on the context, this can be an issue.\nSolution: run experiments for longer (thought this comes with opportunity costs, and will increase cookie churn)\n\n\n\n8.2.5 Survivor bias\n\nThis is really just a version of the above: if you select only users that have used the product for some time, your sample is not representative of all users. The classic demonstration of survivor bias is Abraham Wald’s insight in WWII that you want to put extra armour where returning plans got hit the least, since it’s presumable the planes that got hit there that didn’t make it back.\n\n\n\n\n8.2.6 Novelty and learning effects\n\nChallenge: behaviour might change abruptly and temporarily in response to a new feature (novelty or “burn in” effect) or it might take a while for behaviour fully adapt to a new feature (learning effects). In both cases, the results from a relatively short experiment will not provide a representative picture of the long-run effects of a feature.\nExamples: Increasing number of adds shows on Google led to increase in add revenue initially but then decrease of clicks in the long term because it increased add blindness Hohnhold, O’Brien, and Tang (2015)\nSolutions:\n\nMeasure long-term effects (by running experiments for longer)\nHave a “holdout” group of users that isn’t exposed to any changes for a pre-set period of time (a month, a quarter), to measure long-term effects\nEstimate dynamic treatment effects to see the evolution of the treatment effect\n\n\n\n\n8.2.7 Sample ratio mismatch\n\n\n8.2.8 Attrition\nAttrition is when, for some reason, we cannot collect endline data on some units.\nIt’s a problem because when it’s systematic rather than random, treatment and control group are no longer comparable, which is a threat to internal validity. (Even if the same number of people drop out, if they are different type, the problem is the same.) Also, it reduces sample size and thus power.\nWe can limit it if we promise access to the program to everyone (phase-in design), change the level of randomisation, and improve data collection.\nIn our analysis we should 1. Report the extent of attrition, 2. Check for differential attrition (between groups, and within groups based on observable characteristics), and 3. Determine the range of estimates given attrition using a selection model or bounds.\nOne method is to use Heckman’s selection model: we look at the characteristics of those who attrite, assume that they have the same outcomes as those with the same characteristics for which we have data, and then fill in their outcome variables accordingly.\nAnother method is to use bounds. There are two types.\nManski-Horowitz bounds: Lower bound: replace all missing values in treatment with the least favourable outcome value from the observed sample and replace all missing values in control with most favourable value in the observed sample. Upper bound created in a reverse way. Unless attrition is low and the outcome variable is tightly bounded, this tends to lead to very large bounds.\nLee bounds: We treat the estimate from the available data as an upper bound, and construct the lower bound by trimming from the sample with less attrition the observations that most contribute to the treatment effect.\n\n\n8.2.9 ## Imperfect compliance\nPartial complience\n\nPartial compliance occurs if, for some reason, some people in the treatment group are not treated or some people in the control group are.\nIt’s problematic because it reduces the difference in treatment exposure between treatment and control group (in the extreme, if they are equal, we learn nothing), and because they might make treatment takeup non-random.\nA few things can help to limit the problem: make takeup easy and/or incentivise it, randomise at a higher level, and provide a treatment to everyone.\nWe can adjust our analysis by calculating LATE, either using the Wald estimator (ITT / difference in take-up between treatment and control groups) or 2SLS where we instrument the behaviour we want to encourage with the treatment dummy (and possibly other covariates).\nDo not drop non-compliers or re-assign them to the control group – compliers and non-compliers are different so that dropping or reclassifying non-compliers would re-introduce self-selection into out two samples, which defeats the whole point of the randomisation.\n\nDefiers\n\nThey are the opposite of compliers: they either take up the treatment because they were assigned to control or the other way around.\nThey might occur in an encouragement design if they overestimated the benefit of treatment and got discouraged by the information provided in the treatment.\nThey might make us significantly misinterpret the true effect (RRE page 303, or, better, MHE p 156).\nWe can deal with them only if they form an identifiable subgroup, in which case we can estimate the treatment effect on defiers and compliers separately and calculate an average treatment effect.\n\nIn an experiment with one-sided non-compliance what does IV estimate 1. if there are no always-takers and 2. if there are not never-takers?\n\nIn general, IV estimates LATE, the effect on compliers, and the treated consist of compliers and always-takers, while the non-treated consist of compliers and never-takers.\nIf there are no always-takers, the population of compliers is the same as the population of the treated, so that LATE = ATET.\nIf there are no never-takers, the population of compliers is the same as that of the untreated, so LATE = average treatment effect of the untreated.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Threats to validity</span>"
    ]
  },
  {
    "objectID": "chapters/threats_to_validity.html#treats-to-external-validity",
    "href": "chapters/threats_to_validity.html#treats-to-external-validity",
    "title": "8  Threats to validity",
    "section": "8.3 Treats to external validity",
    "text": "8.3 Treats to external validity\n\nExternal validity is concerned with whether the results from a study generalise to other contexts.\n\n\n8.3.1 Budget effects in Ads\n\nOn an adds platform, a treatment might perform very well during an experiment in that it makes marketers launch more adds. But once scaled up may do less well because the increased traffic might exhaust marketer’s budgets, leading them to reduce adds launched.\n\n\n\n8.3.2 Feedback loops from personalisation\n\nTreatments might behave differently during experimentation and once they are scaled up if the performance of a feature is a function of the size of the audience it is exposed to (an example could be a recommendation algorithm, which performs better and better as it is being used more).\n\n\n\n8.3.3 Day-of-week effects\n\nSee below\n\n\n\n8.3.4 Seasonality\n\nSeasonality comes in many forms: day of week effects, week of year effects, season effects, holiday effects, etc.\nThe challenge is that, potentially, user behaviour might differ on certain days or over certain time periods either because we get different users or because users change their behaviour.\nWhether it is really a problem depends on the context. One aspect that is often forgotten here is that seasonality, first and foremost, is about a shift in levels – activity on LinkedIn might go down during the summer months. What we usually want to measure, however, is the difference between treatment and control units. Hence, if you don’t have reason to believe that the effect of the treatment is different during a particular season (e.g. because you think it’s additive), then seasonality might not be a problem for you.\nHaving said that, it’s actually quite likely that with either different users or different behaviour by the same users, users might react differently to featore on different days. So it really is a thread to external validity, and we thus should usually care about it.\nSolution: design your experiment so as to take seasonality into account. E.g. run your experiment for at least one week to account for day of week effects (that’s generally a good idea), don’t run crucial experiments during the holiday season or on major holidays or discard data from such periods, etc.\nWhat to take into account depends on your context. So understand the relevant seasonality for you (if you’re a travel app, consider seasonality of travel demand, if you’re an e-commerce site, consider seasonality of shopping behaviour)\n\n\n\n8.3.5 Differences in time-to-action between users\n\nSome users may engage with a new features immediately, others might take a while and then react differently to it.\nWhen running experiments for a very short time, we might thus get a biased picture of the overall effect of the feature.\nWith this one, one could argue that it’s a threat to internal validity, too. But that depends on what whether we set out to measure the short or long-term causal effect in our study\n\n\n\n8.3.6 Consent\n\nIf consent for experiment participation is required, then people who give consent may be different from those who don’t.\n\n\n\n8.3.7 Heterogeneous treatment effects\n\nConsent above is a specific manifestation of the underlying problem: heterogeneous treatment effects. Often, it is plausible that participants of an experiment are different from non-participants, since – in real life – sampling into the experiment population doesn’t happen at random. So, clearly defining who the full population of interest is, what population we can make inferences about from our experiment population, and understanding hte difference between the two is crucial.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Threats to validity</span>"
    ]
  },
  {
    "objectID": "chapters/threats_to_validity.html#resources",
    "href": "chapters/threats_to_validity.html#resources",
    "title": "8  Threats to validity",
    "section": "8.4 Resources",
    "text": "8.4 Resources\n\nForbes article on when not to trust your A/B tests\nDennis Meisner discussing threats to external validity\n\n\n\n\n\nHohnhold, Henning, Deirdre O’Brien, and Diane Tang. 2015. “Focusing on the Long-Term: It’s Good for Users and Business.” In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1849–58.\n\n\nKing, Gary, and Langche Zeng. 2006. “The Dangers of Extreme Counterfactuals.” Political Analysis 14 (2): 131–59.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Threats to validity</span>"
    ]
  },
  {
    "objectID": "chapters/experiment_setup.html",
    "href": "chapters/experiment_setup.html",
    "title": "9  Experiment setup",
    "section": "",
    "text": "9.1 Approaches to analysing BREs – sampling vs design based",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Experiment setup</span>"
    ]
  },
  {
    "objectID": "chapters/experiment_setup.html#assignment-mechanism",
    "href": "chapters/experiment_setup.html#assignment-mechanism",
    "title": "7  Experiment setup",
    "section": "",
    "text": "7.1.1 General discussion\n\nSee [[notes_on_imbens2015causal]] for background on assignment mechanism\n\n\n\n7.1.2 BRE\nBRE in online experiments, but CRE used in literature for analysis. Apart from those, many others.\n\nSecond, regardless of which of these two perspectives we adopt, we decide how to allocate the \\(n\\) units in the experiment sample into a treatment and control group. The procedure for performing this allocation is called the assignment mechanism, and there are a number of different such mechanisms.\n\nTreatment assignment for units in the experiment sample then works in the same way:\n\nWe again create a unique – but different – hash string for each unit (e.g. &lt;user_id&gt;&lt;experiment_id&gt;&lt;market&gt; with the first bit flipped).\n\nWhy another hash? Suppose we used the same hash strings instead, and that we sampled units with hash values that fall into the bottom 10% of possible hash values. What would happen if we now allocated all units with hash values in the bottom 50% of possible values to treatment and all others to control? How many units would be in the control group? (None! Since the hash values of all units in the sample would fall into the bottom 10% of possible hash values so that all units would be allocated to treatment.) A simple way to create a different hash value is to flip the first bit of the hash string. Because of the avalanche effect, this would result in a completely different hash value.\n\nWe use the hash algorithm to generate a hash value\nIf we wanted to allocate units equally to a control and treatment group, we could allocate all units with hash values within the bottom 50% of possible values to the treatment group and all others to the control group.\n\n\nHashed sampling and treatment assignment resembles sampling without replacement in that we can only include a given user in the experiment once, and resembles sampling with replacement in that sampling and treatment assignment are independent across units – sampling any one unit does not alter the chance of being sampled for any other unit.\nIn online experiments, as least, this is not an assumption if we properly test the randomisation proceedure (see discussion of SRM in Chapter 5)\nIn online experiments, the assignment mechanism is usually a BRE. The assignment mechanism of a BRE is individualistic, probabilistic, and unconfounded. In the simplest case without stratification, it is also independent of covariates. In all cases, the assignment mechanism is fully under our control. For probability of treatment assignment \\(q\\), we thus have:\n\n\\[\nP(\\mathbf{W} | \\mathbf{X}, \\mathbf{Y}(1), \\mathbf{Y}(0)) = P(\\mathbf{W}) = q^{n_t} (1-q)^{n_c}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Experiment setup</span>"
    ]
  },
  {
    "objectID": "chapters/experiment_setup.html#approaches-to-analysing-bres-sampling-vs-design-based",
    "href": "chapters/experiment_setup.html#approaches-to-analysing-bres-sampling-vs-design-based",
    "title": "9  Experiment setup",
    "section": "",
    "text": "Sampling vs randomisation based – see [[stats_foundations#Modes of inference]]\nReading Wager, it seems there are two relevant factors for inference: he just conditions on n to get a CRE, and then there is the question of whether to take a finite sample or super-population perspective.\nThe additional assumption (discussed in population asymptotics) of random sampling from super population holds for online experiments.\nHe does use Bernoulli sampling, which is what I need for online experiments. I just don’f fully understand how his perspective fits into the Imbens Rubin book / Athey Imbens one.\nSee Ding book",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Experiment setup</span>"
    ]
  },
  {
    "objectID": "chapters/experiment_setup.html#finite-sample-vs-superpopulation-analysis",
    "href": "chapters/experiment_setup.html#finite-sample-vs-superpopulation-analysis",
    "title": "9  Experiment setup",
    "section": "9.2 Finite sample vs superpopulation analysis",
    "text": "9.2 Finite sample vs superpopulation analysis\n\nFirst, we decide whether the \\(n\\) units in our experiment sample are the population of interest, or whether that population of interest is instead a larger super-population of size \\(N\\) of which the \\(n\\) units in the experiment sample are a random sample. Following Imbens and Rubin (2015), I refer to the former as the finite sample perspective and the later as the super population perspective.\nOnline experiments typically go through a ramp-up phase: they include only a small fraction of users at the start and all users at the end.\n\nBelow is from an old version – I don’t actually consider both. Just discuss difference here. Use material from imbens2015causal to point out that, ultimately, the difference is irrelevant in practice.\n\nStatistically, this means we have to consider two different cases. In the first case, during the early stages of an experiment, we use a sample of the entire user population to learn something about that population as a whole; in this case, the sample we work with and the sample we want to learn something about are different. In the second case, when the entire user population is part of the experiment, the sample we work with and the sample we want to learn something about are the same. Following Imbens and Rubin (2015), I refer to the first approach as the super-population perspective and the second case the finite sample perspective.\nWe have a super population of \\(N\\) users. In the example I’m going to use throughout, these are all of our iOS-app users in the UK.\nFrom this super population, we sample \\(n\\) users to be part of the experiment, and then allocate \\(n_t\\) users to treatment and \\(n_c\\) users to control.\nThe way we sample users into the experiment and allocate them to treatment has implications for our statistical analysis, so let’s have a look at the details.\nOnline experiments typically use the following sampling approach to determine whether a user is part of an experiment:\n\nCreate a hash string unique for each user in the experiment such as &lt;user_id&gt;&lt;experiment_id&gt;&lt;market&gt;.\n\nFeed the hash string into a hash algorithm (often MD5) and receive a hash value.\nUse the hash value to determine whether a user is part of the experiment. Say we allocate 10% of traffic to the experiment. We then include the user only if their hash value falls within the bottom (or top) 10% of possible hash values.\n\nWith this approach, the probability that a user is sampled into the experiment is independent of the sampling decisions of all other users.\nWe write \\(R_i = 1\\) if user \\(i\\) is part of the experiment sample and \\(R_i = 0\\) if they aren’t.\nIf we sample \\(n\\) users into the experiment, then each of our \\(N\\) users is part of the experiment experiment with probability \\(n/N\\).\nFor each user in the super population, being part of the experiment sample is a Bernoulli trial with \\(R_i \\sim \\text{Bernoulli}(n/N)\\) and, hence, \\(\\mathbb{E}[R_i] = n/N\\) and \\(\\mathbb{V}(R_i) = n/N(1-n/N)\\). I assume here that we know \\(n\\). The reason for doing so is twofold. First, it makes the math easier as it spares us from modeling \\(n\\) as a Binomial random variable. Second, by the time we analyse the data, we do know \\(n\\).\n\n\n9.2.0.1 Description\nFrom athey2017econometrics\nSuper population perspective:\n\nTraditionally, uncertainty in empirical analysis is viewed as arising from randomly drawing a sample of size \\(n\\) from an infinitely large super-population of size \\(N\\).\n(Infinite probably out of convenience so math is easier. Check if ever relevant or when I have time.)\nFor example, it we could measure the height of every single person in London there would be no uncertainty about the average height of that population.\n\nFinite sample perspective\n\nWhen we perform causal inference studies, however, then there are many contexts where the above perspective is odd because we have the entire population to work with so that it’s not clear what the super-population is.\nFor instance, an online experiment with an audience traffic of 100% has got the entire population of customers.\nIn such a setting, however, thinking of causal effects as the difference in individual potential outcomes allows us to interpret the randomness as coming from treatment allocation.\n\n\n\n9.2.0.2 Notes on super-population perspective\ntodo: - Is it worth considering SP case? As in, do we have to adjust the standard error? How much do SEs differ in practice?\n\nHow to go about this: 1) establish whether or not super-population approach is required, 2) is so, compare FS and SP standard errors to check whether it makes a difference. Write up regardless to have a good theoretical foundation. But if I’m lucky then using SP SEs makes a material difference in practice, in which case this would be interesting to publish and use at work.\n\nNotes:\n\nSo far, we have focused on the case where the \\(n\\) units in the experiment sample are the population of interest.\nOnline experiments typically go through a ramp-up phase: they include only a small fraction of users at the start and all users at the end.\nStatistically, this means we have to consider two different cases. In the first case, during the early stages of an experiment, we use a sample of the entire user population to learn something about that population as a whole; in this case, the sample we work with and the sample we want to learn something about are different. In the second case, when the entire user population is part of the experiment, the sample we work with and the sample we want to learn something about are the same. Following Imbens and Rubin (2015), I refer to the first approach as the super-population perspective and the second case the finite sample perspective.\nWe have a (super) population of \\(N\\) users. In the example I’m going to use throughout, these are all of our iOS-app users in the UK.\nFrom this super population, we sample \\(n\\) users to be part of the experiment, and then allocate \\(n_t\\) users to treatment and \\(n_c\\) users to control.\nThe way we sample users into the experiment and allocate them to treatment has implications for our statistical analysis, so let’s have a look at the details.\nOnline experiments usually use the following sampling approach to determine whether a user is part of an experiment:\n\nCreate a hash string unique to each user such as &lt;user_id&gt;&lt;experiment_id&gt;&lt;market&gt;.\nFeed the hash string into a hash algorithm (often MD5) and receive a hash value.\nUse the hash value to determine whether a user is part of the experiment. Say we allocate 10% of traffic to the experiment. We then include the user only if their hash value falls within the bottom (or top) 10% of possible hash values.\n\nWith this approach, the probability that a user is sampled into the experiment is independent of the sampling decisions of all other users.\nEach of our \\(N\\) users is part of the experiment experiment with probability \\(n/N\\) and we write \\(R_i = 1\\) if user \\(i\\) is part of the experiment sample and \\(R_i = 0\\) if they aren’t. Note that I take \\(n\\) as given here. For each user in the super population, being part of the experiment sample is a Bernoulli trial with \\(R_i \\sim \\text{Bernoulli}(n/N)\\) and, hence, \\(\\mathbb{E}[{R_i}] = n/N\\) and \\(\\mathbb{V}(R_i) = n/N(1-n/N)\\). I assume here that we know \\(n\\). The reason for doing so is twofold. First, it makes the math easier as it spares us from modeling \\(n\\) as a Binomial random variable. Second, by the time we analyse the data, we do know \\(n\\).\nFor each user in the super population, being part of the experiment sample is a Bernoulli trial, as is being part of the treatment group for each user in the experiment sample. \\[\n\\begin{align}\nR_i \\sim \\text{Bernoulli}(p) \\quad &\\text{with} \\quad \\mathbb{E}[R_i] = p \\\\\nW_i \\sim \\text{Bernoulli}(q) \\quad &\\text{with} \\quad \\mathbb{E}[W_i] = q\n\\end{align}\n\\]\nThe total number of users in the sample is \\(n = \\sum_{i = 1}^{N}R_i\\).\nEach of the \\(n\\) users in our sample is allocated to the treatment condition with probability \\(q\\), and we write \\(W_i = 1\\) if user \\(i\\) is in the treatment group and \\(W_i = 0\\) if they are in the control group.\nThe total number of users in the treatment group is \\(n_t = \\sum_{i = 1}^{N} W_i\\), and the total number of users in the control group is \\(n_c = \\sum_{i = 1}^{N} (1 - W_i)\\).\nGiven this setup, we have: \\[\n\\begin{align}\n\\mathbb{E}[R_i] &= p \\\\\n\\mathbb{E}[W_i] &= q \\\\\n\\mathbb{E}[n] &= Np \\\\\n\\mathbb{E}[n_t] &= nq \\\\\n\\mathbb{E}[n_c] &= n(1 - q) \\\\\n\\end{align}\n\\]\n(we will use this in the unbiasedness proof below)\nCompare this to a setup where treatment allocation is-non independent: This is easiest to see in contrast to experiments where neither of these decisions are independent, as is often the case in lab and field experiments in social science, but also medical experiments. There, we typically recruit a pre-determined number of units into our experiment, so that the inclusion of any given unit lowers the probability of inclusion for all others. Similarly, for treatment assignment, we would often use a completely randomised assignment, whereby we ensure that exactly \\(N_t\\) units end up in the treatment group. This, again means that assigning any given unit to treatment lowers the probability of receiving the treatment for all other units.\n\nSuper population Estimator\n\nA natural estimator is …\nWe can write our treatment effect estimator, \\(\\hat{\\tau}\\) in terms of the super-population as\n\n\\[\n\\hat{\\tau} = \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i - \\frac{1}{n_c}\\sum_{i=1}^{N} R_i (1 - W_i) Y_i\n\\]\nUnbiasedness of \\(\\hat{\\tau}\\)\n\nUse derivation in wager2024causal page 6, which is very transparent!\nFirst, note that using \n\nwe can write:\n\\[\n\\begin{align}\n\\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i &= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i(1) \\\\\n\\frac{1}{n_c}\\sum_{i=1}^{N} R_i (1 - W_i) Y_i &= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i(1 - W_i) Y_i(0)\n\\end{align}\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nDerivation\n\\[\n\\begin{align}\n\\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i \\Bigl(W_i Y_i(1) + (1 - W_i) Y_i(0)\\Bigr) \\\\\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} \\Bigl(R_i W_i W_i Y_i(1) + R_i W_i (1 - W_i) Y_i(0)\\Bigr) \\\\\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i W_i Y_i(1) \\\\\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i(1) \\\\\n\\frac{1}{n_c}\\sum_{i=1}^{N} R_i (1 - W_i) Y_i\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i (1 - W_i) \\Bigl(W_i Y_i(1) + (1 - W_i) Y_i(0)\\Bigr) \\\\\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} \\Bigl(R_i(1 - W_i) W_i Y_i(1) + R_i(1 - W_i) (1 - W_i) Y_i(0)\\Bigr) \\\\\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i(1 - W_i) (1 - W_i) Y_i(0) \\\\\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i(1 - W_i) Y_i(0)\n\\end{align}\n\\]\n\n\n\n\nWe can now show that \\(\\hat{\\tau}\\) in unbiased, that \\(\\mathbb{E}[\\hat{\\tau}] = \\tau\\).\nWe have two sources of randomness, one due to random sampling and one due to random allocation to treatment. Using the law of iterated expectations, we can write:\n\n\\[\n\\mathbb{E}[\\hat{\\tau}] = \\mathbb{E}_{sp}[\\mathbb{E}_W{\\hat{\\tau}|R}]].\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nLaw of iterated expectations\n\nThat is, we can first take the expectation over the randomisation distribution while talking the vector of sampling allocation indicators, \\(R\\), as given, and then take the expectation over the sampling distribution. \\[\n\\begin{align}\n...\n\\end{align}\n\\]\n\n\n\n\n\nIn both of these steps, we implicitly also condition on the vectors of potential outcomes in the super population, \\(Y_{sp}(0), Y_{sp}(1)\\), which we consider fixed and take as given. I don’t condition on these explicitly to keep the notation light.1\nTODO: condition on \\(Y\\), as a shorthand. Adapt notation below. Also, consider using bf for vectors and matrices for clarity. Probably do it!\nThe inner expectation is equal to:\n\n\\[\n\\begin{align}\n\\EW{\\hat{\\tau} | R}\n&= \\EW{\\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i - \\frac{1}{n_c}\\sum_{i=1}^{N} R_i (1 - W_i) Y_i \\&gt;\\Bigg|\\&gt; R} \\vs\n&= \\EW{\\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i(1) - \\frac{1}{n_c}\\sum_{i=1}^{N} R_i (1 - W_i) Y_i(0) \\&gt;\\Bigg|\\&gt; R} \\vs\n&= \\EW{\\sum_{i=1}^{N} R_i \\Biggl(\\frac{W_i Y_i(1)}{n_t} - \\frac{(1 - W_i) Y_i(0)}{n_c}\\Biggr)\\&gt;\\Bigg|\\&gt; R} \\vs\n&= \\sum_{i=1}^{N} R_i \\EW{\\frac{W_i Y_i(1)}{n_t} - \\frac{(1 - W_i) Y_i(0)}{n_c}} \\vs\n&= \\sum_{i=1}^{N} R_i \\Biggl(\\frac{\\EW{W_i} Y_i(1)}{\\EW{n_t}} - \\frac{(1 - \\EW{W_i}) Y_i(0)}{\\EW{n_c}}\\Biggr) \\vs\n&= \\sum_{i=1}^{N} R_i \\Biggl(\\frac{q Y_i(1)}{Nq} - \\frac{(1 - q) Y_i(0)}{N(1-q)}\\Biggr) \\vs\n&= \\sum_{i=1}^{N} R_i \\Biggl(\\frac{Y_i(1)}{N} - \\frac{Y_i(0)}{N}\\Biggr) \\vs\n&= \\frac{1}{N}\\sum_{i=1}^{N} R_i \\bigl(Y_i(1) - Y_i(0)\\bigr) \\vs\n&= \\tau_{fs}\n\\end{align}\n\\]\n\nThe outer expectation is equal to:\n\n\\[\n\\begin{align}\n\\mathbb{E}[\\hat{\\tau}]\n&= \\Esp{\\EW{\\hat{\\tau}|R}} \\\\\n&= \\Esp{\\tau_{fs}} \\\\\n&= \\Esp{\\frac{1}{N}\\sum_{i=1}^{N} R_i \\bigl(Y_i(1) - Y_i(0)\\bigr)} \\\\\n&= \\frac{1}{\\Esp{N}}\\sum_{i=1}^{N} \\Esp{R_i} \\bigl(Y_i(1) - Y_i(0)\\bigr) \\\\\n&= \\frac{1}{Np}\\sum_{i=1}^{N} p \\bigl(Y_i(1) - Y_i(0)\\bigr) \\\\\n&= \\frac{1}{N}\\sum_{i=1}^{N}\\bigl(Y_i(1) - Y_i(0)\\bigr) \\\\\n&= \\tau\n\\end{align}\n\\]\nVariance of \\(\\hat{\\tau}\\)\n\nUsing the law of total variance2, we can write \\(\\V{\\hat{\\tau}}\\) as\n\n\\[\n\\begin{align}\n\\V{\\hat{\\tau}}\n&= \\Esp{\\VW{\\hat{\\tau} | R}} + \\Vsp{\\EW{\\hat{\\tau} | R}}\n\\end{align}\n\\]\n\n\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.\n\n\nLarsen, Nicholas, Jonathan Stallrich, Srijan Sengupta, Alex Deng, Ron Kohavi, and Nathaniel T Stevens. 2023. “Statistical Challenges in Online Controlled Experiments: A Review of a/b Testing Methodology.” The American Statistician, 1–15.\n\n\nNordin, Mattias, and Mårten Schultzberg. 2024. “Precision-Based Designs for Sequential Randomized Experiments.” arXiv Preprint arXiv:2405.03487.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Experiment setup</span>"
    ]
  },
  {
    "objectID": "chapters/experiment_setup.html#footnotes",
    "href": "chapters/experiment_setup.html#footnotes",
    "title": "9  Experiment setup",
    "section": "",
    "text": "If we were to explicitly condition on potential outcomes, we’d get: \\[\n  \\begin{align}\n  \\mathbb{E}[\\hat{\\tau}]\n  &=\\Esp{\\EW{\\hat{\\tau}|R, Y_{sp}(0), Y_{sp}(1)} | Y_{sp}(0), Y_{sp}(1)}\n  \\end{align}\n  \\]↩︎\nIn general, the Law of total variance states that: \\[\n  \\begin{align}\n  \\V{Y} = \\mathbb{E}[\\V{Y|X}] + \\V{\\mathbb{E}[Y|X}]\n  \\end{align}\n  \\] In our case here, conditioning on \\(R\\) means that we take the expectation or variance over the randomisation distribution, which I make explicit with the subscript \\(W\\). The unconditional expectation or variance is taken over the randomisation distribution, which I make explicit using the subscript \\(sp\\). As in the unbiasedness proof above, we are also implicitly conditioning on potential outcomes and I omit making this explicit to keep the notation lighter. Making the conditioning explicit would mean we apply the law to a conditional variance, for which the logic would still hold, and we’d write: \\[\n  \\begin{align}\n  \\V{\\hat{\\tau} | Y_{sp}(0), Y_{sp}(1)}\n  &= \\Esp{\\VW{\\hat{\\tau} | R, Y_{sp}(0), Y_{sp}(1)} | Y_{sp}(0), Y_{sp}(1)} \\\\\n  &+ \\Vsp{\\EW{\\hat{\\tau} | R, Y_{sp}(0), Y_{sp}(1)} | Y_{sp}(0), Y_{sp}(1)}\n  \\end{align}\n  \\]↩︎",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Experiment setup</span>"
    ]
  },
  {
    "objectID": "chapters/lemmas.html",
    "href": "chapters/lemmas.html",
    "title": "7  Lemmas",
    "section": "",
    "text": "7.1 Lemma 1\nGiven that \\(W_i \\in \\{0, 1\\} \\sim \\text{Bernoulli}(q)\\), and given that we take potential outcomes \\(\\mathbf{Y(w)} = (\\mathbf{Y(1)}, \\mathbf{Y(0)})\\) and sample sizes \\(\\mathbf{n} = (n, n_t, n_c)\\) as given, we have: \\[\n\\mathbb{E}[W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\n=\n\\frac{n_t}{n}\n\\]\nand\n\\[\n\\mathbb{E}[1-W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\n=\n\\frac{n_c}{n}.\n\\] Proof:\nGiven that \\(W_i \\in \\{0, 1\\} \\sim \\text{Bernoulli}(q)\\) we have: \\[\nP(W_i = 1 \\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)})\n=\n\\frac{n_t}{n}.\n\\]Hence: $$ \\[\\begin{align}\n\\mathbb{E}&[W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\n\\\\[5pt]\n\n&=\n1 \\times P(W_i = 1 \\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)})\n+ 0 \\times P(W_i = 0 \\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)})\n\\\\[5pt]\n\n&=\nP(W_i = 1 \\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)})\n\\\\[5pt]\n\n&= \\frac{n_t}{n}\n\\end{align}\\] \\[\nand\n\\] \\[\\begin{align}\n\\mathbb{E}&[(1-W_i)\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\n\\\\[5pt]\n\n&=\n1 - \\mathbb{E}[W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\n\\\\[5pt]\n\n&=\n1 - \\frac{n_t}{n}\n\\\\[5pt]\n\n&=\n\\frac{n - n_t}{n}\n\\\\[5pt]\n\n&=\n\\frac{n_c}{n}\n\\qquad\\square\n\\end{align}\\] $$",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Lemmas</span>"
    ]
  },
  {
    "objectID": "chapters/lemmas.html#sec-lemma2",
    "href": "chapters/lemmas.html#sec-lemma2",
    "title": "7  Lemmas",
    "section": "7.2 Lemma 2",
    "text": "7.2 Lemma 2\nGiven that \\(W_i \\sim \\text{Bernoulli} \\left( \\frac{n_t}{n} \\right)\\), we have:\n\\(\\mathbb{V}(W_i^2) = \\mathbb{V}(W_i)\\).\nProof:\nBernoulli distributed random variables take on either values 0 or 1, so \\(W_i \\in \\{0, 1\\}\\), which implies that: \\[\nW_i^2 =\n\\begin{cases}\n1 &\n\\text{if } W_i = 1\\\\[5pt]\n0 &\n\\text{if } W_i = 0\\\\[5pt]\n\\end{cases}\n\\qquad \\implies\nW_i^2 = W_i.\n\\]\nHence:\n\\(\\mathbb{V}(W_i^2) = \\mathbb{V}(W_i)\\qquad\\square\\)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Lemmas</span>"
    ]
  },
  {
    "objectID": "chapters/lemmas.html#sec-lemma3",
    "href": "chapters/lemmas.html#sec-lemma3",
    "title": "7  Lemmas",
    "section": "7.3 Lemma 3",
    "text": "7.3 Lemma 3\n\\[\n\\mathbb{V}(W_i) = \\frac{n_t n_c}{n^2}, \\qquad\n\\text{Cov}(W_i, W_j) = -\\frac{n_t n_c}{n^2(n-1)}\n\\] Proof:\nGiven that \\[\nW_i \\sim \\text{Bern} \\left( \\frac{n_t}{n} \\right),\n\\]\n\\[\n\\begin{align}\n\\mathbb{V}(W_i) &= \\left(\\frac{n_t}{n}\\right) \\left(1-\\frac{n_t}{n}\\right) \\\\[5pt]\n\\mathbb{V}(W_i) &= \\left(\\frac{n_t}{n}\\right) \\left(\\frac{n-n_t}{n}\\right) \\\\[5pt]\n\\mathbb{V}(W_i) &= \\left(\\frac{n_t}{n}\\right) \\left(\\frac{n_c}{n}\\right) \\\\[5pt]\n\\mathbb{V}(W_i) &= \\frac{n_tn_c}{n^2} \\\\[5pt]\n\\end{align}\n\\]\nFrom the basic result that \\(\\mathbb{V}(X + Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2\\text{Cov}(X, Y)\\), and the fact that symmetry implies that the variances and covariances of all \\(W_i\\)s are the same, we get:\n$$ \\[\\begin{align}\n\\mathbb{V}\\left(\\sum_{i=1}^{n}W_i\\right)\n&= \\sum_{i=1}^{n}\\mathbb{V}(W_i) + 2\\sum_{i&lt;j}^{n}\\text{Cov}(W_i, W_j)\n& \\\\[5pt]\n\n\\mathbb{V}\\left(\\sum_{i=1}^{n}W_i\\right)\n&= n\\mathbb{V}(W_i) + 2\\frac{n(n-1)}{2}\\text{Cov}(W_i, W_j)\n& \\text{symmetry} \\\\[5pt]\n\n\\mathbb{V}\\left(n_t\\right)\n&= n\\mathbb{V}(W_i) + 2\\frac{n(n-1)}{2}\\text{Cov}(W_i, W_j)\n& \\text{Def of }n_t \\\\[5pt]\n\n0 &= n\\mathbb{V}(W_i) + 2\\frac{n(n-1)}{2}\\text{Cov}(W_i, W_j)\n& n_t\\text{ is constant} \\\\[5pt]\n\n0 &= n\\left(\\frac{n_tn_c}{n^2}\\right) + 2\\frac{n(n-1)}{2}\\text{Cov}(W_i, W_j)\n& \\text{Result for } \\mathbb{V}(W_i) \\\\[5pt]\n\n0 &= \\left(\\frac{n_tn_c}{n}\\right) + n(n-1)\\text{Cov}(W_i, W_j)\n& \\text{} \\\\[5pt]\n\n\\text{Cov}(W_i, W_j) &= -\\frac{n_tn_c}{n^2(n-1)}& \\text{}\n\\qquad\\square\n\\end{align}\\] $$",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Lemmas</span>"
    ]
  },
  {
    "objectID": "chapters/lemmas.html#sec-lemma4",
    "href": "chapters/lemmas.html#sec-lemma4",
    "title": "7  Lemmas",
    "section": "7.4 Lemma 4",
    "text": "7.4 Lemma 4\n\\[\n-\\sum_{i=1}^{n}\\sum_{j \\neq i}^{n}\n(Y_i^+ - \\overline{Y}^+)(Y_j^+ - \\overline{Y}^+)\n= \\sum_{i=1}^{n}(Y_i^+ - \\overline{Y}^+)^2\n\\] Proof:\nThe sum of demeaned variables is zero. Hence, \\(\\sum_{i=1}^{n}(Y_i^+ - \\overline{Y}^+) = 0\\), which implies that:\n$$ \\[\\begin{align}\n0\n&= \\sum_{i=1}^{n}(Y_i^+ - \\overline{Y}^+)\n\\sum_{j=1}^{n}(Y_j^+ - \\overline{Y}^+)\n\\\\[5pt]\n\n&= \\sum_{i=1}^{n}\\sum_{j=1}^{n}\n(Y_i^+ - \\overline{Y}^+)(Y_j^+ - \\overline{Y}^+)\n\\\\[5pt]\n\n&= \\sum_{i=1}^{n}(Y_i^+ - \\overline{Y}^+)^2\n+\\sum_{i=1}^{n}\\sum_{j \\neq i}^{n}\n(Y_i^+ - \\overline{Y}^+)(Y_j^+ - \\overline{Y}^+)\n\\\\[5pt]\n\n-\\sum_{i=1}^{n}\\sum_{j \\neq i}^{n}\n(Y_i^+ - \\overline{Y}^+)(Y_j^+ - \\overline{Y}^+)\n&= \\sum_{i=1}^{n}(Y_i^+ - \\overline{Y}^+)^2\n\\end{align}\\] $$ ## Lemma 5 {#sec-lemma5}\n\\[\n2S_{0,1} = S^2_1 + S^2_0 - S^2_{\\tau_i}\n\\] Proof:\n$$ \\[\\begin{align}\nS_{\\tau_i}^2\n\n&= \\frac{1}{n-1}\\sum_{i=1}^{n}\n\\left(\nY_i(1) - Y_i(0)\n- \\left(\\overline{Y}(1) - \\overline{Y}(0)\\right)\n\\right)^2\n\\\\[5pt]\n\n&= \\frac{1}{n-1}\\sum_{i=1}^{n}\n\\left(\n\\left(Y_i(1) - \\overline{Y}(1)\\right)\n- \\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)^2\n\\\\[5pt]\n\n&= \\frac{1}{n-1}\\sum_{i=1}^{n}\n\\left(\n\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n- 2\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)\n\\\\[5pt]\n\n&=\n\\frac{1}{n-1}\\sum_{i=1}^{n}\n\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n-1}\\sum_{i=1}^{n}\n\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n- 2\\frac{1}{n-1}\\sum_{i=1}^{n}\n\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\\\[5pt]\n\n&=\nS^2_1 + S^2_0 - 2S_{0, 1}\n\\\\[5pt]\n\n2S_{0, 1} &= S^2_1 + S^2_0 - S^2_{\\tau_i}\n\\end{align}\\] $$",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Lemmas</span>"
    ]
  },
  {
    "objectID": "chapters/stats_foundations.html",
    "href": "chapters/stats_foundations.html",
    "title": "7  Statistics foundations",
    "section": "",
    "text": "7.1 Other assumptions in casusal inference",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Statistics foundations</span>"
    ]
  },
  {
    "objectID": "chapters/stats_foundations.html#modes-of-inference",
    "href": "chapters/stats_foundations.html#modes-of-inference",
    "title": "7  Statistics foundations",
    "section": "7.2 Modes of inference",
    "text": "7.2 Modes of inference\n\nsee abadie2020sampling ### From athey2017econometrics (my notes)\n\nSampling based: - Also model-based (why?) - This is the classical mode of inference in statistics and observational studies - Randomness results from random sampling. - We assume that the population at hand is a random subsample of a (much) larger population, so that individual values are random. - For instance, in \\(\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n}X_i\\) we treat each \\(X_i\\) as a random variable. - In the context of experimentation, where we can write the treatment group mean as \\(\\bar{Y}_t = \\frac{1}{n_t}\\sum_{i=1}^{n}W_iY_i\\), we treat the \\(W_i\\)s as fixed and \\(Y_i\\)s as random (“for each reserved slot in the treatment group, what is the value of the unit we randomly selected for that slot?”) Randomisation based:\n\n7.2.1 Good chat GPT explanation\nWritten by ChatGPT (OpenAI), March 2025.\nWhy Do the Terms Design-Based and Model-Based Make Sense?\n\nGreat question — the terms design-based and model-based refer to where the uncertainty comes from and what justifies your inference in a causal or statistical analysis. The names make intuitive sense once you understand their core logic:\n\nDesign-Based Inference: Uncertainty from the Design\nWhy “design-based”? - Because inference is justified by the experimental design itself — specifically, the randomization. - The potential outcomes are assumed fixed (part of the “science” in Rubin’s terms). - The only randomness comes from how the treatment was assigned, which is determined by the experimental design (e.g., flipping a fair coin).\n\n📌 The inference relies solely on the known design of the experiment, not on any model of the outcomes.\n\nAnalogy: - You’re not modeling anything — you’re just using the fact that “we randomly assigned treatment, so any observed differences must be causally interpretable.”\nModel-Based Inference: Uncertainty from a Statistical Model\nWhy “model-based”? - Because inference is justified by a statistical model for the data-generating process — not just the design. - Units are thought of as drawn randomly from a population. - Potential outcomes are random variables. - You specify models for those outcomes: ( Y_i(1), Y_i(0) )\n\n📌 The validity of your inference depends on the correctness of the model, not just the study design.\n\nAnalogy: - You’re saying: “Let me make assumptions about how the data are generated, and then use probability to estimate causal effects based on those assumptions.”\nSummary Table\n\n\n\n\n\n\n\n\n\nTerm\nWhy It Makes Sense\nWhere Uncertainty Comes From\nKey Assumption\n\n\n\n\nDesign-Based\nRelies on experimental design (e.g. randomization)\nAssignment mechanism\nRandomized treatment\n\n\nModel-Based\nRelies on statistical models of outcomes\nSampling or model error\nCorrect model specification\n\n\n\nWhy These Terms Are Intuitive - Design-based: You get inference “for free” from the structure of your design, without modeling outcomes. - Model-based: You infer causal effects by assuming a model — inference comes from the model, not the design.\n\n\n7.2.2 Other chat conversation: What precisely makes the approach in the main text design-based?\nThe key is that your derivation conditions on the randomization mechanism — that is, the known process by which treatment is assigned.\n\n\n7.2.3 🔹 1. Expectation taken over assignment mechanism\nYou compute:\n\\[\n\\mathbb{E}\\left[\n\\hat{\\tau}^{\\text{dm}} \\mid \\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n\\]\n\nThe randomness here is over the assignment vector ( ) — i.e., how units are assigned to treatment or control.\nThe potential outcomes ( ) are treated as fixed (non-random).\nThis reflects the design of the experiment: if we re-ran the randomization, we’d get a different estimate ( ^{} ), but the outcomes under treatment and control for each unit would remain the same.\n\n\nThis is the hallmark of the design-based approach:\nIt treats assignment as the source of randomness, and all other aspects (units, outcomes, covariates) as fixed.\n\n\n\n\n7.2.4 🔹 2. Unbiasedness is shown by averaging over random assignments\nYou show:\n\\[\n\\mathbb{E}[\\hat{\\tau}^{\\text{dm}} \\mid \\mathbf{n}, \\mathbf{Y(w)}] = \\tau\n\\]\nThis tells us that: - The estimator is unbiased because of how the assignment was randomized, not because of any assumptions about functional forms, ignorability, or data-generating processes. - That is: randomization justifies the inference, not a model of selection or outcome behavior.\n\n\n\n7.2.5 🔹 3. No assumptions about ignorability or conditional independence\nYou do not assume: - ( W_i (Y_i(0), Y_i(1)) X_i ) (as in observational methods), - or any structural model of selection or behavior.\nInstead, your inference relies solely on the known randomization scheme — e.g., Bernoulli or complete random assignment.\n\n\n\n7.2.6 🧭 In contrast: Identification-based (observational) approach\n\nTakes the data as generated by an unknown, possibly non-random assignment.\nMakes assumptions (e.g., unconfoundedness) to justify:\n\n\\[\n\\mathbb{E}[Y_i(1) - Y_i(0)] = \\mathbb{E}[Y_i \\mid W_i = 1] - \\mathbb{E}[Y_i \\mid W_i = 0]\n\\]\n\nAssumes assignment is as good as random after controlling for covariates.\n\n\n\n\n7.2.7 📌 Summary\n\nThe approach in the main text is design-based because it: - Treats potential outcomes as fixed,\n- Takes expectations only over the random assignment,\n- Shows unbiasedness of the estimator purely from the known experimental design,\n- Requires no modeling of selection.\n\nThis is fundamentally different from the identification-based approach, which models or assumes ignorability to equate observed and counterfactual outcomes.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Statistics foundations</span>"
    ]
  },
  {
    "objectID": "chapters/stats_foundations.html#sampling",
    "href": "chapters/stats_foundations.html#sampling",
    "title": "7  Statistics foundations",
    "section": "7.3 Sampling",
    "text": "7.3 Sampling\n\nWe rely on a sample to learn about a larger population.\nWe thus need to make sure that the sampling procedure is free of bias, so that units in the sample are representative of those in the population.\nWhile representativeness cannot be achieved perfectly, it’s important to ensure that non-representativeness is due to random error and not due to systematic bias.\nRandom errors produce deviations that vary over repeated samples, while systematic bias persists. Such selection bias can lead to misleading and ephemeral conclusions.\nSampling procedures:\n\n[[Simple random sampling]]\n[[Completely random sampling]]\n[[Stratified random sampling]]\nRandomly select \\(n_s\\) from each stratum \\(S\\) of a population of \\(N\\)\nOn stratification: why does it reduce variance? Imagine an extreme case, where the number of strata were equal to the number of different units in the sample. In this case, the variance would be zero. Number of diff units here needs be individuals, but groups of units that share all relevant characteristics\nThe mean outcome of the sample is denoted \\(\\bar{x}\\); that of the population, \\(\\mu\\).\n\nRepeated sampling creates a [Sampling distribution]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Statistics foundations</span>"
    ]
  },
  {
    "objectID": "chapters/stats_foundations.html#selection-bias",
    "href": "chapters/stats_foundations.html#selection-bias",
    "title": "7  Statistics foundations",
    "section": "7.4 Selection bias",
    "text": "7.4 Selection bias\nCommon types of selection bias in data science: - The vast search effect (using the data to answer many questions will eventually reveal something interesting by mere chance – if 20,000 people flip a coin 10 times, some will have 10 straight heads) - Nonrandom sampling - Cherry-picking data - Selecting specific time-intervals - Stopping experiments prematurely - Regression to the mean (occurs in settings where we measure outcomes repeatedly over time and where luck and skill combine to determine outcomes, since winners of one period will be less lucky next period and perform closer to the mean performer)\nWays to guard against selection bias: - have one or many holdout datasets to confirm your results.\n\n7.4.1 Sampling distribution\n\nA sampling distribution is the distribution of a statistic (e.g. the mean) over many repeated samples. Classical statistics is much concerned with making inferences from samples about the population based on such statistics.\nWhen we measure an attribute of the population based on a sample using a statistic, the result will vary over repeated samples. To capture by how much it varies, we are concerned with the sampling variability.\nKey distinctions:\n\nThe data distribution is the distribution of the data in the sample, and its spread is measured by the variance or its square root, the standard deviation.\nThe sampling distribution is the distribution of the sample statistic, and its spread is measured by the sampling variance or its square root, the standard error.\n\nPlots below show that:\n\nData distribution has larger spread than sampling distributions (each data point is a special case of a sample with n = 1)\nThe spread of sampling distributions decreases with increasing sample size\n\n\nrng = np.random.default_rng(2312)\n\n\ndef means(data, sample_size, num_means=1000):\n    return rng.choice(data, (sample_size, num_means)).mean(0)\n\n\n# Create dataset with population and sample data\ndata = pd.DataFrame({\"Population\": rng.normal(size=1_000_000)})\nfor n in [10, 100, 1000]:\n    data = data.join(\n        pd.Series(means(data.Population, n), name=f\"Means of samples of {n}\")\n    )\ndata = data.melt()\n\n\ng = sns.FacetGrid(data, col=\"variable\")\ng.map(sns.histplot, \"value\", bins=40, stat=\"percent\")\ng.set_axis_labels(\"Value\", \"Count\")\ng.set_titles(\"{col_name}\");\n\n\n7.4.2 Variance and standard error\n\nThe standard error is a measure for the variability of the sampling distribution.\nIt is related to the standard deviation of the observations, \\(\\sigma\\) and the sample size \\(n\\) in the following way:\n\n\\[\nse = \\frac{\\sigma}{\\sqrt{n}}\n\\] - The relationship between sample size and se is sometimes called the “Square-root of n rule”, since reducing the \\(se\\) by a factor of 2 requires an increase in the sample size by a factor of 4.\nDerivation:\nThe sum of a sequence of independent random variables is: \\[\nT = (x_1 + x_2 + ... + x_n)\n\\]\nWhich has variance\n\\[\nVar(T) = Var(x_1) + Var(x_2) + ... + Var(x_n) = n\\sigma^2\n\\]\nand mean\n\\[\n\\bar{x} = T/n.\n\\]\nThe variance of \\(\\bar{x}\\) is then given by:\n\\[\nVar(\\bar{x}) = Var\\left(\\frac{T}{n}\\right) = \\frac{1}{n^2}Var(T) = \\frac{1}{n^2}n\\sigma^2 = \\frac{\\sigma^2}{n}.\n\\]\nThe standard error is defined as the standard deviation of \\(\\bar{x}\\), and is thus\n\\[\nse(\\bar{x}) = \\sqrt{Var(\\bar{x})} = \\frac{\\sigma}{\\sqrt{n}}.\n\\]\n\n\n7.4.3 Example code\n\nrng = np.random.default_rng(2312)\n\ndef means(data, sample_size, num_means=1000):\n    return rng.choice(data, (sample_size, num_means)).mean(0)\n\n  \n# Create dataset with population and sample data\n\ndata = pd.DataFrame({\"Population\": rng.normal(size=1_000_000)})\n\nfor n in [10, 100, 1000]:\n    data = data.join(\n        pd.Series(means(data.Population, n),\n        name=f\"Means of samples of {n}\")\n    )\n\ndata = data.melt()\n\ng = sns.FacetGrid(data, col=\"variable\")\ng.map(sns.histplot, \"value\", bins=40, stat=\"percent\")\ng.set_axis_labels(\"Value\", \"Count\")\ng.set_titles(\"{col_name}\");\nFigure shows that:\n\nThe spread of sampling distributions decreases with increasing sample size\nData distribution has larger spread than sampling distributions (each data point is a special case of a sample with n = 1)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Statistics foundations</span>"
    ]
  },
  {
    "objectID": "chapters/stats_foundations.html#law-of-large-numbers-and-central-limit-theorems",
    "href": "chapters/stats_foundations.html#law-of-large-numbers-and-central-limit-theorems",
    "title": "7  Statistics foundations",
    "section": "7.5 Law of large numbers and central limit theorems",
    "text": "7.5 Law of large numbers and central limit theorems\n\nSuppose that we have a sequence of independent and identically distributed (iid) random variables \\(\\{x_1, ..., x_n\\}\\) drawn from a distribution with expected value \\(\\mu\\) and finite variance \\(\\sigma^2\\), and we are interested in the mean value \\(\\bar{x} = \\frac{x_1 + ... + x_n}{n}\\).\nThe law or large numbers states that \\(\\bar{x}\\) converges to \\(\\mu\\) as we increase the sample size. Formally:\n\n\\[\n\\bar{x} \\rightarrow \\mu \\text{ as } n \\rightarrow \\infty.\n\\]\n\nThe (classical, Lindeberg-Lévy) central limit theorem describes the spread of the sampling distribution of \\(\\bar{x}\\) around \\(\\mu\\) during this convergence. In particular, it implies that for large enough \\(n\\), the distribution of \\(\\bar{x}\\) will be close to a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2/n\\). The above figures are a visual representation of this. Formally:\n\n\\[\n\\lim _{n\\to\\infty} \\sqrt{n}(\\bar{x} - \\mu) \\rightarrow \\mathcal{N}\\left(0,\\sigma ^{2}\\right).\n\\]\n\nThis is useful because it means that irrespective of the underlying distribution (i.e. the distribution of the values in our sequence above), we can use the normal distribution and approximations to it (such as the t-distribution) to calculate sampling distributions when we do inference. Because of this, the CLT is at the heart of the theory of hypothesis testing and confidence intervals, and thus of much of classical statistics.\nFor experiments, this means that our estiamted treatment effect is normally distributed, which is what allows us to draw inferences from our experimental setting ot the population as a whole. The CLT is thus at the heart of the experimental approach.\nThe CLT also explains the prevalence of the normal distribution in the natural world. Many characteristics of living things we observe and measure are the sum of the additive effects of many genetic and environmental factors, so their distribution tends to be normal.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Statistics foundations</span>"
    ]
  },
  {
    "objectID": "chapters/stats_foundations.html#degrees-of-freedom",
    "href": "chapters/stats_foundations.html#degrees-of-freedom",
    "title": "7  Statistics foundations",
    "section": "7.6 Degrees of freedom",
    "text": "7.6 Degrees of freedom\nIn statistics, degrees of freedom generally refers to the number of values in a calculation that can vary freely.\nExamples:\n\nVariance calculation: given that we have a mean, once we know all but one value, we also know final value, since sum of mean deviations has to be zero.\nCovariance calculation: given the two means, once we know the values for all but one x and y pair, we also know the values of the final pair. Hence, we loose one df (not clear to me why not two, given that both x and y are determined – because we treat their product as a single value? but that seems arbitrary)\nAlso, why no correction when we have popultion means? See wikipedia article on variance for section on bias correction\nThere is lots of confusion out there when it comes to df. For instance, you sometimes hear people say that df is the number of parameters you had to calculate on route. But this is wrong. It happens to come to the same when calculating variance, but not if you calcualte covariance (where you calculate two means beforehand, but only loose one df).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Statistics foundations</span>"
    ]
  },
  {
    "objectID": "chapters/stats_foundations.html#the-bootstrap",
    "href": "chapters/stats_foundations.html#the-bootstrap",
    "title": "7  Statistics foundations",
    "section": "7.7 The bootstrap",
    "text": "7.7 The bootstrap\n\nIn practice, we often use the bootstrap to calculate standard errors of model parameters or statistics.\nConceptually, the bootstrap works as follows:\n\n\nwe draw an original sample and calculate our statistic\nwe then create a blown-up version of that sample by duplicating it many times\nwe then draw repeated samples from the large sample, recalculate our statistic, and calculate the standard deviation of these statistics to get the standard error.\n\n\nTo achieve this easily, we can skip step 2) by simply sampling with replacement from the original distribution in step 3).\nThe full procedure makes clear what the bootstrap results tell us, however: they tell us how lots of additional samples would behave if they were drawn from a population like our original sample.\nHence, if the original sample is not representative of the population of interest, then bootstrap results are not informative about that population either.\nThe bootstrap can also be used to improve the performance of classification or regression trees by fitting multiple trees on bootstrapped sample and then averaging their predictions. This is called “bagging”, short for “bootstrap aggregating”.\nWe can use to boostrap also to calculate CIs following this algorithm:\n\n\nDraw a large number of bootstrap samples and calculate the statistic of interest\nTrim [(100-x)/2] percent of the bootstrap results on either end of the distribution\nThe trim points are the end point of the CI.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Statistics foundations</span>"
    ]
  },
  {
    "objectID": "chapters/stats_foundations.html#combination-vs-permutation",
    "href": "chapters/stats_foundations.html#combination-vs-permutation",
    "title": "7  Statistics foundations",
    "section": "7.8 Combination vs Permutation",
    "text": "7.8 Combination vs Permutation\nPermutation (Order Matters)\nIf we have \\(n\\) items and we want to pick \\(r\\) in a specific order, the formula is:\n\\[\nP(n, r) = \\frac{n!}{(n - r)!}\n\\] Example: Arranging 3 letters (A, B, C) in 2 positions.\n- Possible orders: AB, AC, BA, BC, CA, CB → 6 ways\n- Formula:\n\\[\n  P(3,2) = \\frac{3!}{(3 - 2)!} = \\frac{3!}{1!} = \\frac{3 \\times 2 \\times 1}{1} = 6\n  \\]\nCombination (Order Doesn’t Matter)\nIf we have \\(n\\) items and we want to pick \\(r\\), but order does not matter, the formula is:\n\\[\nC(n, r) = \\frac{n!}{r!(n - r)!}\n\\]\nExample:\nChoosing 2 letters from (A, B, C), where order does not matter.\n- Possible groups: {A, B}, {A, C}, {B, C} → 3 ways\n- Formula:\n\\[\n  C(3,2) = \\frac{3!}{2!(3 - 2)!} = \\frac{3!}{(2! \\times 1!)} = \\frac{3 \\times 2 \\times 1}{(2 \\times 1) \\times 1} = 3\n  \\]\nKey Difference: - Permutation: ABC and BAC are different\n- Combination: ABC and BAC are the same\nShortcut:\n\\[\nP(n, r) = C(n, r) \\times r!\n\\]\n(Since for every combination, there are \\(r!\\) ways to arrange it.)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Statistics foundations</span>"
    ]
  },
  {
    "objectID": "chapters/stats_foundations.html#moments-of-random-variables",
    "href": "chapters/stats_foundations.html#moments-of-random-variables",
    "title": "7  Statistics foundations",
    "section": "7.9 Moments of random variables",
    "text": "7.9 Moments of random variables\nIn general, the kth uncentered moment of a discrete random variable X is defined by\n\\[\nE(X^k) = \\sum_{i=1}^n p(x_i)x_i^k,\n\\]\nand the kth centered moment as\n\\[\nE\\left(X-E(X)\\right)^k = \\sum_{i=1}^n p(x_i)(x_i - \\mu)^k,\n\\]\nHence, the mean of a random variable is the first uncentered momement, and the variance is the second centered moment.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Statistics foundations</span>"
    ]
  },
  {
    "objectID": "chapters/stats_foundations.html#variance-and-covariance-properties",
    "href": "chapters/stats_foundations.html#variance-and-covariance-properties",
    "title": "7  Statistics foundations",
    "section": "7.10 Variance and covariance properties",
    "text": "7.10 Variance and covariance properties\nBuilding blocks for advanced manipulations.\n\\[\n\\begin{align}\nVar(X + c) &= Var(X) \\\\\nVar(X + Y + c) &= Var(X + Y)\n\\end{align}\n\\]\nAdd here covariance properties that show that\ncov(X + a, Y + b) = cov(X ,Y)\n$$ \\[\\begin{align}\nCov(\\bar{c}, \\bar{d})\n\n&=\\mathbb{E}\\left[(\\bar{c} - \\mathbb{E}[\\bar{c}])\n(\\bar{d} - \\mathbb{E}[\\bar{d}])\\right]\n&\\text{}\n\\\\[5pt]\n\n&=\\mathbb{E}\\left[\n\\bar{c}\\bar{d}\n- \\mathbb{E}[\\bar{d}]\\bar{c}\n- \\mathbb{E}[\\bar{c}]\\bar{d}\n+ \\mathbb{E}[\\bar{c}]\\mathbb{E}[\\bar{d}]\n\\right]\n&\\text{}\n\\\\[5pt]\n\n&=\n\\mathbb{E}\\left[\\bar{c}\\bar{d}\\right]\n- \\mathbb{E}[\\bar{d}]\\mathbb{E}[\\bar{c}]\n- \\mathbb{E}[\\bar{c}]\\mathbb{E}[\\bar{d}]\n+ \\mathbb{E}[\\bar{c}]\\mathbb{E}[\\bar{d}]\n&\\text{}\n\\\\[5pt]\n\n&=\\mathbb{E}\\left[\\bar{c}\\bar{d}\\right] - \\mathbb{E}[\\bar{c}]\\mathbb{E}[\\bar{d}]\n&\\text{}\n\\\\[5pt]\n\\end{align}\\] $$\nIn general:\n\\[\n\\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y] + \\text{Cov}(X, Y)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Statistics foundations</span>"
    ]
  },
  {
    "objectID": "chapters/stats_foundations.html#confidence-intervals",
    "href": "chapters/stats_foundations.html#confidence-intervals",
    "title": "7  Statistics foundations",
    "section": "7.11 Confidence intervals",
    "text": "7.11 Confidence intervals\n\nA CI is another way to learn about the variability of a test statistic.\nIt can be calculated using the (standard) normal distribution or the t-distribution (if sample sizes are small).\nBut for data science purposes we can compute an x-percent CI from the bootstrap, following this algorithm: 1) Draw a large number of bootstrap samples and calculate the statistic of interest, 2) Trim [(100-x)/2] percent of the bootstrap results on either end of the distribution, 3) the trim points are the end point of the CI.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Statistics foundations</span>"
    ]
  },
  {
    "objectID": "chapters/stats_foundations.html#commonly-used-distributions",
    "href": "chapters/stats_foundations.html#commonly-used-distributions",
    "title": "7  Statistics foundations",
    "section": "7.12 Commonly used distributions",
    "text": "7.12 Commonly used distributions\nfrom here\n\n7.12.1 Commonly used probability distributions\nThe following table lists the variance for some commonly used probability distributions.\nName of the probability distribution | Probability distribution function | Mean | Variance |\n|————————————–|———————————–|——|———-|\nBinomial distribution | \\(\\Pr\\,(X=k) = \\binom{n}{k}p^k(1 - p)^{n-k}\\) | \\(np\\) | \\(np(1 - p)\\) |\nGeometric distribution | \\(\\Pr\\,(X=k) = (1 - p)^{k-1}p\\) | \\(\\frac{1}{p}\\) | \\(\\frac{1 - p}{p^2}\\) |\nNormal distribution | \\(f(x \\mid \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\\) | \\(\\mu\\) | \\(\\sigma^2\\) |\nUniform distribution (continuous) | \\(f(x \\mid a, b) = \\begin{cases} \\frac{1}{b - a} & \\text{for } a \\le x \\le b, \\\\[3pt] 0 & \\text{for } x &lt; a \\text{ or } x &gt; b \\end{cases}\\) | \\(\\frac{a + b}{2}\\) | \\(\\frac{(b - a)^2}{12}\\) |\nExponential distribution | \\(f(x \\mid \\lambda) = \\lambda e^{-\\lambda x}\\) | \\(\\frac{1}{\\lambda}\\) | \\(\\frac{1}{\\lambda^2}\\) |\nPoisson distribution | \\(f(k \\mid \\lambda) = \\frac{e^{-\\lambda}\\lambda^{k}}{k!}\\) | \\(\\lambda\\) | \\(\\lambda\\) |",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Statistics foundations</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html",
    "href": "chapters/faqs.html",
    "title": "12  FAQs",
    "section": "",
    "text": "12.1 Q1\nWhy do we need potential outcomes at all? Can’t we interpret the difference from a simple comparison of averages as the causal effect?\nWhy potential outcomes? - Clarifies what precisely we are trying to estimate: average individual treatment effect - Makes explicit the assumptions we need to make to do so: - SUTVA: What we need is to be able to write Y-i = WY1 + (1-W)Y0. For this we need i) independence from other’s assignment, and ii) clearly defined meaning of Wi =1 and Wi = 0, because if they are not clearly defined then Y1/Y0 might not be stable. SUTVA handles both of these. - Randomisation: to make sure that EY0 for W=1 equals EY0 W=0 Material - ding2023first footnote 2 in chapter 4 and\nIn the classic two-sample problem, observations in the treatment group {y1s} and control group {y0s} are assumed to be IID draws from two separate distributions. Treatment observations are assumed to be IID draws from a distribution with mean \\(\\mu_t\\) and variance \\(\\sigma_t^2\\) and similar for control, and the variance of the difference in means estimator is given by:\n\\[\n\\mathbb{V}(\\hat{\\tau}) = \\frac{\\sigma_t^2}{n_t} + \\frac{\\sigma_c^2}{n_c}.\n\\] That is, there is no third term for the variance of the individual-level potential outcomes.\nIn contrast, Rubin points out that for proper causal inference, {y1, y0} pairs are from the same distribution but we observe only one item of the pair.\nDifferences: - Sampling based vs randomisation based variation: makes sense given that in IID case we are assumed to sample from population, whereas in FS case we are assumed to have all units, but randomise which item of the PO pair is observed. - Hence: the variance in IID is taken over the randomness of the outcomes because uncertainty is sampling based, whereas in the potential outcomes framework, where potential outcomes are fixed, the variance is taken over the randomisation distribution. - As a result: there is no correlation between two groups in IID case (covar = 0) and hence no third term, whereas in FS case there is – why precisely? Because there is correlation between y1s and y2s – if there isn’t, then the third term vanishes. See ding derivation. However, ultimately it’s because there is heterogeneity in individual-level treatment effects. Why is that? Is that the same as PO correlation at individual level? - Weird, though, that Ding lemmas seem to be based on IID case!",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#questions",
    "href": "chapters/faqs.html#questions",
    "title": "9  FAQs",
    "section": "",
    "text": "9.1.1 Q1\nWhy do we need potential outcomes at all? Can’t we interpret the difference from a simple comparison of averages as the causal effect?\n\n\n9.1.2 Q2\nWhy do randomised trials not require the excludability assumption in order to lead to unbiased results?",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#answers",
    "href": "chapters/faqs.html#answers",
    "title": "9  FAQs",
    "section": "9.2 Answers",
    "text": "9.2 Answers\n\n9.2.1 A1\nWhy potential outcomes? - Clarifies what precisely we are trying to estimate: average individual treatment effect - Makes explicit the assumptions we need to make to do so: - SUTVA: What we need is to be able to write Y-i = WY1 + (1-W)Y0. For this we need i) independence from other’s assignment, and ii) clearly defined meaning of Wi =1 and Wi = 0, because if they are not clearly defined then Y1/Y0 might not be stable. SUTVA handles both of these. - Randomisation: to make sure that EY0 for W=1 equals EY0 W=0 Material - ding2023first footnote 2 in chapter 4 and\n\nWhat is definition of causal effect in suggested comparison?\nWhat is source of randomisation?\nDiscuss textbook iid approach and why it’s not a good model for our purpose.\nShow that in practice, variance is the same\n\nIn the classic two-sample problem, observations in the treatment group {y1s} and control group {y0s} are assumed to be IID draws from two separate distributions. Treatment observations are assumed to be IID draws from a distribution with mean \\(\\mu_t\\) and variance \\(\\sigma_t^2\\) and similar for control, and the variance of the difference in means estimator is given by:\n\\[\n\\mathbb{V}(\\hat{\\tau}) = \\frac{\\sigma_t^2}{n_t} + \\frac{\\sigma_c^2}{n_c}.\n\\] That is, there is no third term for the variance of the individual-level potential outcomes.\nIn contrast, Rubin points out that for proper causal inference, {y1, y0} pairs are from the same distribution but we observe only one item of the pair.\nDifferences: - Sampling based vs randomisation based variation: makes sense given that in IID case we are assumed to sample from population, whereas in FS case we are assumed to have all units, but randomise which item of the PO pair is observed. - Hence: the variance in IID is taken over the randomness of the outcomes because uncertainty is sampling based, whereas in the potential outcomes framework, where potential outcomes are fixed, the variance is taken over the randomisation distribution. - As a result: there is no correlation between two groups in IID case (covar = 0) and hence no third term, whereas in FS case there is – why precisely? Because there is correlation between y1s and y2s – if there isn’t, then the third term vanishes. See ding derivation. However, ultimately it’s because there is heterogeneity in individual-level treatment effects. Why is that? Is that the same as PO correlation at individual level? - Weird, though, that Ding lemmas seem to be based on IID case!\n\n\n9.2.2 A2\n…",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/power.html#what-is-power-and-how-do-we-measure-it",
    "href": "chapters/power.html#what-is-power-and-how-do-we-measure-it",
    "title": "7  Power",
    "section": "",
    "text": "Power is defined as\n\n\n\n\nCohen (1977) proposes estimated effect size / standard deviation of outcome. This is useful to compare effects across studies and domains.\nBloom (1985) proposes MDE, useful for within study/domain comparisons. More directly interpretable.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Power</span>"
    ]
  },
  {
    "objectID": "chapters/hypothesis_testing.html",
    "href": "chapters/hypothesis_testing.html",
    "title": "6  Hypothesis testing",
    "section": "",
    "text": "6.1 Types of errors\nWith the above proceedure, there are two types of mistakes we can make:\nProvide detail of Neyman approach/insight (cannot control these for single experiment, but can control in the long-run over many experiments). Implications: how to interpret (and not interpret test results).\nThe complements of these two errors are:\nThe false discovery rate",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapters/hypothesis_testing.html#types-of-errors",
    "href": "chapters/hypothesis_testing.html#types-of-errors",
    "title": "6  Hypothesis testing",
    "section": "",
    "text": "We can reject \\(H_O\\) when it is true. This is called a Type I error and leads to a false positive. The probability of this type of error is denoted \\(\\alpha\\).\nWe can fail to reject \\(H_0\\) when it is false. This is called a Type II error and leads to a false negative. The probability of this type of error is denoted \\(\\beta\\).\n\n\n\n\nThe confidence level, the probability that we do not reject \\(H_O\\) if it is false – the probebility of a true negative – given by \\(1 - \\alpha\\).\nPower, the probability that we do reject \\(H_O\\) if it is false – the probability of a true positive – given by \\(1 - \\beta\\).\n\n\n\nThe false positive rate is \\(P(significant result | H0 true)\\)\nThe false discovery rate is \\(P(H0 true | significant result)\\)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapters/hypothesis_testing.html#hypothesis-testing",
    "href": "chapters/hypothesis_testing.html#hypothesis-testing",
    "title": "6  Hypothesis testing",
    "section": "6.2 Hypothesis testing",
    "text": "6.2 Hypothesis testing\nTo test whether the observed treatment effect is significantly different from zero, we test:\n\\[\n\\begin{align}\n&H_0: \\tau = 0 \\\\[5 pt]\n&H_A: \\tau \\neq 0\n\\end{align}\n\\]\nWe calculate the test-statistic\n\\[\nT =\n\\frac{\\hat{\\tau}^{\\text{dm}}}\n{SE\\left(\\hat{\\tau}^{\\text{dm}}\\right)} \\sim t_{(N_t + N_c - 2)},\n\\]\nwhere \\(N_t + N_c - 2\\) is number of degrees of freedom.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapters/hypothesis_testing.html#justification-for-use-of-testing-distribution",
    "href": "chapters/hypothesis_testing.html#justification-for-use-of-testing-distribution",
    "title": "6  Hypothesis testing",
    "section": "6.3 Justification for use of testing distribution",
    "text": "6.3 Justification for use of testing distribution\nWhy can we use t/z distribution?\nTo integrate: Note that the test statistic follows a t-distribution because we have to estimate the variance (that is, if we replace the true variance with its estimate when standardising a normal variable, the result follows a Student’s t-distribution). So, this has nothing to do with the CLT. However, for the test statistic to follow a student distribution, the numerator has to follow a normal distribution. Often, though, the underlying data is not normal, so that its approximately normal only for large enough samples, due to the CLT. At the same time, the t-distribution also converges to normal as the sample size increases. Hence, one we have a sample size large enough to justify using the t-distribution, we might as well use a z-test. As pointed out in Chapter 9 in Rice (2006), the test statistic above only follows a t-distribution if we use the pooled variance, but for large sample sizes, the distribution is still approximately t or normal.\n\nSee ding2023first section 4.2 and imbens2015causal section 6.6.1 and 6.6.2 for justification for testing approach\nSee ding2023first pdf page 72 for proof and derivation\nSee Rice 7.3.3\nSee Rice 6.2 on why this follows t distribution\nFor complete treatment and derivation of sampling distributions (incl. discussion of all the approximations and sample corrections), see Rice sampling chapter and my ipad notes.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapters/hypothesis_testing.html#understanding-p-values",
    "href": "chapters/hypothesis_testing.html#understanding-p-values",
    "title": "6  Hypothesis testing",
    "section": "6.4 Understanding P-values",
    "text": "6.4 Understanding P-values\n\n6.4.1 History of the P-value\n\nThere are two schools of thought in statistical significance testing.\nR.A. Fisher thought of the p-value as a useful metric to determine how surprising a given set of data was.\nJerzy Neyman and Egon Pearson realised that while it is not possible to eliminate false positives and negatives, it is possible to set up a process that guarantees that false positives occur only at a pre-defined rate, which they called \\(\\alpha\\).\nUnlike in Fisher’s approach, the p-value in the Neyman-Pearson approach doesn’t tell us anything about the strength of the evidence in any particular experiment besides whether or not to reject the null hypothesis, but guarantees that in the long run (over the course of many experiments), our false positive rate is not larger than \\(\\alpha\\). :::\n\n\n\n6.4.2 The base-rate fallacy\nSuppose you test 100 features out of which 10 have a true effect. If you have 80 percent power and use a 5 percent significance level. You can expect to get a significant result for 8 of the 10 working features, but you also have a false positive rate of 5%, so you’ll also get a significant result for about 5 non-working features. You thus end up with 13 treatments that appear to work. But we know that only 8 of these 13, or 62% of them work, while the remaining 5 are false discoveries. Thus, you have a false discovery rate of 38%.\nYou commit the base-rate fallacy when you confuse your p-value with your false discovery rate. This would lead you to make statements such as “My p-value is 0.002, so there is only a 2 in a 1000 chance that I found my result by chance!”\nThis confuses\n\\[\nP(significant result | H_0),\n\\]\nthe p-value, with\n\\[\nP(H_A | significant result)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapters/hypothesis_testing.html#limitations-of-hypothesis-testing",
    "href": "chapters/hypothesis_testing.html#limitations-of-hypothesis-testing",
    "title": "6  Hypothesis testing",
    "section": "6.5 Limitations of hypothesis testing",
    "text": "6.5 Limitations of hypothesis testing\n\np-values do not tell you anything about whether the result has any practical significance.\nAny intervention usually has some effect, you will always find a significant result with enough data. The question is whether the range of plausible effect sizes (captured by the confidence interval) is relevant.\nArbitrary cutoff\nNo appreciation for variation of coefficient – focus on ci instead (see Romer (2020), Imbens (2021))\nMultiple hypothesis testing (actual) – report and apply MHT-correction\nMultiple hypothesis testing (potential Gelman post)\nMHT: family-wise error rate vs false discovery rate",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapters/hypothesis_testing.html#confidence-intervals",
    "href": "chapters/hypothesis_testing.html#confidence-intervals",
    "title": "6  Hypothesis testing",
    "section": "6.6 Confidence intervals",
    "text": "6.6 Confidence intervals\n\nRely on confidence intervals: they provide the same information as a p-value (if they include the value of the null hypothesis then we cannot reject it) but the width of the interval also provides additional information on the uncertainty of the effect and its practical significance. (See In Praise of Confidence Intervals by David Romer and Statistical Significance, p-Values, and the Reporting of Uncertainty by Guido Imbens for more).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapters/hypothesis_testing.html#testing-and-ci-duality",
    "href": "chapters/hypothesis_testing.html#testing-and-ci-duality",
    "title": "6  Hypothesis testing",
    "section": "6.7 Testing and CI duality",
    "text": "6.7 Testing and CI duality",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapters/hypothesis_testing.html#one-sides-vs-two-sided-tests",
    "href": "chapters/hypothesis_testing.html#one-sides-vs-two-sided-tests",
    "title": "6  Hypothesis testing",
    "section": "6.8 One-sides vs two-sided tests",
    "text": "6.8 One-sides vs two-sided tests\n\nInstacard uses one-sided because they focus on improvements (hesterberg2024power section 2)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapters/hypothesis_testing.html#multivariant-tests",
    "href": "chapters/hypothesis_testing.html#multivariant-tests",
    "title": "6  Hypothesis testing",
    "section": "6.9 Multivariant tests",
    "text": "6.9 Multivariant tests",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapters/hypothesis_testing.html#multiple-hypothesis-correction",
    "href": "chapters/hypothesis_testing.html#multiple-hypothesis-correction",
    "title": "6  Hypothesis testing",
    "section": "6.10 Multiple hypothesis correction",
    "text": "6.10 Multiple hypothesis correction\n\nSee BIT blue book 4.3 for nice explanation of BH MHT correction\n\n\n\n\n\n\nImbens, Guido W. 2021. “Statistical Significance, p-Values, and the Reporting of Uncertainty.” Journal of Economic Perspectives 35 (3): 157–74.\n\n\nRice, John A. 2006. Mathematical Statistics and Data Analysis. Cengage Learning.\n\n\nRomer, David. 2020. “In Praise of Confidence Intervals.” In AEA Papers and Proceedings, 110:55–60.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapters/hypothesis_testing.html#qa",
    "href": "chapters/hypothesis_testing.html#qa",
    "title": "3  Hypothesis testing",
    "section": "3.11 Q&A",
    "text": "3.11 Q&A\nQuestions\n\n\n\n\nA student is asked 12 true-or-false questions and gets 3 of them wrong. What is the probability that the student guessed randomly?\nThe student above would actually have been asked questions until they got 3 wrong. What is the probability that they guessed randomly?\n\nc)What do you conclude from a) and b)?\n\n\n\nConsider the outcome of a large sample size (e.g. 10K subjects) A/B test that yielded tiny (e.g. odds ratio of 1.0008) but statistically significant (e.g. p &lt; 0.001) results. Would you deploy the change to production. Why or why not?\n\n\n\nA researcher runs an experiment, gets a p-value of 0.033, and concludes that his false positive rate is 3.3 percent. Is that correct? Why or why not?\n\n\n\nWhy don’t we include MDE in our hypothesis statement (i.e. “a will increase b by at least MDE for target population”)? Wouldn’t that be a good idea in a business context where we strongly care about an MDE? Don’t we just not do that because academics, who developed the methods, don’t usually care about an effect being of a certain size but only about learning what the effect is?\n\n\n\nThe 95% CI for control and treatment overlap. Does this imply treatment is not significant?\nAnswers\n1\n\nCalculate p-value for getting no more than observed number of errors\n\np = stats.binom.cdf(k=3, n=12, p=0.5)\nprint(f\"p-value is: {p:.3f}\")\n2\n3\nNo. An individual experiment doesn’t have a false positive rate. The false positive rate is determined by the proceedure used for experiments over the long run. For example, if you consistently use a p-value of 0.05, then you are guaranteed to have a false positive rate of 5 percent in the long run. This is the main insight underlying the Neyman-Pearson hypothesis testing framework.\n\n\n\nIncluding the MDE’s in the hypothesis would be incorrect. Why? Because what we formulate is the alternative hypothesis. Without altering the null hypothesis, which traditionally states the effect is zero, our two hypotheses would not be complete (H0 testing effect different from 0, HA asserting that effect is at least MDE means rejecting H0 would not imply support of HA). So why not adapt H0, too? Because the hypothesis is the thing we test when we calculate our test statistic (duh!), and so if included the MDE in the hypothesis formulation, then we’d have to include it in the calculation of the test statistic (subtract it from the observed difference), which would be incorrect. Why? The question confused the MDE with the effect size under the Null hypothesis, which are conceptually different things: the MDE is the smallest effect size we want to detect – we are interested in effects that are as large or larger than the MDES, we’re not testing whether the observed difference is significantly different from it, which is what the null hypothesis value is.\n\n\n\n\nImbens, Guido W. 2021. “Statistical Significance, p-Values, and the Reporting of Uncertainty.” Journal of Economic Perspectives 35 (3): 157–74.\n\n\nRice, John A. 2006. Mathematical Statistics and Data Analysis. Cengage Learning.\n\n\nRomer, David. 2020. “In Praise of Confidence Intervals.” In AEA Papers and Proceedings, 110:55–60.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#qa",
    "href": "chapters/faqs.html#qa",
    "title": "9  FAQs",
    "section": "9.8 Q&A",
    "text": "9.8 Q&A\nQuestions:\n\nLonger experiment duration generally increases power. Can you think of a scenario where this is not the case?\nAn online shopping site ranks products according to their average rating. Why might this be suboptimal? What could the site do instead?\n\nAnswers:\n\nWhen using a cumulative metric such as number of likes, the variance of which will increase the longer the experiment runs, which will increase the standard error of our treatment effect estimate and lower our power. Remember that \\(SE(\\hat{\\tau}) = \\sqrt{\\frac{1}{P(1-P)}\\frac{\\sigma^2}{N}}\\). So, whether this happens depends on what happens to \\(\\frac{\\sigma^2}{N}\\), as experiment duration increases. A decrease in power is plausible – likely, even! – because \\(N\\) will increase in a concave fashion over the course of the experiment duration (some users keep coming back), while \\(\\sigma^2\\) is likely to grow faster than linearly, which causes the ratio to increase and power to decrease.\nThe approach is suboptimal because products with few ratings will have much more variance than products with many ratings, and their average rating is thus less reliable. The problem is akin to small US states having the highest and lowest rates of kidney cancer, or small schools having highest and lowest average pupil performance. Fundamentally, it’s a problem of low power – the sample size is too low to reliably detect a true effect. The solution is to use a shrinkage method: use a weighted average of the product average rating and some global product rating, with the weight of the product average rating being proportional to the number of ratings. This way, products with few ratings will be average, while products with many ratings will reflect their own rating.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#q1",
    "href": "chapters/faqs.html#q1",
    "title": "12  FAQs",
    "section": "",
    "text": "What is definition of causal effect in suggested comparison?\nWhat is source of randomisation?\nDiscuss textbook iid approach and why it’s not a good model for our purpose.\nShow that in practice, variance is the same",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#q2",
    "href": "chapters/faqs.html#q2",
    "title": "12  FAQs",
    "section": "12.2 Q2",
    "text": "12.2 Q2\nWhy do randomised trials not require the excludability assumption in order to lead to unbiased results?",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#section",
    "href": "chapters/faqs.html#section",
    "title": "9  FAQs",
    "section": "9.5 ",
    "text": "9.5 \nA researcher runs an experiment, gets a p-value of 0.033, and concludes that his false positive rate is 3.3 percent. Is that correct? Why or why not?\nNo. An individual experiment doesn’t have a false positive rate. The false positive rate is determined by the proceedure used for experiments over the long run. For example, if you consistently use a p-value of 0.05, then you are guaranteed to have a false positive rate of 5 percent in the long run. This is the main insight underlying the Neyman-Pearson hypothesis testing framework.\n\n\n\nWhy don’t we include MDE in our hypothesis statement (i.e. “a will increase b by at least MDE for target population”)? Wouldn’t that be a good idea in a business context where we strongly care about an MDE? Don’t we just not do that because academics, who developed the methods, don’t usually care about an effect being of a certain size but only about learning what the effect is?\n\n\n\nThe 95% CI for control and treatment overlap. Does this imply treatment is not significant?\nAnswers\n1\n2\n3\n\n\n\nIncluding the MDE’s in the hypothesis would be incorrect. Why? Because what we formulate is the alternative hypothesis. Without altering the null hypothesis, which traditionally states the effect is zero, our two hypotheses would not be complete (H0 testing effect different from 0, HA asserting that effect is at least MDE means rejecting H0 would not imply support of HA). So why not adapt H0, too? Because the hypothesis is the thing we test when we calculate our test statistic (duh!), and so if included the MDE in the hypothesis formulation, then we’d have to include it in the calculation of the test statistic (subtract it from the observed difference), which would be incorrect. Why? The question confused the MDE with the effect size under the Null hypothesis, which are conceptually different things: the MDE is the smallest effect size we want to detect – we are interested in effects that are as large or larger than the MDES, we’re not testing whether the observed difference is significantly different from it, which is what the null hypothesis value is.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#q3",
    "href": "chapters/faqs.html#q3",
    "title": "12  FAQs",
    "section": "12.3 Q3",
    "text": "12.3 Q3\na) A student is asked 12 true-or-false questions and gets 3 of them wrong. What is the probability that the student guessed randomly?\nb) The student above would actually have been asked questions until they got 3 wrong. What is the probability that they guessed randomly?\nc)What do you conclude from a) and b)?\n\nCalculate p-value for getting no more than observed number of errors\n\np = stats.binom.cdf(k=3, n=12, p=0.5)\nprint(f\"p-value is: {p:.3f}\")",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#q4",
    "href": "chapters/faqs.html#q4",
    "title": "12  FAQs",
    "section": "12.4 Q4",
    "text": "12.4 Q4\nConsider the outcome of a large sample size (e.g. 10K subjects) A/B test that yielded tiny (e.g. odds ratio of 1.0008) but statistically significant (e.g. p &lt; 0.001) results. Would you deploy the change to production. Why or why not?",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#q5",
    "href": "chapters/faqs.html#q5",
    "title": "12  FAQs",
    "section": "12.5 Q5",
    "text": "12.5 Q5\nA researcher runs an experiment, gets a p-value of 0.033, and concludes that his false positive rate is 3.3 percent. Is that correct? Why or why not?\nNo. An individual experiment doesn’t have a false positive rate. The false positive rate is determined by the proceedure used for experiments over the long run. For example, if you consistently use a p-value of 0.05, then you are guaranteed to have a false positive rate of 5 percent in the long run. This is the main insight underlying the Neyman-Pearson hypothesis testing framework.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#q5-1",
    "href": "chapters/faqs.html#q5-1",
    "title": "9  FAQs",
    "section": "9.6 Q5",
    "text": "9.6 Q5\nWhy don’t we include MDE in our hypothesis statement (i.e. “a will increase b by at least MDE for target population”)? Wouldn’t that be a good idea in a business context where we strongly care about an MDE? Don’t we just not do that because academics, who developed the methods, don’t usually care about an effect being of a certain size but only about learning what the effect is?\nIncluding the MDE’s in the hypothesis would be incorrect. Why? Because what we formulate is the alternative hypothesis. Without altering the null hypothesis, which traditionally states the effect is zero, our two hypotheses would not be complete (H0 testing effect different from 0, HA asserting that effect is at least MDE means rejecting H0 would not imply support of HA). So why not adapt H0, too? Because the hypothesis is the thing we test when we calculate our test statistic (duh!), and so if included the MDE in the hypothesis formulation, then we’d have to include it in the calculation of the test statistic (subtract it from the observed difference), which would be incorrect. Why? The question confused the MDE with the effect size under the Null hypothesis, which are conceptually different things: the MDE is the smallest effect size we want to detect – we are interested in effects that are as large or larger than the MDES, we’re not testing whether the observed difference is significantly different from it, which is what the null hypothesis value is.\n\n\n\nThe 95% CI for control and treatment overlap. Does this imply treatment is not significant?\nAnswers\n1\n2\n3",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#q6",
    "href": "chapters/faqs.html#q6",
    "title": "12  FAQs",
    "section": "12.6 Q6",
    "text": "12.6 Q6\nWhy don’t we include MDE in our hypothesis statement (i.e. “a will increase b by at least MDE for target population”)? Wouldn’t that be a good idea in a business context where we strongly care about an MDE? Don’t we just not do that because academics, who developed the methods, don’t usually care about an effect being of a certain size but only about learning what the effect is?\nIncluding the MDE’s in the hypothesis would be incorrect. Why? Because what we formulate is the alternative hypothesis. Without altering the null hypothesis, which traditionally states the effect is zero, our two hypotheses would not be complete (H0 testing effect different from 0, HA asserting that effect is at least MDE means rejecting H0 would not imply support of HA). So why not adapt H0, too? Because the hypothesis is the thing we test when we calculate our test statistic (duh!), and so if included the MDE in the hypothesis formulation, then we’d have to include it in the calculation of the test statistic (subtract it from the observed difference), which would be incorrect. Why? The question confused the MDE with the effect size under the Null hypothesis, which are conceptually different things: the MDE is the smallest effect size we want to detect – we are interested in effects that are as large or larger than the MDES, we’re not testing whether the observed difference is significantly different from it, which is what the null hypothesis value is.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#q",
    "href": "chapters/faqs.html#q",
    "title": "9  FAQs",
    "section": "9.7 Q",
    "text": "9.7 Q\nThe 95% CI for control and treatment overlap. Does this imply treatment is not significant?\nAnswers\n1\n2\n3",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#q7",
    "href": "chapters/faqs.html#q7",
    "title": "12  FAQs",
    "section": "12.7 Q7",
    "text": "12.7 Q7\nThe 95% CI for control and treatment overlap. Does this imply treatment is not significant? …",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#q8",
    "href": "chapters/faqs.html#q8",
    "title": "12  FAQs",
    "section": "12.8 Q8",
    "text": "12.8 Q8\nLonger experiment duration generally increases power. Can you think of a scenario where this is not the case?\nWhen using a cumulative metric such as number of likes, the variance of which will increase the longer the experiment runs, which will increase the standard error of our treatment effect estimate and lower our power. Remember that \\(SE(\\hat{\\tau}) = \\sqrt{\\frac{1}{P(1-P)}\\frac{\\sigma^2}{N}}\\). So, whether this happens depends on what happens to \\(\\frac{\\sigma^2}{N}\\), as experiment duration increases. A decrease in power is plausible – likely, even! – because \\(N\\) will increase in a concave fashion over the course of the experiment duration (some users keep coming back), while \\(\\sigma^2\\) is likely to grow faster than linearly, which causes the ratio to increase and power to decrease.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#qan-online-shopping-site-ranks-products-according-to-their-average-rating.-why-might-this-be-suboptimal-what-could-the-site-do-instead",
    "href": "chapters/faqs.html#qan-online-shopping-site-ranks-products-according-to-their-average-rating.-why-might-this-be-suboptimal-what-could-the-site-do-instead",
    "title": "9  FAQs",
    "section": "9.9 QAn online shopping site ranks products according to their average rating. Why might this be suboptimal? What could the site do instead?",
    "text": "9.9 QAn online shopping site ranks products according to their average rating. Why might this be suboptimal? What could the site do instead?\nAnswers:\n\nWhen using a cumulative metric such as number of likes, the variance of which will increase the longer the experiment runs, which will increase the standard error of our treatment effect estimate and lower our power. Remember that \\(SE(\\hat{\\tau}) = \\sqrt{\\frac{1}{P(1-P)}\\frac{\\sigma^2}{N}}\\). So, whether this happens depends on what happens to \\(\\frac{\\sigma^2}{N}\\), as experiment duration increases. A decrease in power is plausible – likely, even! – because \\(N\\) will increase in a concave fashion over the course of the experiment duration (some users keep coming back), while \\(\\sigma^2\\) is likely to grow faster than linearly, which causes the ratio to increase and power to decrease.\nThe approach is suboptimal because products with few ratings will have much more variance than products with many ratings, and their average rating is thus less reliable. The problem is akin to small US states having the highest and lowest rates of kidney cancer, or small schools having highest and lowest average pupil performance. Fundamentally, it’s a problem of low power – the sample size is too low to reliably detect a true effect. The solution is to use a shrinkage method: use a weighted average of the product average rating and some global product rating, with the weight of the product average rating being proportional to the number of ratings. This way, products with few ratings will be average, while products with many ratings will reflect their own rating.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/faqs.html#q9",
    "href": "chapters/faqs.html#q9",
    "title": "12  FAQs",
    "section": "12.9 Q9",
    "text": "12.9 Q9\nAn online shopping site ranks products according to their average rating. Why might this be suboptimal? What could the site do instead?\nThe approach is suboptimal because products with few ratings will have much more variance than products with many ratings, and their average rating is thus less reliable. The problem is akin to small US states having the highest and lowest rates of kidney cancer, or small schools having highest and lowest average pupil performance. Fundamentally, it’s a problem of low power – the sample size is too low to reliably detect a true effect. The solution is to use a shrinkage method: use a weighted average of the product average rating and some global product rating, with the weight of the product average rating being proportional to the number of ratings. This way, products with few ratings will be average, while products with many ratings will reflect their own rating.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>FAQs</span>"
    ]
  },
  {
    "objectID": "chapters/stats_of_online_experiments.html#section",
    "href": "chapters/stats_of_online_experiments.html#section",
    "title": "2  The stats of online experiments",
    "section": "2.2 ",
    "text": "2.2 \nEach unit has two potential outcomes: \\(Y_i(1)\\) is the outcome for unit \\(i\\) if they are in treatment and \\(Y_i(0)\\) is the outcome if they are in control. To simplify notation, we collect all unit-level potential outcomes in the \\(n \\times 1\\) vectors \\(\\mathbf{Y(1)}\\) and \\(\\mathbf{Y(0)}\\). These outcomes are “potential outcomes” because before the start of the experiment, each unit could be exposed to either treatment condition so that they can potentially experience either outcome. Once the experiment has started and units are assigned to treatment, only one of the two outcomes will be observed.\nThe causal effect of the treatment for unit \\(i\\) is the difference between the two potential outcomes:2 \\[\n\\tau_i = Y_i(1) - Y_i(0).\n\\] Because a unit can only ever be in either treatment or control, we can only ever observe one of the two potential outcomes, which means that directly observing unit-level treatment effects is impossible. This is the fundamental problem of causal inference (Holland 1986).\nAn experiment is one solution to the fundamental problem:3 randomly assigning units from a population to either treatment or control allows us to estimate average (unit-level) treatment effects. In the words of Holland (1986, 947):4\n\n“The important point is that [an experiment] replaces the impossible-to-observe causal effect of [a treatment] on a specific unit with the possible-to-estimate average causal effect of [the treatment] over a population of units.”\n\nHence, instead of trying to observe unit-level causal effects, the quantity of interest – the estimand – in an experiment is an average across a sample of units. In particular, we are usually interested in the effect of a universal policy, a comparison between a state of the world where everyone is exposed to the treatment and one where nobody is. While we can capture the difference between these two states of the world in many different ways, we typically focus on the difference in the averages of all these unit-level causal effects over the entire sample:\n\\[\n\\begin{align}\n\\tau\n= \\frac{1}{n}\\sum_{i=1}^n \\left(Y_i(1) - Y_i(0)\\right)\n= \\frac{1}{n}\\sum_{i=1}^n Y_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0).\n\\end{align}\n\\tag{2.1}\\]\nThis is the estimand, the statistical quantity we are trying to estimate in our experiment.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The stats of online experiments</span>"
    ]
  },
  {
    "objectID": "chapters/stats_of_online_experiments.html#experiment",
    "href": "chapters/stats_of_online_experiments.html#experiment",
    "title": "4  The stats of online experiments",
    "section": "4.2 Experiment",
    "text": "4.2 Experiment\nRunning an experiment with our \\(n\\) units means that we randomly assign some units to treatment and some to control. We use the binary treatment indicator \\(W_i \\in \\{0, 1\\}\\) to indicate treatment exposure for unit \\(i\\) and write \\(W_i = 1\\) if they are in treatment and \\(W_i = 0\\) if they are in control. We collect all unit-level treatment indicators in the \\(n \\times 1\\) vector \\(\\mathbf{W} = (W_1, W_2, \\dots, W_n)'\\). At the end of the experiment, we have \\(n_t = \\sum_{i=1}^n W_i\\) units in treatment and the remaining \\(n_c = \\sum_{i=1}^n (1-W_i)\\) units in control. For each unit, we observe outcome \\(Y_i\\).\nTo estimate \\(\\tau\\), we use the observed difference in means between the treatment and control units:5\n\\[\n\\begin{align}\n\\hat{\\tau}^{\\text{dm}}\n=\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\end{align}\n\\]\nThis is our estimator, the method we use to produce estimates of the estimand.\nThe procedure we use the allocate units to treatment conditions is the assignment mechanism. In online experiments, we typically assign units to treatment conditions dynamically as they visit our site and use an assignment mechanism where the assignment of each unit is determined by a process that is equivalent to a coin-toss, such that \\(P(W_i) = q\\), where \\(q \\in [0, 1]\\). Throughout, I’ll focus on the most common case where \\(q=\\frac{1}{2}\\), so that we have:\n\\[\nP(W_i = 1) = P(W_i = 0) = \\frac{1}{2}.\n\\]\nBecause of their coin-toss-like nature assignments follow a Bernoulli distribution and the type of experiment is called a Bernoulli Randomised Experiment. There are different approaches we could take to formally analyse our experiment. We have to make the following decisions:\n\nWe could either take a superpopulation or fixed sample perspective. Because for all but the largest companies, most online experiments are eventually run on the entire population of interest, I focus on the latter. This means that the goal of our experiment is to estimate the average treatment effect of the treatment on our \\(n\\) units, rather than using the estimate for our \\(n\\) units to infer the average treatment effect on a larger population from which the \\(n\\) units are drawn. I thus use a fully design-based approach (see Chapter 7 for details)\nWe can analyse the Bernoulli Randomised Experiment treating \\(n_t\\) as a Binomial random variable or taking it as given. Because by the time of the analysis it is, in fact, given, I follow the latter approach. This approach also has the advantage of considerably simplifying the math.\n\nImplications:\n\nOur sample of \\(n\\) units and the associated potential outcomes \\(\\mathbf{Y(1)}\\) and \\(\\mathbf{Y(0)}\\) are fixed (because units are non-random but determined by sample I have). I refer to the potential outcomes collectively as \\(\\mathbf{Y(w)} = (\\mathbf{Y(1)}, \\mathbf{Y(0)})\\).\nOnce randomisation is complete the number of units in treatment and control, \\(n_t\\) and \\(n_c\\) are given. I refer to them collectively as \\(\\mathbf{n} = (n_t, n_c)\\).\nThe assignment mechanism is also such that units treatment assignment is independent of the treatment assignment of all other units.\n\nIn the next two sections we show that \\(\\hat{\\tau}^{\\text{dm}}\\) is an unbiased estimator of \\(\\tau\\) and calculate its variance. My approach is based on Ding (2023). For an alternative, see Appendix 6.B. in Imbens and Rubin (2015).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The stats of online experiments</span>"
    ]
  },
  {
    "objectID": "chapters/setup.html",
    "href": "chapters/setup.html",
    "title": "2  Setup",
    "section": "",
    "text": "We study a sample of \\(n\\) units to learn about the effect of a binary treatment on these units. We index units as \\(i = 1, \\dots, n\\).\nThe sample of units might be all visitors to an e-commerce app and the treatment a new UX feature. The treatment is “binary” because we only consider two treatment conditions: a unit either experiences the active treatment and is exposed to the new feature or experiences the control treatment and is exposed to the status-quo. We often refer to the two treatment conditions simply as “treatment” and “control”.\nEach unit has two potential outcomes: \\(Y_i(1)\\) is the outcome for unit \\(i\\) if they are in treatment and \\(Y_i(0)\\) is the outcome if they are in control. To simplify notation, we collect all unit-level potential outcomes in the \\(n \\times 1\\) vectors \\(\\mathbf{Y(1)}\\) and \\(\\mathbf{Y(0)}\\). These outcomes are “potential outcomes” because before the start of the experiment, each unit could be exposed to either treatment condition so that they can potentially experience either outcome. Once the experiment has started and units are assigned to treatment, only one of the two outcomes will be observed.\nThe causal effect of the treatment for unit \\(i\\) is the difference between the two potential outcomes:\n\\[\n\\tau_i = Y_i(1) - Y_i(0).\n\\]\nBecause a unit can only ever be in either treatment or control, we can only ever observe one of the two potential outcomes, which means that directly observing unit-level treatment effects is impossible. This is the fundamental problem of causal inference (Holland 1986).\nAn experiment is one solution to the fundamental problem:[^scientific_solution] randomly assigning units from a population to either treatment or control allows us to estimate average (unit-level) treatment effects. In the words of Holland (1986, 947):[^shortcut]\n\n“The important point is that [an experiment] replaces the impossible-to-observe causal effect of [a treatment] on a specific unit with the possible-to-estimate average causal effect of [the treatment] over a population of units.”\n\nHence, instead of trying to observe unit-level causal effects, the quantity of interest – the estimand – in an experiment is an average across a sample of units. We are usually interested in the effect of a universal policy, a comparison between a state of the world where everyone is exposed to the treatment and one where nobody is. While we can capture the difference between these two states of the world in many different ways, we typically focus on the difference in the averages of all these unit-level causal effects over the entire sample:\n\\[\n\\begin{align}\n\\tau\n= \\frac{1}{n}\\sum_{i=1}^n \\left(Y_i(1) - Y_i(0)\\right)\n= \\frac{1}{n}\\sum_{i=1}^n Y_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0).\n\\end{align}\n\\tag{2.1}\\]\nThis is the estimand, the statistical quantity we are trying to estimate in our experiment.\n\n\n\n\nHolland, Paul W. 1986. “Statistics and Causal Inference.” Journal of the American Statistical Association 81 (396): 945–60.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "chapters/setup.html#footnotes",
    "href": "chapters/setup.html#footnotes",
    "title": "1  Setup",
    "section": "",
    "text": "Holland (1986) discusses two solutions to the Fundamental Problem: one is the statistical solution, which relies on estimating average treatment effects across a large population of units while the other is the scientific solution, which uses homogeneity or invariance assumptions. The scientific solution works as follows: say we have one measurement of a units outcome under treatment from today and another measurement of their outcome under control from yesterday. If we are prepared to assume that control measurements are homogenous and invariant to time – that yesterday’s control measurement equals the control measurement we would have taken today – then we can calculate the individual level causal effect by comparing the two measurements taken at different points in time. Our assumption is untestable, of course, but in lab experiments it is sometimes possible to make a strong case that it is plausible. It is also the approach we informally use in daily life, whenever we conclude that taking Paracetamol helps against headaches or that going to sleep early makes us feel better the next morning.↩︎\nI have taken a slight shortcut here by treating experiments as being synonymous with the statistical solution because my focus here is on experiments. In principle, however, observational studies can serve the same purpose (albeit with additional assumptions). See, for instance, Imbens and Rubin (2015) for an extensive discussion of experimental and observational approaches.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "chapters/references.html",
    "href": "chapters/references.html",
    "title": "References",
    "section": "",
    "text": "Abadie, Alberto, Susan Athey, Guido W Imbens, and Jeffrey M Wooldridge.\n2020. “Sampling-Based Versus Design-Based Uncertainty in\nRegression Analysis.” Econometrica 88 (1): 265–96.\n\n\nAthey, Susan, and Guido W Imbens. 2017. “The Econometrics of\nRandomized Experiments.” In Handbook of Economic Field\nExperiments, 1:73–140. Elsevier.\n\n\nBloom, Howard S. 1995. “Minimum Detectable Effects: A Simple Way\nto Report the Statistical Power of Experimental Designs.”\nEvaluation Review 19 (5): 547–56.\n\n\nBojinov, Iavor, David Simchi-Levi, and Jinglong Zhao. 2023.\n“Design and Analysis of Switchback Experiments.”\nManagement Science 69 (7): 3759–77.\n\n\nDing, Peng. 2023. “A First Course in Causal Inference.” https://arxiv.org/abs/2305.18793.\n\n\nDuflo, Esther, Rachel Glennerster, and Michael Kremer. 2007.\n“Using Randomization in Development Economics Research: A\nToolkit.” Handbook of Development Economics 4:\n3895–3962.\n\n\nHohnhold, Henning, Deirdre O’Brien, and Diane Tang. 2015.\n“Focusing on the Long-Term: It’s Good for Users and\nBusiness.” In Proceedings of the 21th ACM SIGKDD\nInternational Conference on Knowledge Discovery and Data Mining,\n1849–58.\n\n\nHolland, Paul W. 1986. “Statistics and Causal Inference.”\nJournal of the American Statistical Association 81 (396):\n945–60.\n\n\nImbens, Guido W. 2021. “Statistical Significance, p-Values, and\nthe Reporting of Uncertainty.” Journal of Economic\nPerspectives 35 (3): 157–74.\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in\nStatistics, Social, and Biomedical Sciences. Cambridge University\nPress.\n\n\nKing, Gary, and Langche Zeng. 2006. “The Dangers of Extreme\nCounterfactuals.” Political Analysis 14 (2): 131–59.\n\n\nKohavi, Ron, Alex Deng, Roger Longbotham, and Ya Xu. 2014. “Seven\nRules of Thumb for Web Site Experimenters.” In Proceedings of\nthe 20th ACM SIGKDD International Conference on Knowledge Discovery and\nData Mining, 1857–66.\n\n\nLarsen, Nicholas, Jonathan Stallrich, Srijan Sengupta, Alex Deng, Ron\nKohavi, and Nathaniel T Stevens. 2023. “Statistical Challenges in\nOnline Controlled Experiments: A Review of a/b Testing\nMethodology.” The American Statistician, 1–15.\n\n\nList, John A, Sally Sadoff, and Mathis Wagner. 2011. “So You Want\nto Run an Experiment, Now What? Some Simple Rules of Thumb for Optimal\nExperimental Design.” Experimental Economics 14: 439–57.\n\n\nNordin, Mattias, and Mårten Schultzberg. 2024. “Precision-Based\nDesigns for Sequential Randomized Experiments.” arXiv\nPreprint arXiv:2405.03487.\n\n\nReich, Nicholas G, Jessica A Myers, Daniel Obeng, Aaron M Milstone, and\nTrish M Perl. 2012. “Empirical Power and Sample Size Calculations\nfor Cluster-Randomized and Cluster-Randomized Crossover Studies.”\nPloS One 7 (4): e35564.\n\n\nRice, John A. 2006. Mathematical Statistics and Data Analysis.\nCengage Learning.\n\n\nRomer, David. 2020. “In Praise of Confidence Intervals.” In\nAEA Papers and Proceedings, 110:55–60.\n\n\nRubin, Donald B. 1980. “Randomization Analysis of Experimental\nData: The Fisher Randomization Test Comment.” Journal of the\nAmerican Statistical Association 75 (371): 591–93.\n\n\nZhou, Jing, Jiannan Lu, and Anas Shallah. 2023. “All about\nSample-Size Calculations for a/b Testing: Novel Extensions and Practical\nGuide.” arXiv Preprint arXiv:2305.16459.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "chapters/experiments.html",
    "href": "chapters/experiments.html",
    "title": "2  Experiments",
    "section": "",
    "text": "Running an experiment with our \\(n\\) units means that we randomly assign some units to treatment and some to control. We use the binary treatment indicator \\(W_i \\in \\{0, 1\\}\\) to indicate treatment exposure for unit \\(i\\) and write \\(W_i = 1\\) if they are in treatment and \\(W_i = 0\\) if they are in control. We collect all unit-level treatment indicators in the \\(n \\times 1\\) vector \\(\\mathbf{W} = (W_1, W_2, \\dots, W_n)'\\). At the end of the experiment, we have \\(n_t = \\sum_{i=1}^n W_i\\) units in treatment and the remaining \\(n_c = \\sum_{i=1}^n (1-W_i)\\) units in control. For each unit, we observe outcome \\(Y_i\\).\nTo estimate \\(\\tau\\), we use the observed difference in means between the treatment and control units:[^1]\n\\[\n\\begin{align}\n\\hat{\\tau}^{\\text{dm}}\n=\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\end{align}\n\\]\nThis is our estimator, the method we use to produce estimates of the estimand.\nThe procedure we use the allocate units to treatment conditions is the assignment mechanism. In online experiments, we typically assign units to treatment conditions dynamically as they visit our site and use an assignment mechanism where the assignment of each unit is determined by a process that is equivalent to a coin-toss, such that \\(P(W_i=1) = q\\), where \\(q \\in [0, 1]\\). Throughout, I’ll focus on the most common case of equal sample sizes, where \\(q=\\frac{1}{2}\\), so that we have:\n\\[\nP(W_i = 1) = P(W_i = 0) = \\frac{1}{2}.\n\\]\nBecause of their coin-toss-like nature assignments follow a Bernoulli distribution and the type of experiment is called a Bernoulli Randomised Experiment. There are different approaches we could take to formally analyse our experiment.\nFirst, we have to decide how to think of our sample of \\(n\\) units. We could either view these units as the population of interest or treat them as a sample from a larger population and use results from the sample to make inferences about the population. Because in all but the largest companies experiments usually run on all traffic, the first perspective is more natural for online experiments and in what follows we treat our \\(n\\) units as the population of interest. In this approach, where the sample of \\(n\\) units is taken as fixed (rather than being treated as a random sample from a larger population), the only source of randomness comes from treatment assignments – from the design of our experiment – and the approach is thus naturally called “design-based”.[^design] Given that our sample is fixed, the two vectors of potential outcomes, \\(\\mathbf{Y(1)}\\) and \\(\\mathbf{Y(0)}\\) are also fixed.\nSecond, we have to decide how to treat the treatment condition sample sizes. We can analyse the Bernoulli Randomised Experiment treating \\(n_t\\) and \\(n_c\\) as Binomial random variables or taking them as given. I follow the latter approach for two reasons: it considerably simplifies the math, and it more naturally aligns with the situation we face in online experiments given that, by the time of the analysis, sample sizes are, indeed, given.\nIn the next two sections we show that \\(\\hat{\\tau}^{\\text{dm}}\\) is an unbiased estimator of \\(\\tau\\) – that is that, on average, our estimator helps us find the true value of the estimand.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Experiments</span>"
    ]
  },
  {
    "objectID": "chapters/experiments.html#footnotes",
    "href": "chapters/experiments.html#footnotes",
    "title": "2  Experiments",
    "section": "",
    "text": "For more on the difference between sampling vs design-based inference, see Abadie et al. (2020), Athey and Imbens (2017), Imbens and Rubin (2015) for discussions on sampling vs design-based inference.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Experiments</span>"
    ]
  },
  {
    "objectID": "chapters/unbiasedness.html",
    "href": "chapters/unbiasedness.html",
    "title": "3  Unbiasedness",
    "section": "",
    "text": "An estimator is unbiased if its expected value equals the true value of the estimand. In Equation 2.1 we defined our difference-in-means estimator as:\n\\[\n\\begin{align}\n\\hat{\\tau}^{\\text{dm}}\n=\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i,\n\\end{align}\n\\]\nand in Equation 1.1 we defined the estimand as:\n\\[\n\\begin{align}\n\\tau\n= \\frac{1}{n}\\sum_{i=1}^n Y_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0).\n\\end{align}\n\\]\nGiven that we take sample sizes and potential outcomes as fixed, showing that our estimator is unbiased amounts to showing that:\n\\[\n\\begin{align}\n\\mathbb{E}\\left[\n\\hat{\\tau}^{\\text{dm}}\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\\tau\n\\\\[5pt]\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n- \\mathbb{E}\\left[\n\\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0),\n\\end{align}\n\\]\nwhere \\(\\mathbf{Y(w)} = (\\mathbf{Y(1)}, \\mathbf{Y(0)})\\) and \\(\\mathbf{n} = (n_t, n_c)\\).\nThere are two pieces we need for this:\n\nLink observed to potential outcomes so that \\(Y_i = Y_i(W_i)\\). This requires the Stable Unit Treatment Value Assumption (SUTVA).\nLink treatment group averages to sample averages so that \\(\\mathbb{E}\\left[\\frac{1}{n_t}\\sum_{W_i=w}Y_i(w)\\right] = \\frac{1}{n}\\sum_{i=1}^{n}Y_i(w)\\). This requires randomisation.\n\n\n3.0.1 SUTVA links observed outcomes to potential outcomes\nWe want to learn something about unit-level differences in potential outcomes \\[\n\\tau_i = Y_i(1) - Y_i(0),\n\\] where a potential outcome is a unit-indexed function of the treatment level, with the treatment levels in our case simply being “treatment” and “control”, captured by the assignment indicator \\(W_i \\in {0, 1}\\).\nNow say we run an experiment and unit \\(i\\) is allocated to treatment. The \\(i\\)-th element of the assignment vector \\(\\mathbf{W}\\) of that experiment is thus \\(W_i = 1\\), and we refer to this assignment vector as \\(\\mathbf{W}^{(i=1)}\\).\nWe know we can’t observe both \\(Y_i(0)\\) and \\(Y_i(1)\\), but given that \\(i\\) is in treatment we can observe the potential outcome under treatment, \\(Y_i(1)\\), which will help us estimate \\(\\hat{\\tau}\\). So we need\n\\[\nY_i = Y_i(1).\n\\]\nWhat we directly observe, however, is \\[\nY_i = Y_i\\left(\\mathbf{W}^{(i=1)}\\right).\n\\] In words: the outcome we observe for unit \\(i\\) in our experiment is not the potential outcome for \\(i\\) under treatment, but the potential outcome for \\(i\\) under the specific assignment vector of our experiment, \\(\\mathbf{W}^{(i=1)}\\). What does this mean concretely? It means that the observed outcome is a function not only of \\(i\\)’s treatment assignment but of:\n\nThe assignment of all units in the experiment\nThe precise form of the assigned treatment level received by \\(i\\)\nThe way in which said assigned treatment level is administered to \\(i\\)\n\nWe need: \\[\nY_i = Y_i\\left(\\mathbf{W}^{(i=1)}\\right) \\overset{!}{=} Y_i(1).\n\\] The only way to make progress is to assume what we need: that potential outcomes for unit \\(i\\) are a function only of the treatment level unit \\(i\\) itself receives and independent of (i) treatment assignment of other units and (ii) the form and administration of the treatment level. (i) above is referred to as “no interference” in the literature, (ii) as “no hidden variations of treatment”.\nThat assumption is SUTVA, the Stable Unit Treatment Value Assumption. It ensures that the potential outcomes for each unit and each treatment level are well-defined functions of the unit index and the treatment level only – that for a given unit and treatment level, the potential outcome is well-defined and, thus, “stable” (Rubin 1980).\nNote that (ii) does not mean that a treatment level has to take the same form for all units, even though it is often misinterpreted to mean that. What we need is that \\(Y_i(W_i)\\) is a clearly defined function for all \\(i\\) and all possible treatment levels \\(W_i \\in \\{0, 1\\}\\). For this to be the case, it must be the case that there are no different forms of possible treatments, the potential outcome for each for is the same so that the differences are irrelevant, or that the experienced form is random so that the expected outcome across all units remains stable.\nIn the context of our e-commerce app experiment, the non-interference part of SUTVA means that potential outcomes for all customers are independent of treatment assignment of all other customers – very much including family members and friends and the no-hidden-variation part means that there their precise experience is pinned down by their mobile device and remains stable over time: there are no accidental server-side bugs that creates different background colours and the it is either clear whether a customer uses an Android or iOS app (or the experience is identical). But, again, SUTVA does not require that the active treatment looks exactly the same on iOS and Android apps just that for each unit in our experiment, their experience if they are part of the active treatment is pinned down.\nWhy is this important? We want to know what happened if we rolled out our policy to everyone compared to if we didn’t roll it out to anyone. To have any hope of estimating this we can’t have treatment level’s vary over time or depending on circumstances, but need them to be pinned down for each unit. (In the context of Tech, this would mean that the experience of a feature for a given user is pinned down by, say, the size of their phone screen and the app version they use, which, by and large, is plausible.)\nSUTVA is a strong assumption and can be violated in a number of ways. I’ll discuss these, together with solutions, in Chapter 8.\nIf SUTVA holds we have:\n\\[\nY_i = Y_i(W_i) = \\begin{cases}\n   Y_i(1) & \\text{if } W_i = 1 \\\\\n   Y_i(0)       & \\text{if } W_i = 0,\n  \\end{cases}\n\\]\nor, more compactly:\n\\[\nY_i = W_iY_i(1) + (1 - W_i)Y_i(0).\n\\]\nThis is the link between observed and potential outcomes we need, and makes clear that we observe \\(Y_i(1)\\) for units in treatment and \\(Y_i(0)\\) for units in control.\nIn our unbiasedness proof, we now have\n\\[\n\\begin{align}\n\\mathbb{E}\\left[\n\\hat{\\tau}^{\\text{dm}}\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\\tau\n\\\\[5pt]\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n- \\mathbb{E}\\left[\n\\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n\\mathbb{E}\\left[\\frac{1}{n_t}\\sum_{W_i=1}Y_i(1)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]\n- \\mathbb{E}\\left[\\frac{1}{n_c}\\sum_{W_i=0}Y_i(0)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\end{align}\n\\]\nWhat remains is to show that \\(\\mathbb{E}\\left[\\frac{1}{n_t}\\sum_{W_i=w}Y_i(w)\\right] = \\frac{1}{n}\\sum_{i=1}^{n}Y_i(w)\\). This requires randomisation.\n\n\n3.0.2 Randomisation links treatment groups to the population\nWe start by rewriting the last equation slightly: we use the definition of \\(W_i\\) to write \\(\\sum_{W_i=1}Y_i(1)\\) as \\(\\sum_{i=1}^{n} W_iY_i(1)\\) for treatment units and use the corresponding expression for control units; we use the linearity of the expectation operator to move it inside the summation; and we move \\(\\mathbf{Y(w)}\\), which is fixed, out of the expectation. We now have:\n\\[\n\\begin{align}\n\\mathbb{E}\\left[\n\\hat{\\tau}^{\\text{dm}}\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\\tau\n\\\\[5pt]\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n- \\mathbb{E}\\left[\n\\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n\\mathbb{E}\\left[\\frac{1}{n_t}\\sum_{W_i=1}Y_i(1)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]\n- \\mathbb{E}\\left[\\frac{1}{n_c}\\sum_{W_i=0}Y_i(0)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n\\frac{1}{n_t}\\sum_{i=1}^{n}\\mathbb{E}\\left[W_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]Y_i(1)\n- \\frac{1}{n_c}\\sum_{i=1}^{n}\\mathbb{E}\\left[1-W_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]Y_i(0)\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0).\n\\end{align}\n\\]\nThis expression makes transparent that \\(W_i\\) is the only random element. \\(\\mathbb{E}[W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\\) and \\(\\mathbb{E}[1-W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\\) are determined by the assignment mechanism. Given that we have defined \\(W_i\\) as a Bernoulli random variable and given that we take potential outcomes \\(\\mathbf{Y(w)}\\) and sample sizes \\(\\mathbf{n}\\) as given we have \\[\nP(W_i = 1 \\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)})\n=\n\\frac{n_t}{n}.\n\\]Hence: \\[\n\\begin{align}\n\\mathbb{E}&[W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\n\\\\[5pt]\n&=\n1 \\times P(W_i = 1 \\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)})\n+ 0 \\times P(W_i = 0 \\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)})\n\\\\[5pt]\n&=\nP(W_i = 1 \\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)})\n\\\\[5pt]\n&= \\frac{n_t}{n}.\n\\end{align}\n\\] Similarly: \\[\n\\begin{align}\n\\mathbb{E}&[(1-W_i)\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\n\\\\[5pt]\n&=\n1 - \\mathbb{E}[W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\n\\\\[5pt]\n&=\n1 - \\frac{n_t}{n}\n\\\\[5pt]\n&=\n\\frac{n - n_t}{n}\n\\\\[5pt]\n&=\n\\frac{n_c}{n}.\n\\end{align}\n\\]\nPlugging these two expressions gives us the final result:\n\\[\n\\begin{align}\n\\mathbb{E}\\left[\n\\hat{\\tau}^{\\text{dm}}\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\\tau\n\\\\[5pt]\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n- \\mathbb{E}\\left[\n\\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n\\mathbb{E}\\left[\\frac{1}{n_t}\\sum_{W_i=1}Y_i(1)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]\n- \\mathbb{E}\\left[\\frac{1}{n_c}\\sum_{W_i=0}Y_i(0)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n\\frac{1}{n_t}\\sum_{i=1}^{n}\\mathbb{E}\\left[W_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]Y_i(1)\n- \\frac{1}{n_c}\\sum_{i=1}^{n}\\mathbb{E}\\left[1-W_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]Y_i(0)\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n&\\text{Randomisation}\n\\\\[5pt]\n\\frac{1}{n_t}\\sum_{i=1}^{n}\\left(\\frac{n_t}{n}\\right)Y_i(1)\n- \\frac{1}{n_c}\\sum_{i=1}^{n}\\left(\\frac{n_c}{n}\\right)Y_i(0)\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n\\frac{1}{n}\\sum_{i=1}^{n}Y_i(1)\n- \\frac{1}{n}\\sum_{i=1}^{n}Y_i(0)\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\end{align}\n\\]\nThis completes our proof of unbiasedness of our difference in means estimator.\nIn the next section, we’ll calculate the estimator’s variance.\n\n\n\n\nRubin, Donald B. 1980. “Randomization Analysis of Experimental Data: The Fisher Randomization Test Comment.” Journal of the American Statistical Association 75 (371): 591–93.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unbiasedness</span>"
    ]
  },
  {
    "objectID": "chapters/unbiasedness.html#sec-lemma1",
    "href": "chapters/unbiasedness.html#sec-lemma1",
    "title": "3  Unbiasedness",
    "section": "3.1 Lemma 1",
    "text": "3.1 Lemma 1\nGiven that \\(W_i \\in \\{0, 1\\} \\sim \\text{Bernoulli}(q)\\), and given that we take potential outcomes \\(\\mathbf{Y(w)} = (\\mathbf{Y(1)}, \\mathbf{Y(0)})\\) and sample sizes \\(\\mathbf{n} = (n, n_t, n_c)\\) as given, we have: \\[\n\\mathbb{E}[W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\n=\n\\frac{n_t}{n}\n\\]\nand\n\\[\n\\mathbb{E}[1-W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\n=\n\\frac{n_c}{n}.\n\\] Proof:\nGiven that \\(W_i \\in \\{0, 1\\} \\sim \\text{Bernoulli}(q)\\) we have: \\[\nP(W_i = 1 \\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)})\n=\n\\frac{n_t}{n}.\n\\]Hence: $$ \\[\\begin{align}\n\\mathbb{E}&[W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\n\\\\[5pt]\n\n&=\n1 \\times P(W_i = 1 \\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)})\n+ 0 \\times P(W_i = 0 \\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)})\n\\\\[5pt]\n\n&=\nP(W_i = 1 \\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)})\n\\\\[5pt]\n\n&= \\frac{n_t}{n}\n\\end{align}\\] \\[\nand\n\\] \\[\\begin{align}\n\\mathbb{E}&[(1-W_i)\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\n\\\\[5pt]\n\n&=\n1 - \\mathbb{E}[W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\n\\\\[5pt]\n\n&=\n1 - \\frac{n_t}{n}\n\\\\[5pt]\n\n&=\n\\frac{n - n_t}{n}\n\\\\[5pt]\n\n&=\n\\frac{n_c}{n}\n\\qquad\\square\n\\end{align}\\] $$\n\nUse Lemma 1 (randomisation) to replace expectations with expected values.\n\n\\[\n\\begin{align}\n\\mathbb{E}\\left[\n\\hat{\\tau}^{\\text{dm}}\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n&=\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n\\\\[5pt]\n&=\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n- \\mathbb{E}\\left[\n\\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{E}\\left[\\frac{1}{n_t}\\sum_{W_i=1}Y_i(1)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]\n- \\mathbb{E}\\left[\\frac{1}{n_c}\\sum_{W_i=0}Y_i(0)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\\right]\n\\\\[5pt]\n&=\n\\mathbb{E}\\left[\n\\frac{1}{n_t}\\sum_{i=1}^{n}W_iY_i(1)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n-\n\\mathbb{E}\\left[\n\\frac{1}{n_c}\\sum_{i=1}^{n}(1-W_i)Y_i(0)\n\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}\n\\right]\n\\\\[5pt]\n&=\n\\frac{1}{n_t}\\sum_{i=1}^{n}\n\\mathbb{E}[W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\nY_i(1)\n-\n\\frac{1}{n_c}\\sum_{i=1}^{n}\n\\mathbb{E}[1-W_i\\&gt;|\\&gt;\\mathbf{n}, \\mathbf{Y(w)}]\nY_i(0)\n\\\\[5pt]\n&\\text{Randomisation (Lemma 1)}\n\\\\[5pt]\n&=\n\\frac{1}{n_t}\\sum_{i=1}^{n}\n\\left(\\frac{n_t}{n}\\right)\nY_i(1)\n-\n\\frac{1}{n_c}\\sum_{i=1}^{n}\n\\left(\\frac{n_c}{n}\\right)\nY_i(0)\n\\\\[5pt]\n&=\n\\frac{1}{n}\\sum_{i=1}^nY_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]\n&=\n\\tau\n\\end{align}\n\\]\n\n\n\n\nRubin, Donald B. 1980. “Randomization Analysis of Experimental Data: The Fisher Randomization Test Comment.” Journal of the American Statistical Association 75 (371): 591–93.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unbiasedness</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html",
    "href": "chapters/variance.html",
    "title": "4  Variance",
    "section": "",
    "text": "4.1 Definitions\nWe start with some definitions.\nThe sample means and variances of the potential outcomes are:\n\\[\n\\begin{align}\n\\overline{Y}(1) = \\frac{1}{n}\\sum_{i=1}^n Y_i(1),\n\\qquad\nS_1^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n\\\\[5pt]\n\\overline{Y}(0) = \\frac{1}{n}\\sum_{i=1}^n Y_i(0),\n\\qquad\nS_0^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n\\\\[5pt]\n\\end{align}\n\\]\nWe have already defined the sample average treatment effect in Equation 1.1. I rewrite it here for convenience and expand the definition using the above expressions:\n\\[\n\\begin{align}\n\\tau\n&= \\frac{1}{n}\\sum_{i=1}^n \\tau_i\n\\\\[5pt]&= \\frac{1}{n}\\sum_{i=1}^n \\left(Y_i(1) - Y_i(0)\\right)\n\\\\[5pt]&= \\frac{1}{n}\\sum_{i=1}^n Y_i(1) - \\frac{1}{n}\\sum_{i=1}^nY_i(0)\n\\\\[5pt]&= \\overline{Y}(1) - \\overline{Y}(0).\n\\end{align}\n\\]\nThe variance of the individual-level causal effects is:\n\\[\n\\begin{align}\nS_{\\tau_i}^2\n&= \\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - Y_i(0)\n- \\left(\\overline{Y}(1) - \\overline{Y}(0)\\right)\\right)^2\n\\\\[5pt]\n&= \\frac{1}{n-1}\\sum_{i=1}^{n}\\left(\\tau_i - \\tau\\right)^2 \\\\[5pt]\n\\end{align}\n\\] The covariance of potential outcomes is: \\[\n\\begin{align}\nS_{0, 1} &= \\frac{1}{n-1}\\sum_{i=1}^{n}\n\\left(Y_i(1) - \\overline{Y}(1)\\right)\n\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\end{align}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/standard_error.html",
    "href": "chapters/standard_error.html",
    "title": "5  Standard error",
    "section": "",
    "text": "The standard error of an estimator is simply the square root of its sampling variance. From\n\nwe thus have:\n\\[\n\\widehat{SE}\n= \\sqrt{\\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}}.\n\\tag{5.1}\\]\nBecause in online experiments sample sizes are large and treatment effects are usually small, it is sometimes convenient to assume equal sample sizes, so that the sample size for each variant is \\(n_t = n_c = n_v\\), and equal variances, so that \\(s_t^2 = s_c^2 = s^2\\). The common variance \\(s^2\\) is estimated by “pooling” the treatment group variances to create a degrees-of-freedom-weighted estimator of the form: \\[\ns^2 = \\frac{(n_t - 1) s_t^2 + (n_c - 1) s_c^2}{n_t + n_c - 2}.\n\\] Substituting in Equation eq-se we then have: \\[\n\\widehat{SE}^{\\text{equal}}\n= \\sqrt{\\frac{s^2}{n_v} + \\frac{s^2}{n_v}}\n= \\sqrt{\\frac{2s^2}{n_v}}.\n\\tag{5.2}\\]\nFinally, for the purpose of experiment design it is sometimes useful to express the standard error in terms of the proportion of units allocated to the treatment group. Hence, instead of assuming equal sample sizes, we use \\(p\\) to denote that proportion and \\(n\\) to denote total sample size, while maintaining the assumption of equal variance. Again substituting in Equation eq-se we can then write: \\[\n\\widehat{SE}^{\\text{prop}}\n= \\sqrt{\\frac{s^2}{pn} + \\frac{s^2}{(1-p)n}}\n= \\sqrt{\\frac{s^2}{np(1-p)}}.\n\\tag{5.3}\\]\nFor \\(p=0.5\\), this formulation is equivalent to Equation eq-se-equal as expected.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Standard error</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#the-title",
    "href": "chapters/variance.html#the-title",
    "title": "4  Variance",
    "section": "4.1 The title",
    "text": "4.1 The title\nDerivation\n\\[\n\\begin{align}\n\\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i \\Bigl(W_i Y_i(1) + (1 - W_i) Y_i(0)\\Bigr) \\\\\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} \\Bigl(R_i W_i W_i Y_i(1) + R_i W_i (1 - W_i) Y_i(0)\\Bigr) \\\\\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i W_i Y_i(1) \\\\\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i(1) \\\\\n\\frac{1}{n_c}\\sum_{i=1}^{N} R_i (1 - W_i) Y_i\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i (1 - W_i) \\Bigl(W_i Y_i(1) + (1 - W_i) Y_i(0)\\Bigr) \\\\\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} \\Bigl(R_i(1 - W_i) W_i Y_i(1) + R_i(1 - W_i) (1 - W_i) Y_i(0)\\Bigr) \\\\\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i(1 - W_i) (1 - W_i) Y_i(0) \\\\\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i(1 - W_i) Y_i(0)\n\\end{align}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#footnotes",
    "href": "chapters/variance.html#footnotes",
    "title": "4  Variance",
    "section": "",
    "text": "Imbens and Rubin (2015) provide an alternative derivation in Appendix B of Chapter 6 that is fairly detailed but still skips a lot of steps that weren’t immediately obvious to me, and they define a helper variable I don’t find to help that much. I find the approach in Ding (2023) more transparent. But the original source skips a lot of steps and is thus not very accessible.↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#definitions",
    "href": "chapters/variance.html#definitions",
    "title": "4  Variance",
    "section": "",
    "text": "Note 4.1: Derivation\n\n\n\n\n\nDerivation\n\\[\n\\begin{align}\n\\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i \\Bigl(W_i Y_i(1) + (1 - W_i) Y_i(0)\\Bigr) \\\\\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\nIf treatment effects are constant across units, then this is an unbiased estimator of the true sampling variance since in this case, \\(S^2_{\\tau_i} = 0\\).\nIf treatment effects are not constant, then this is a conservative estimator of the sampling variance (since \\(S_{\\tau_i}^2\\) is non-negative).\n\n\n\n\n\nDing, Peng. 2023. “A First Course in Causal Inference.” https://arxiv.org/abs/2305.18793.\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#section",
    "href": "chapters/variance.html#section",
    "title": "4  Variance",
    "section": "4.3 ",
    "text": "4.3 \n \\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&\\text{\\href{#lemma-1}{Lemma 1}}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{\\href{#lemma-2}{Lemma 2}}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1)\n- \\frac{1}{n_c}\\sum_{i=1}^n Y_i(0)\n+ \\frac{1}{n_c}\\sum_{i=1}^n W_iY_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i\\frac{Y_i(1)}{n_t}\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n+ \\sum_{i=1}^n W_i\\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&\\text{Drop constant (variance unchanged)}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n\\right)\n\\\\[5pt]\n&\\text{Demean (variance unchanged)}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c} - \\left(\\frac{\\overline{Y}(1)}{n_t} + \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Using shorthands } Y_i^+ \\coloneqq Y_i(1)/n_t + Y_i(0)/n_c \\text{ and } \\overline{Y}^+ \\coloneqq \\overline{Y}(1)/n_t + \\overline{Y}(0)/n_c\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Rewriting variance in terms of covariance}\n\\\\[5pt]\n&=\n\\text{Cov}\\left(\n\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\\right),\n\\sum_{j=1}^n W_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(\nW_i \\left(Y_i^+ - \\overline{Y}^+\\right),\nW_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i^2\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 2}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 3}\n\\\\[5pt]\n&=\n\\sum_{i=1}^{n}\\left(\\frac{n_tn_c}{n^2}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\sum_{i=1}^{n}\\sum_{j \\neq i}\\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\\sum_{j \\neq i}\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&\\text{Lemma 4}\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+ \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2} + \\frac{n_tn_c}{n^2(n-1)}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c(n-1) + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{nn_tn_c - n_tn_c + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&\\text{Reverting to full notation and expanding square term}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c} - \\left(\\frac{\\overline{Y}(1)}{n_t} + \\frac{\\overline{Y}(0)}{n_c}\\right)\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\n- \\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\left(\\frac{Y_i(1)}{n_t} - \\frac{\\overline{Y}(1)}{n_t}\\right)\n+ \\left(\\frac{Y_i(0)}{n_c} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t}\\left(Y_i(1) - \\overline{Y}(1)\\right)\n+ \\frac{1}{n_c}\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t^2}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\frac{1}{n_t^2}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{n_t}{n n_c}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}2S_{0,1}\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 5}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}\\left(S_1^2 + S_0^2 - S_{\\tau_i}^2\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\left(\\frac{n_c}{n n_t} + \\frac{1}{n}\\right)S_1^2\n+ \\left(\\frac{n_t}{n n_c} + \\frac{1}{n}\\right) S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c + n_t}{n n_t} S_1^2\n+ \\frac{n_t + n_c}{n n_c} S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{S_1^2}{n_t}\n+ \\frac{S_0^2}{n_c}\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n\\end{align}\n\\tag{4.1}\\]\nThis is the sampling variance of \\(\\hat{\\tau}^{\\text{dm}}\\). It’s a theoretical quantity we cannot directly observe.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#derivation",
    "href": "chapters/variance.html#derivation",
    "title": "4  Variance",
    "section": "4.2 Derivation",
    "text": "4.2 Derivation\nWe can now start with our derivation.\nThe variance of \\(\\hat{\\tau}^{\\text{dm}}\\) is defined as:\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\end{align}\n\\]\nUsing SUTVA and the definition of \\(W_i\\) to write \\(\\sum_{W_i=1}Y_i(1)\\) as \\(\\sum_{i=1}^{n} W_iY_i(1)\\) for treatment units and use the corresponding expression for control units we get:\n$$ \\[\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n\n\\end{align}\\] $$\n…I’m here\nAll lemmas referred to below are here.\nWe can then calculate the variance as (I do not explicitly condition on \\(\\mathbf{n}\\) and \\(\\mathbf{Y(w)}\\) here to keep the notation lighter):\n\n\n\n\n\n\nNote 4.1: Derivation\n\n\n\n\n\nDerivation\n\\[\n\\begin{align}\n\\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i \\Bigl(W_i Y_i(1) + (1 - W_i) Y_i(0)\\Bigr) \\\\\n\\end{align}\n\\]\n\n\n\nSee Note 4.1\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1)\n- \\frac{1}{n_c}\\sum_{i=1}^n Y_i(0)\n+ \\frac{1}{n_c}\\sum_{i=1}^n W_iY_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i\\frac{Y_i(1)}{n_t}\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n+ \\sum_{i=1}^n W_i\\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&\\text{Dropping constant term}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n\\right)\n\\\\[5pt]\n&\\text{Demeaning (leaves variance unchanged)}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c} - \\left(\\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Using shorthands } Y_i^+ = Y_i(1)/n_t + Y_i(0)/n_c \\text{ and } \\overline{Y}^+ = \\overline{Y}(1)/n_t - \\overline{Y}(0)/n_c\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Rewriting variance in terms of covariance}\n\\\\[5pt]\n&=\n\\text{Cov}\\left(\n\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\\right),\n\\sum_{j=1}^n W_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(\nW_i \\left(Y_i^+ - \\overline{Y}^+\\right),\nW_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i^2\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 2}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 3}\n\\\\[5pt]\n&=\n\\sum_{i=1}^{n}\\left(\\frac{n_tn_c}{n^2}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\sum_{i=1}^{n}\\sum_{j \\neq i}\\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\\sum_{j \\neq i}\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&\\text{Lemma 4}\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+ \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2} + \\frac{n_tn_c}{n^2(n-1)}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c(n-1) + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{nn_tn_c - n_tn_c + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&\\text{Reverting to full notation and expanding square term}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\n- \\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\left(\\frac{Y_i(1)}{n_t} - \\frac{\\overline{Y}(1)}{n_t}\\right)\n+ \\left(\\frac{Y_i(0)}{n_c} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t}\\left(Y_i(1) - \\overline{Y}(1)\\right)\n+ \\frac{1}{n_c}\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t^2}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\frac{1}{n_t^2}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{n_t}{n n_c}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}2S_{0,1}\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 5}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}\\left(S_1^2 + S_0^2 - S_{\\tau_i}^2\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\left(\\frac{n_c}{n n_t} + \\frac{1}{n}\\right)S_1^2\n+ \\left(\\frac{n_t}{n n_c} + \\frac{1}{n}\\right) S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c + n_t}{n n_t} S_1^2\n+ \\frac{n_t + n_c}{n n_c} S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{S_1^2}{n_t}\n+ \\frac{S_0^2}{n_c}\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n\\end{align}\n\\tag{4.1}\\]\nThis is the sampling variance of \\(\\hat{\\tau}^{\\text{dm}}\\). It’s a theoretical quantity we cannot directly observe. However, we can observe treatment group means:\n\\[\n\\begin{align}\n\\overline{Y}_t = \\frac{1}{n_t}\\sum_{i=1}^n W_iY_i\n\\qquad\n\\overline{Y}_c = \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\end{align}\n\\] and treatment group variances:\n\\[\n\\begin{align}\ns_t^2 = \\frac{1}{n_t-1}\\sum_{i=1}^{n}W_i\\left(Y_i - \\overline{Y}_t\\right)^2\n\\qquad\ns_c^2 = \\frac{1}{n_c-1}\\sum_{i=1}^{n}(1-W_i)\\left(Y_i - \\overline{Y}_c\\right)^2.\n\\end{align}\n\\] It can be shown that the observed treatment group variances \\(s_t^2\\) and \\(s_c^2\\) are unbiased estimators of the sample variances \\(S_1^2\\) and \\(S_0^2\\) (see, for instance, Appendix A in Chapter 6 of Imbens and Rubin (2015)). The last term in\n\n\\(S_{\\tau_i}^2\\), is the variance of unit-level treatment effects, which is impossible to observe.\nAs a result, the most widely used estimator in practice is: \\[\n\\hat{\\mathbb{V}}\n= \\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}.\n\\] In our context, the main advantages of this estimator are:\n\nIf treatment effects are constant across units, then this is an unbiased estimator of the true sampling variance since in this case, \\(S^2_{\\tau_i} = 0\\).\nIf treatment effects are not constant, then this is a conservative estimator of the sampling variance (since \\(S_{\\tau_i}^2\\) is non-negative).\n\n\n\n\n\nDing, Peng. 2023. “A First Course in Causal Inference.” https://arxiv.org/abs/2305.18793.\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#variacne-erivation",
    "href": "chapters/variance.html#variacne-erivation",
    "title": "4  Variance",
    "section": "4.2 Variacne erivation",
    "text": "4.2 Variacne erivation\nWe can now start with our derivation.\nThe variance of \\(\\hat{\\tau}^{\\text{dm}}\\) is defined as:\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\end{align}\n\\]\nUsing SUTVA and the definition of \\(W_i\\) to write \\(\\sum_{W_i=1}Y_i(1)\\) as \\(\\sum_{i=1}^{n} W_iY_i(1)\\) for treatment units and use the corresponding expression for control units we get:\n$$ \\[\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n\n\\end{align}\\] $$\n…I’m here\nAll lemmas referred to below are here.\nWe can then calculate the variance as (I do not explicitly condition on \\(\\mathbf{n}\\) and \\(\\mathbf{Y(w)}\\) here to keep the notation lighter):\n\n\n\n\n\n\nNote 4.1: Derivation\n\n\n\n\n\nDerivation\n\\[\n\\begin{align}\n\\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i \\Bigl(W_i Y_i(1) + (1 - W_i) Y_i(0)\\Bigr) \\\\\n\\end{align}\n\\]\n\n\n\nSee Note 4.1\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1)\n- \\frac{1}{n_c}\\sum_{i=1}^n Y_i(0)\n+ \\frac{1}{n_c}\\sum_{i=1}^n W_iY_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i\\frac{Y_i(1)}{n_t}\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n+ \\sum_{i=1}^n W_i\\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&\\text{Dropping constant term}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n\\right)\n\\\\[5pt]\n&\\text{Demeaning (leaves variance unchanged)}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c} - \\left(\\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Using shorthands } Y_i^+ = Y_i(1)/n_t + Y_i(0)/n_c \\text{ and } \\overline{Y}^+ = \\overline{Y}(1)/n_t - \\overline{Y}(0)/n_c\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Rewriting variance in terms of covariance}\n\\\\[5pt]\n&=\n\\text{Cov}\\left(\n\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\\right),\n\\sum_{j=1}^n W_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(\nW_i \\left(Y_i^+ - \\overline{Y}^+\\right),\nW_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i^2\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 2}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 3}\n\\\\[5pt]\n&=\n\\sum_{i=1}^{n}\\left(\\frac{n_tn_c}{n^2}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\sum_{i=1}^{n}\\sum_{j \\neq i}\\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\\sum_{j \\neq i}\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&\\text{Lemma 4}\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+ \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2} + \\frac{n_tn_c}{n^2(n-1)}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c(n-1) + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{nn_tn_c - n_tn_c + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&\\text{Reverting to full notation and expanding square term}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\n- \\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\left(\\frac{Y_i(1)}{n_t} - \\frac{\\overline{Y}(1)}{n_t}\\right)\n+ \\left(\\frac{Y_i(0)}{n_c} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t}\\left(Y_i(1) - \\overline{Y}(1)\\right)\n+ \\frac{1}{n_c}\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t^2}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\frac{1}{n_t^2}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{n_t}{n n_c}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}2S_{0,1}\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 5}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}\\left(S_1^2 + S_0^2 - S_{\\tau_i}^2\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\left(\\frac{n_c}{n n_t} + \\frac{1}{n}\\right)S_1^2\n+ \\left(\\frac{n_t}{n n_c} + \\frac{1}{n}\\right) S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c + n_t}{n n_t} S_1^2\n+ \\frac{n_t + n_c}{n n_c} S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{S_1^2}{n_t}\n+ \\frac{S_0^2}{n_c}\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n\\end{align}\n\\tag{4.1}\\]\nThis is the sampling variance of \\(\\hat{\\tau}^{\\text{dm}}\\). It’s a theoretical quantity we cannot directly observe. However, we can observe treatment group means:\n\\[\n\\begin{align}\n\\overline{Y}_t = \\frac{1}{n_t}\\sum_{i=1}^n W_iY_i\n\\qquad\n\\overline{Y}_c = \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\end{align}\n\\] and treatment group variances:\n\\[\n\\begin{align}\ns_t^2 = \\frac{1}{n_t-1}\\sum_{i=1}^{n}W_i\\left(Y_i - \\overline{Y}_t\\right)^2\n\\qquad\ns_c^2 = \\frac{1}{n_c-1}\\sum_{i=1}^{n}(1-W_i)\\left(Y_i - \\overline{Y}_c\\right)^2.\n\\end{align}\n\\] It can be shown that the observed treatment group variances \\(s_t^2\\) and \\(s_c^2\\) are unbiased estimators of the sample variances \\(S_1^2\\) and \\(S_0^2\\) (see, for instance, Appendix A in Chapter 6 of Imbens and Rubin (2015)). The last term in\n\n\\(S_{\\tau_i}^2\\), is the variance of unit-level treatment effects, which is impossible to observe.\nAs a result, the most widely used estimator in practice is: \\[\n\\hat{\\mathbb{V}}\n= \\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}.\n\\] In our context, the main advantages of this estimator are:\n\nIf treatment effects are constant across units, then this is an unbiased estimator of the true sampling variance since in this case, \\(S^2_{\\tau_i} = 0\\).\nIf treatment effects are not constant, then this is a conservative estimator of the sampling variance (since \\(S_{\\tau_i}^2\\) is non-negative).\n\n\n\n\n\nDing, Peng. 2023. “A First Course in Causal Inference.” https://arxiv.org/abs/2305.18793.\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#variacerivation",
    "href": "chapters/variance.html#variacerivation",
    "title": "4  Variance",
    "section": "4.2 Variacerivation",
    "text": "4.2 Variacerivation\nWe can now start with our derivation.\nThe variance of \\(\\hat{\\tau}^{\\text{dm}}\\) is defined as:\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\end{align}\n\\]\nUsing SUTVA and the definition of \\(W_i\\) to write \\(\\sum_{W_i=1}Y_i(1)\\) as \\(\\sum_{i=1}^{n} W_iY_i(1)\\) for treatment units and use the corresponding expression for control units we get:\n$$ \\[\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n\n\\end{align}\\] $$\n…I’m here\nAll lemmas referred to below are here.\nWe can then calculate the variance as (I do not explicitly condition on \\(\\mathbf{n}\\) and \\(\\mathbf{Y(w)}\\) here to keep the notation lighter):\n\n\n\n\n\n\nNote 4.1: Derivation\n\n\n\n\n\nDerivation\n\\[\n\\begin{align}\n\\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i \\Bigl(W_i Y_i(1) + (1 - W_i) Y_i(0)\\Bigr) \\\\\n\\end{align}\n\\]\n\n\n\nSee Note 4.1\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1)\n- \\frac{1}{n_c}\\sum_{i=1}^n Y_i(0)\n+ \\frac{1}{n_c}\\sum_{i=1}^n W_iY_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i\\frac{Y_i(1)}{n_t}\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n+ \\sum_{i=1}^n W_i\\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&\\text{Dropping constant term}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n\\right)\n\\\\[5pt]\n&\\text{Demeaning (leaves variance unchanged)}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c} - \\left(\\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Using shorthands } Y_i^+ = Y_i(1)/n_t + Y_i(0)/n_c \\text{ and } \\overline{Y}^+ = \\overline{Y}(1)/n_t - \\overline{Y}(0)/n_c\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Rewriting variance in terms of covariance}\n\\\\[5pt]\n&=\n\\text{Cov}\\left(\n\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\\right),\n\\sum_{j=1}^n W_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(\nW_i \\left(Y_i^+ - \\overline{Y}^+\\right),\nW_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i^2\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 2}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 3}\n\\\\[5pt]\n&=\n\\sum_{i=1}^{n}\\left(\\frac{n_tn_c}{n^2}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\sum_{i=1}^{n}\\sum_{j \\neq i}\\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\\sum_{j \\neq i}\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&\\text{Lemma 4}\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+ \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2} + \\frac{n_tn_c}{n^2(n-1)}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c(n-1) + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{nn_tn_c - n_tn_c + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&\\text{Reverting to full notation and expanding square term}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\n- \\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\left(\\frac{Y_i(1)}{n_t} - \\frac{\\overline{Y}(1)}{n_t}\\right)\n+ \\left(\\frac{Y_i(0)}{n_c} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t}\\left(Y_i(1) - \\overline{Y}(1)\\right)\n+ \\frac{1}{n_c}\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t^2}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\frac{1}{n_t^2}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{n_t}{n n_c}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}2S_{0,1}\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 5}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}\\left(S_1^2 + S_0^2 - S_{\\tau_i}^2\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\left(\\frac{n_c}{n n_t} + \\frac{1}{n}\\right)S_1^2\n+ \\left(\\frac{n_t}{n n_c} + \\frac{1}{n}\\right) S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c + n_t}{n n_t} S_1^2\n+ \\frac{n_t + n_c}{n n_c} S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{S_1^2}{n_t}\n+ \\frac{S_0^2}{n_c}\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n\\end{align}\n\\tag{4.1}\\]\nThis is the sampling variance of \\(\\hat{\\tau}^{\\text{dm}}\\). It’s a theoretical quantity we cannot directly observe. However, we can observe treatment group means:\n\\[\n\\begin{align}\n\\overline{Y}_t = \\frac{1}{n_t}\\sum_{i=1}^n W_iY_i\n\\qquad\n\\overline{Y}_c = \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\end{align}\n\\] and treatment group variances:\n\\[\n\\begin{align}\ns_t^2 = \\frac{1}{n_t-1}\\sum_{i=1}^{n}W_i\\left(Y_i - \\overline{Y}_t\\right)^2\n\\qquad\ns_c^2 = \\frac{1}{n_c-1}\\sum_{i=1}^{n}(1-W_i)\\left(Y_i - \\overline{Y}_c\\right)^2.\n\\end{align}\n\\] It can be shown that the observed treatment group variances \\(s_t^2\\) and \\(s_c^2\\) are unbiased estimators of the sample variances \\(S_1^2\\) and \\(S_0^2\\) (see, for instance, Appendix A in Chapter 6 of Imbens and Rubin (2015)). The last term in\n\n\\(S_{\\tau_i}^2\\), is the variance of unit-level treatment effects, which is impossible to observe.\nAs a result, the most widely used estimator in practice is: \\[\n\\hat{\\mathbb{V}}\n= \\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}.\n\\] In our context, the main advantages of this estimator are:\n\nIf treatment effects are constant across units, then this is an unbiased estimator of the true sampling variance since in this case, \\(S^2_{\\tau_i} = 0\\).\nIf treatment effects are not constant, then this is a conservative estimator of the sampling variance (since \\(S_{\\tau_i}^2\\) is non-negative).\n\n\n\n\n\nDing, Peng. 2023. “A First Course in Causal Inference.” https://arxiv.org/abs/2305.18793.\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#variace-d",
    "href": "chapters/variance.html#variace-d",
    "title": "4  Variance",
    "section": "4.2 Variace d",
    "text": "4.2 Variace d\nWe can now start with our derivation.\nThe variance of \\(\\hat{\\tau}^{\\text{dm}}\\) is defined as:\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\end{align}\n\\]\nUsing SUTVA and the definition of \\(W_i\\) to write \\(\\sum_{W_i=1}Y_i(1)\\) as \\(\\sum_{i=1}^{n} W_iY_i(1)\\) for treatment units and use the corresponding expression for control units we get:\n$$ \\[\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n\n\\end{align}\\] $$\n…I’m here\nAll lemmas referred to below are here.\nWe can then calculate the variance as (I do not explicitly condition on \\(\\mathbf{n}\\) and \\(\\mathbf{Y(w)}\\) here to keep the notation lighter):\n\n\n\n\n\n\nNote 4.1: Derivation\n\n\n\n\n\nDerivation\n\\[\n\\begin{align}\n\\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i \\Bigl(W_i Y_i(1) + (1 - W_i) Y_i(0)\\Bigr) \\\\\n\\end{align}\n\\]\n\n\n\nSee Note 4.1\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1)\n- \\frac{1}{n_c}\\sum_{i=1}^n Y_i(0)\n+ \\frac{1}{n_c}\\sum_{i=1}^n W_iY_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i\\frac{Y_i(1)}{n_t}\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n+ \\sum_{i=1}^n W_i\\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&\\text{Dropping constant term}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n\\right)\n\\\\[5pt]\n&\\text{Demeaning (leaves variance unchanged)}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c} - \\left(\\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Using shorthands } Y_i^+ = Y_i(1)/n_t + Y_i(0)/n_c \\text{ and } \\overline{Y}^+ = \\overline{Y}(1)/n_t - \\overline{Y}(0)/n_c\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Rewriting variance in terms of covariance}\n\\\\[5pt]\n&=\n\\text{Cov}\\left(\n\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\\right),\n\\sum_{j=1}^n W_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(\nW_i \\left(Y_i^+ - \\overline{Y}^+\\right),\nW_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i^2\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 2}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 3}\n\\\\[5pt]\n&=\n\\sum_{i=1}^{n}\\left(\\frac{n_tn_c}{n^2}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\sum_{i=1}^{n}\\sum_{j \\neq i}\\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\\sum_{j \\neq i}\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&\\text{Lemma 4}\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+ \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2} + \\frac{n_tn_c}{n^2(n-1)}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c(n-1) + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{nn_tn_c - n_tn_c + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&\\text{Reverting to full notation and expanding square term}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\n- \\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\left(\\frac{Y_i(1)}{n_t} - \\frac{\\overline{Y}(1)}{n_t}\\right)\n+ \\left(\\frac{Y_i(0)}{n_c} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t}\\left(Y_i(1) - \\overline{Y}(1)\\right)\n+ \\frac{1}{n_c}\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t^2}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\frac{1}{n_t^2}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{n_t}{n n_c}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}2S_{0,1}\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 5}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}\\left(S_1^2 + S_0^2 - S_{\\tau_i}^2\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\left(\\frac{n_c}{n n_t} + \\frac{1}{n}\\right)S_1^2\n+ \\left(\\frac{n_t}{n n_c} + \\frac{1}{n}\\right) S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c + n_t}{n n_t} S_1^2\n+ \\frac{n_t + n_c}{n n_c} S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{S_1^2}{n_t}\n+ \\frac{S_0^2}{n_c}\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n\\end{align}\n\\tag{4.1}\\]\nThis is the sampling variance of \\(\\hat{\\tau}^{\\text{dm}}\\). It’s a theoretical quantity we cannot directly observe. However, we can observe treatment group means:\n\\[\n\\begin{align}\n\\overline{Y}_t = \\frac{1}{n_t}\\sum_{i=1}^n W_iY_i\n\\qquad\n\\overline{Y}_c = \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\end{align}\n\\] and treatment group variances:\n\\[\n\\begin{align}\ns_t^2 = \\frac{1}{n_t-1}\\sum_{i=1}^{n}W_i\\left(Y_i - \\overline{Y}_t\\right)^2\n\\qquad\ns_c^2 = \\frac{1}{n_c-1}\\sum_{i=1}^{n}(1-W_i)\\left(Y_i - \\overline{Y}_c\\right)^2.\n\\end{align}\n\\] It can be shown that the observed treatment group variances \\(s_t^2\\) and \\(s_c^2\\) are unbiased estimators of the sample variances \\(S_1^2\\) and \\(S_0^2\\) (see, for instance, Appendix A in Chapter 6 of Imbens and Rubin (2015)). The last term in\n\n\\(S_{\\tau_i}^2\\), is the variance of unit-level treatment effects, which is impossible to observe.\nAs a result, the most widely used estimator in practice is: \\[\n\\hat{\\mathbb{V}}\n= \\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}.\n\\] In our context, the main advantages of this estimator are:\n\nIf treatment effects are constant across units, then this is an unbiased estimator of the true sampling variance since in this case, \\(S^2_{\\tau_i} = 0\\).\nIf treatment effects are not constant, then this is a conservative estimator of the sampling variance (since \\(S_{\\tau_i}^2\\) is non-negative).\n\n\n\n\n\nDing, Peng. 2023. “A First Course in Causal Inference.” https://arxiv.org/abs/2305.18793.\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#variace-derivation",
    "href": "chapters/variance.html#variace-derivation",
    "title": "4  Variance",
    "section": "4.2 Variace derivation",
    "text": "4.2 Variace derivation\nWe can now start with our derivation.\nThe variance of \\(\\hat{\\tau}^{\\text{dm}}\\) is defined as:\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\end{align}\n\\]\nUsing SUTVA and the definition of \\(W_i\\) to write \\(\\sum_{W_i=1}Y_i(1)\\) as \\(\\sum_{i=1}^{n} W_iY_i(1)\\) for treatment units and use the corresponding expression for control units we get:\n$$ \\[\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n\n\\end{align}\\] $$\n…I’m here\nAll lemmas referred to below are here.\nWe can then calculate the variance as (I do not explicitly condition on \\(\\mathbf{n}\\) and \\(\\mathbf{Y(w)}\\) here to keep the notation lighter):\n\n\n\n\n\n\nNote 4.1: Derivation\n\n\n\n\n\nDerivation\n\\[\n\\begin{align}\n\\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i \\Bigl(W_i Y_i(1) + (1 - W_i) Y_i(0)\\Bigr) \\\\\n\\end{align}\n\\]\n\n\n\nSee Note 4.1\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1)\n- \\frac{1}{n_c}\\sum_{i=1}^n Y_i(0)\n+ \\frac{1}{n_c}\\sum_{i=1}^n W_iY_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i\\frac{Y_i(1)}{n_t}\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n+ \\sum_{i=1}^n W_i\\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&\\text{Dropping constant term}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n\\right)\n\\\\[5pt]\n&\\text{Demeaning (leaves variance unchanged)}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c} - \\left(\\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Using shorthands } Y_i^+ = Y_i(1)/n_t + Y_i(0)/n_c \\text{ and } \\overline{Y}^+ = \\overline{Y}(1)/n_t - \\overline{Y}(0)/n_c\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Rewriting variance in terms of covariance}\n\\\\[5pt]\n&=\n\\text{Cov}\\left(\n\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\\right),\n\\sum_{j=1}^n W_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(\nW_i \\left(Y_i^+ - \\overline{Y}^+\\right),\nW_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i^2\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 2}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 3}\n\\\\[5pt]\n&=\n\\sum_{i=1}^{n}\\left(\\frac{n_tn_c}{n^2}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\sum_{i=1}^{n}\\sum_{j \\neq i}\\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\\sum_{j \\neq i}\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&\\text{Lemma 4}\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+ \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2} + \\frac{n_tn_c}{n^2(n-1)}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c(n-1) + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{nn_tn_c - n_tn_c + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&\\text{Reverting to full notation and expanding square term}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\n- \\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\left(\\frac{Y_i(1)}{n_t} - \\frac{\\overline{Y}(1)}{n_t}\\right)\n+ \\left(\\frac{Y_i(0)}{n_c} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t}\\left(Y_i(1) - \\overline{Y}(1)\\right)\n+ \\frac{1}{n_c}\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t^2}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\frac{1}{n_t^2}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{n_t}{n n_c}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}2S_{0,1}\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 5}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}\\left(S_1^2 + S_0^2 - S_{\\tau_i}^2\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\left(\\frac{n_c}{n n_t} + \\frac{1}{n}\\right)S_1^2\n+ \\left(\\frac{n_t}{n n_c} + \\frac{1}{n}\\right) S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c + n_t}{n n_t} S_1^2\n+ \\frac{n_t + n_c}{n n_c} S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{S_1^2}{n_t}\n+ \\frac{S_0^2}{n_c}\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n\\end{align}\n\\tag{4.1}\\]\nThis is the sampling variance of \\(\\hat{\\tau}^{\\text{dm}}\\). It’s a theoretical quantity we cannot directly observe.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#estimating-var",
    "href": "chapters/variance.html#estimating-var",
    "title": "4  Variance",
    "section": "4.3 Estimating var",
    "text": "4.3 Estimating var\nHowever, we can observe treatment group means:\n\\[\n\\begin{align}\n\\overline{Y}_t = \\frac{1}{n_t}\\sum_{i=1}^n W_iY_i\n\\qquad\n\\overline{Y}_c = \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\end{align}\n\\] and treatment group variances:\n\\[\n\\begin{align}\ns_t^2 = \\frac{1}{n_t-1}\\sum_{i=1}^{n}W_i\\left(Y_i - \\overline{Y}_t\\right)^2\n\\qquad\ns_c^2 = \\frac{1}{n_c-1}\\sum_{i=1}^{n}(1-W_i)\\left(Y_i - \\overline{Y}_c\\right)^2.\n\\end{align}\n\\] It can be shown that the observed treatment group variances \\(s_t^2\\) and \\(s_c^2\\) are unbiased estimators of the sample variances \\(S_1^2\\) and \\(S_0^2\\) (see, for instance, Appendix A in Chapter 6 of Imbens and Rubin (2015)). The last term in\n\n\\(S_{\\tau_i}^2\\), is the variance of unit-level treatment effects, which is impossible to observe.\nAs a result, the most widely used estimator in practice is: \\[\n\\hat{\\mathbb{V}}\n= \\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}.\n\\] In our context, the main advantages of this estimator are:\n\nIf treatment effects are constant across units, then this is an unbiased estimator of the true sampling variance since in this case, \\(S^2_{\\tau_i} = 0\\).\nIf treatment effects are not constant, then this is a conservative estimator of the sampling variance (since \\(S_{\\tau_i}^2\\) is non-negative).\n\n\n\n\n\nDing, Peng. 2023. “A First Course in Causal Inference.” https://arxiv.org/abs/2305.18793.\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#estimating-variance",
    "href": "chapters/variance.html#estimating-variance",
    "title": "4  Variance",
    "section": "4.3 Estimating variance",
    "text": "4.3 Estimating variance\nHowever, we can observe treatment group means:\n\\[\n\\begin{align}\n\\overline{Y}_t = \\frac{1}{n_t}\\sum_{i=1}^n W_iY_i\n\\qquad\n\\overline{Y}_c = \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\end{align}\n\\] and treatment group variances:\n\\[\n\\begin{align}\ns_t^2 = \\frac{1}{n_t-1}\\sum_{i=1}^{n}W_i\\left(Y_i - \\overline{Y}_t\\right)^2\n\\qquad\ns_c^2 = \\frac{1}{n_c-1}\\sum_{i=1}^{n}(1-W_i)\\left(Y_i - \\overline{Y}_c\\right)^2.\n\\end{align}\n\\] It can be shown that the observed treatment group variances \\(s_t^2\\) and \\(s_c^2\\) are unbiased estimators of the sample variances \\(S_1^2\\) and \\(S_0^2\\) (see, for instance, Appendix A in Chapter 6 of Imbens and Rubin (2015)). The last term in\n\n\\(S_{\\tau_i}^2\\), is the variance of unit-level treatment effects, which is impossible to observe.\nAs a result, the most widely used estimator in practice is: \\[\n\\hat{\\mathbb{V}}\n= \\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}.\n\\] In our context, the main advantages of this estimator are:\n\nIf treatment effects are constant across units, then this is an unbiased estimator of the true sampling variance since in this case, \\(S^2_{\\tau_i} = 0\\).\nIf treatment effects are not constant, then this is a conservative estimator of the sampling variance (since \\(S_{\\tau_i}^2\\) is non-negative).\n\n\n\n\n\nDing, Peng. 2023. “A First Course in Causal Inference.” https://arxiv.org/abs/2305.18793.\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#variance-derivation",
    "href": "chapters/variance.html#variance-derivation",
    "title": "4  Variance",
    "section": "4.2 Variance derivation",
    "text": "4.2 Variance derivation\nWe now begin the derivation, which uses intermediary results labeled lemmas; their derivations appear at the bottom of the page and are linked from inside the main derivation.\nTo keep the notation simpler, I omit explicit conditioning on \\(\\mathbf{n}\\) and \\(\\mathbf{Y(w)}\\), though the conditioning is implicit throughout. I also define throughout \\[\nY_i^+ \\coloneqq \\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c},\n\\quad \\overline{Y}^+ \\coloneqq \\frac{\\overline{Y}(1)}{n_t} + \\frac{\\overline{Y}(0)}{n_c}.\n\\]\nStarting from the definition of our difference-in-means estimator, we get:\n\n \\[\n\\begin{align}\n\\mathbb{V}\\left(\\hat{\\tau}^{\\text{dm}}\\right)\n&= \\mathbb{V}\\left(\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\\right) \\\\[6pt]\n&\\href{#lemma-1}{=} \\mathbb{V}\\left(\\frac{1}{n_t}\\sum_{i=1}^n W_i Y_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i) Y_i\\right) \\\\[6pt]\n&\\href{#lemma-2}{=} \\mathbb{V}\\left(\\frac{1}{n_t}\\sum_{i=1}^n W_i Y_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i) Y_i(0)\\right) \\\\[6pt]\n&= \\mathbb{V}\\left(\\sum_{i=1}^n W_i \\frac{Y_i(1)}{n_t} + W_i \\frac{Y_i(0)}{n_c} - \\frac{Y_i(0)}{n_c}\\right) \\\\[6pt]\n&= \\mathbb{V}\\left(\\sum_{i=1}^n W_i Y_i^+ - \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\\right) \\\\[6pt]\n&= \\mathbb{V}\\left(\\sum_{i=1}^n W_i Y_i^+\\right) \\quad \\text{(drop constant)} \\\\[6pt]\n&= \\mathbb{V}\\left(\\sum_{i=1}^n W_i (Y_i^+ - \\overline{Y}^+)\\right) \\quad \\text{(demean)} \\\\[6pt]\n\\end{align}\n\\]\nExpressing the variance in terms of the covariance we get: \\[\n\\begin{align}\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i (Y_i^+ - \\overline{Y}^+)\\right)\n&= \\text{Cov}\\left(\n\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\\right),\n\\sum_{j=1}^n W_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n\\\\[6pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(\nW_i \\left(Y_i^+ - \\overline{Y}^+\\right),\nW_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right) \\\\[6pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\end{align}\n\\] Splitting the double sum into cases where \\(i=j\\) and where \\(j \\neq j\\) we get:\nI’m ere",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#d-derivation",
    "href": "chapters/variance.html#d-derivation",
    "title": "4  Variance",
    "section": "4.2 D derivation",
    "text": "4.2 D derivation\nWe can now start with our derivation.\nThe variance of \\(\\hat{\\tau}^{\\text{dm}}\\) is defined as:\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\end{align}\n\\]\nUsing SUTVA and the definition of \\(W_i\\) to write \\(\\sum_{W_i=1}Y_i(1)\\) as \\(\\sum_{i=1}^{n} W_iY_i(1)\\) for treatment units and use the corresponding expression for control units we get:\n$$ \\[\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n\n\\end{align}\\] $$\n…I’m here\nAll lemmas referred to below are here.\nWe can then calculate the variance as (I do not explicitly condition on \\(\\mathbf{n}\\) and \\(\\mathbf{Y(w)}\\) here to keep the notation lighter):\n\n\n\n\n\n\nNote 4.1: Derivation\n\n\n\n\n\nDerivation\n\\[\n\\begin{align}\n\\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i Y_i\n&= \\frac{1}{n_t}\\sum_{i=1}^{N} R_i W_i \\Bigl(W_i Y_i(1) + (1 - W_i) Y_i(0)\\Bigr) \\\\\n\\end{align}\n\\]\n\n\n\nSee Note 4.1\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{SUTVA}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1)\n- \\frac{1}{n_c}\\sum_{i=1}^n Y_i(0)\n+ \\frac{1}{n_c}\\sum_{i=1}^n W_iY_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i\\frac{Y_i(1)}{n_t}\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n+ \\sum_{i=1}^n W_i\\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&\\text{Dropping constant term}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n\\right)\n\\\\[5pt]\n&\\text{Demeaning (leaves variance unchanged)}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c} - \\left(\\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Using shorthands } Y_i^+ = Y_i(1)/n_t + Y_i(0)/n_c \\text{ and } \\overline{Y}^+ = \\overline{Y}(1)/n_t - \\overline{Y}(0)/n_c\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Rewriting variance in terms of covariance}\n\\\\[5pt]\n&=\n\\text{Cov}\\left(\n\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\\right),\n\\sum_{j=1}^n W_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(\nW_i \\left(Y_i^+ - \\overline{Y}^+\\right),\nW_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i^2\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 2}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 3}\n\\\\[5pt]\n&=\n\\sum_{i=1}^{n}\\left(\\frac{n_tn_c}{n^2}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\sum_{i=1}^{n}\\sum_{j \\neq i}\\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\\sum_{j \\neq i}\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&\\text{Lemma 4}\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+ \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2} + \\frac{n_tn_c}{n^2(n-1)}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c(n-1) + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{nn_tn_c - n_tn_c + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&\\text{Reverting to full notation and expanding square term}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\n- \\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\left(\\frac{Y_i(1)}{n_t} - \\frac{\\overline{Y}(1)}{n_t}\\right)\n+ \\left(\\frac{Y_i(0)}{n_c} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t}\\left(Y_i(1) - \\overline{Y}(1)\\right)\n+ \\frac{1}{n_c}\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t^2}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\frac{1}{n_t^2}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{n_t}{n n_c}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}2S_{0,1}\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 5}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}\\left(S_1^2 + S_0^2 - S_{\\tau_i}^2\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\left(\\frac{n_c}{n n_t} + \\frac{1}{n}\\right)S_1^2\n+ \\left(\\frac{n_t}{n n_c} + \\frac{1}{n}\\right) S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c + n_t}{n n_t} S_1^2\n+ \\frac{n_t + n_c}{n n_c} S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{S_1^2}{n_t}\n+ \\frac{S_0^2}{n_c}\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n\\end{align}\n\\tag{4.1}\\]\nThis is the sampling variance of \\(\\hat{\\tau}^{\\text{dm}}\\). It’s a theoretical quantity we cannot directly observe.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#estimation",
    "href": "chapters/variance.html#estimation",
    "title": "4  Variance",
    "section": "4.3 Estimation",
    "text": "4.3 Estimation\nHowever, we can observe treatment group means:\n\\[\n\\begin{align}\n\\overline{Y}_t = \\frac{1}{n_t}\\sum_{i=1}^n W_iY_i\n\\qquad\n\\overline{Y}_c = \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\end{align}\n\\] and treatment group variances:\n\\[\n\\begin{align}\ns_t^2 = \\frac{1}{n_t-1}\\sum_{i=1}^{n}W_i\\left(Y_i - \\overline{Y}_t\\right)^2\n\\qquad\ns_c^2 = \\frac{1}{n_c-1}\\sum_{i=1}^{n}(1-W_i)\\left(Y_i - \\overline{Y}_c\\right)^2.\n\\end{align}\n\\] It can be shown that the observed treatment group variances \\(s_t^2\\) and \\(s_c^2\\) are unbiased estimators of the sample variances \\(S_1^2\\) and \\(S_0^2\\) (see, for instance, Appendix A in Chapter 6 of Imbens and Rubin (2015)). The last term in\n\n\\(S_{\\tau_i}^2\\), is the variance of unit-level treatment effects, which is impossible to observe.\nAs a result, the most widely used estimator in practice is: \\[\n\\hat{\\mathbb{V}}\n= \\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}.\n\\] In our context, the main advantages of this estimator are:\n\nIf treatment effects are constant across units, then this is an unbiased estimator of the true sampling variance since in this case, \\(S^2_{\\tau_i} = 0\\).\nIf treatment effects are not constant, then this is a conservative estimator of the sampling variance (since \\(S_{\\tau_i}^2\\) is non-negative).\n\n\n\n\n\nDing, Peng. 2023. “A First Course in Causal Inference.” https://arxiv.org/abs/2305.18793.\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#vari",
    "href": "chapters/variance.html#vari",
    "title": "4  Variance",
    "section": "4.3 Vari",
    "text": "4.3 Vari\nHowever, we can observe treatment group means:\n\\[\n\\begin{align}\n\\overline{Y}_t = \\frac{1}{n_t}\\sum_{i=1}^n W_iY_i\n\\qquad\n\\overline{Y}_c = \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\end{align}\n\\] and treatment group variances:\n\\[\n\\begin{align}\ns_t^2 = \\frac{1}{n_t-1}\\sum_{i=1}^{n}W_i\\left(Y_i - \\overline{Y}_t\\right)^2\n\\qquad\ns_c^2 = \\frac{1}{n_c-1}\\sum_{i=1}^{n}(1-W_i)\\left(Y_i - \\overline{Y}_c\\right)^2.\n\\end{align}\n\\] It can be shown that the observed treatment group variances \\(s_t^2\\) and \\(s_c^2\\) are unbiased estimators of the sample variances \\(S_1^2\\) and \\(S_0^2\\) (see, for instance, Appendix A in Chapter 6 of Imbens and Rubin (2015)). The last term in\n\n\\(S_{\\tau_i}^2\\), is the variance of unit-level treatment effects, which is impossible to observe.\nAs a result, the most widely used estimator in practice is: \\[\n\\hat{\\mathbb{V}}\n= \\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}.\n\\] In our context, the main advantages of this estimator are:\n\nIf treatment effects are constant across units, then this is an unbiased estimator of the true sampling variance since in this case, \\(S^2_{\\tau_i} = 0\\).\nIf treatment effects are not constant, then this is a conservative estimator of the sampling variance (since \\(S_{\\tau_i}^2\\) is non-negative).\n\n\n\n\n\nDing, Peng. 2023. “A First Course in Causal Inference.” https://arxiv.org/abs/2305.18793.\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#variance-estima",
    "href": "chapters/variance.html#variance-estima",
    "title": "4  Variance",
    "section": "4.3 Variance estima",
    "text": "4.3 Variance estima\nHowever, we can observe treatment group means:\n\\[\n\\begin{align}\n\\overline{Y}_t = \\frac{1}{n_t}\\sum_{i=1}^n W_iY_i\n\\qquad\n\\overline{Y}_c = \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\end{align}\n\\] and treatment group variances:\n\\[\n\\begin{align}\ns_t^2 = \\frac{1}{n_t-1}\\sum_{i=1}^{n}W_i\\left(Y_i - \\overline{Y}_t\\right)^2\n\\qquad\ns_c^2 = \\frac{1}{n_c-1}\\sum_{i=1}^{n}(1-W_i)\\left(Y_i - \\overline{Y}_c\\right)^2.\n\\end{align}\n\\] It can be shown that the observed treatment group variances \\(s_t^2\\) and \\(s_c^2\\) are unbiased estimators of the sample variances \\(S_1^2\\) and \\(S_0^2\\) (see, for instance, Appendix A in Chapter 6 of Imbens and Rubin (2015)). The last term in\n\n\\(S_{\\tau_i}^2\\), is the variance of unit-level treatment effects, which is impossible to observe.\nAs a result, the most widely used estimator in practice is: \\[\n\\hat{\\mathbb{V}}\n= \\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}.\n\\] In our context, the main advantages of this estimator are:\n\nIf treatment effects are constant across units, then this is an unbiased estimator of the true sampling variance since in this case, \\(S^2_{\\tau_i} = 0\\).\nIf treatment effects are not constant, then this is a conservative estimator of the sampling variance (since \\(S_{\\tau_i}^2\\) is non-negative).\n\n\n\n\n\nDing, Peng. 2023. “A First Course in Causal Inference.” https://arxiv.org/abs/2305.18793.\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#variance-estimation",
    "href": "chapters/variance.html#variance-estimation",
    "title": "4  Variance",
    "section": "4.4 Variance estimation",
    "text": "4.4 Variance estimation\nHowever, we can observe treatment group means:\n\\[\n\\begin{align}\n\\overline{Y}_t = \\frac{1}{n_t}\\sum_{i=1}^n W_iY_i\n\\qquad\n\\overline{Y}_c = \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\end{align}\n\\] and treatment group variances:\n\\[\n\\begin{align}\ns_t^2 = \\frac{1}{n_t-1}\\sum_{i=1}^{n}W_i\\left(Y_i - \\overline{Y}_t\\right)^2\n\\qquad\ns_c^2 = \\frac{1}{n_c-1}\\sum_{i=1}^{n}(1-W_i)\\left(Y_i - \\overline{Y}_c\\right)^2.\n\\end{align}\n\\] It can be shown that the observed treatment group variances \\(s_t^2\\) and \\(s_c^2\\) are unbiased estimators of the sample variances \\(S_1^2\\) and \\(S_0^2\\) (see, for instance, Appendix A in Chapter 6 of Imbens and Rubin (2015)). The last term in\n\n\\(S_{\\tau_i}^2\\), is the variance of unit-level treatment effects, which is impossible to observe.\nAs a result, the most widely used estimator in practice is: \\[\n\\hat{\\mathbb{V}}\n= \\frac{s_t^2}{n_t} + \\frac{s_c^2}{n_c}.\n\\] In our context, the main advantages of this estimator are:\n\nIf treatment effects are constant across units, then this is an unbiased estimator of the true sampling variance since in this case, \\(S^2_{\\tau_i} = 0\\).\nIf treatment effects are not constant, then this is a conservative estimator of the sampling variance (since \\(S_{\\tau_i}^2\\) is non-negative).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#note-1",
    "href": "chapters/variance.html#note-1",
    "title": "4  Variance",
    "section": "4.3 Note 1",
    "text": "4.3 Note 1\n\n\n\n\n\n\nNote 1\n\n\n\n\n\nGiven that \\(W_i=1\\) for treatment units and \\(W_i=0\\) for control units, we can calculate treatment group means by summing over all units and using \\(W_i\\) to “pick out” the relevant units for each treatment group so that we have: \\[\n\\begin{align}\n\\hat{\\tau}^{\\text{dm}}\n&=\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\\\[5pt]\n&=\n\\frac{1}{n_t}\\sum_{i=1}^{n}W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^{n}(1-W_i)Y_i\n\\end{align}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#note",
    "href": "chapters/variance.html#note",
    "title": "4  Variance",
    "section": "4.4 Note",
    "text": "4.4 Note\n\n\n\n\n\n\nNote 2\n\n\n\n\n\nThis step uses SUTVA which – if it holds – implies that: \\[\nY_i = Y_i(W_i) = \\begin{cases}\n   Y_i(1) & \\text{if } W_i = 1 \\\\\n   Y_i(0)       & \\text{if } W_i = 0,\n  \\end{cases}\n\\]\nSee here for a detailed discussion.\n\n\n\nThis is the sampling variance of \\(\\hat{\\tau}^{\\text{dm}}\\). It’s a theoretical quantity we cannot directly observe.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#note-2",
    "href": "chapters/variance.html#note-2",
    "title": "4  Variance",
    "section": "4.4 Note 2",
    "text": "4.4 Note 2\n\n\n\n\n\n\nNote 2\n\n\n\n\n\nThis step uses SUTVA which – if it holds – implies that: \\[\nY_i = Y_i(W_i) = \\begin{cases}\n   Y_i(1) & \\text{if } W_i = 1 \\\\\n   Y_i(0)       & \\text{if } W_i = 0,\n  \\end{cases}\n\\]\nSee here for a detailed discussion.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#example-calculation",
    "href": "chapters/variance.html#example-calculation",
    "title": "4  Variance",
    "section": "4.3 Example Calculation",
    "text": "4.3 Example Calculation\n \\[\n\\begin{align}\nP(A \\mid B) &= \\frac{P(A \\cap B)}{P(B)} \\\\\n&\\text{(see \\href{#conditioning-details}{Appendix})}\n\\end{align}\n\\]\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&\\text{Note 1 \\href{#note-1}{Note 1})}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{Note 2}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1)\n- \\frac{1}{n_c}\\sum_{i=1}^n Y_i(0)\n+ \\frac{1}{n_c}\\sum_{i=1}^n W_iY_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i\\frac{Y_i(1)}{n_t}\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n+ \\sum_{i=1}^n W_i\\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&\\text{Dropping constant term}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n\\right)\n\\\\[5pt]\n&\\text{Demeaning (leaves variance unchanged)}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c} - \\left(\\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Using shorthands } Y_i^+ = Y_i(1)/n_t + Y_i(0)/n_c \\text{ and } \\overline{Y}^+ = \\overline{Y}(1)/n_t - \\overline{Y}(0)/n_c\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Rewriting variance in terms of covariance}\n\\\\[5pt]\n&=\n\\text{Cov}\\left(\n\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\\right),\n\\sum_{j=1}^n W_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(\nW_i \\left(Y_i^+ - \\overline{Y}^+\\right),\nW_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i^2\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 2}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 3}\n\\\\[5pt]\n&=\n\\sum_{i=1}^{n}\\left(\\frac{n_tn_c}{n^2}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\sum_{i=1}^{n}\\sum_{j \\neq i}\\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\\sum_{j \\neq i}\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&\\text{Lemma 4}\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+ \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2} + \\frac{n_tn_c}{n^2(n-1)}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c(n-1) + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{nn_tn_c - n_tn_c + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&\\text{Reverting to full notation and expanding square term}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\n- \\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\left(\\frac{Y_i(1)}{n_t} - \\frac{\\overline{Y}(1)}{n_t}\\right)\n+ \\left(\\frac{Y_i(0)}{n_c} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t}\\left(Y_i(1) - \\overline{Y}(1)\\right)\n+ \\frac{1}{n_c}\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t^2}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\frac{1}{n_t^2}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{n_t}{n n_c}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}2S_{0,1}\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 5}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}\\left(S_1^2 + S_0^2 - S_{\\tau_i}^2\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\left(\\frac{n_c}{n n_t} + \\frac{1}{n}\\right)S_1^2\n+ \\left(\\frac{n_t}{n n_c} + \\frac{1}{n}\\right) S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c + n_t}{n n_t} S_1^2\n+ \\frac{n_t + n_c}{n n_c} S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{S_1^2}{n_t}\n+ \\frac{S_0^2}{n_c}\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n\\end{align}\n\\tag{4.1}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#conditioning-details",
    "href": "chapters/variance.html#conditioning-details",
    "title": "4  Variance",
    "section": "4.4 Appendix on Conditioning",
    "text": "4.4 Appendix on Conditioning\nMore details about the conditioning steps.\nThis is the sampling variance of \\(\\hat{\\tau}^{\\text{dm}}\\). It’s a theoretical quantity we cannot directly observe.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#note-details",
    "href": "chapters/variance.html#note-details",
    "title": "4  Variance",
    "section": "4.4 Note 1",
    "text": "4.4 Note 1\n\n\n\n\n\n\nNote 1\n\n\n\n\n\nGiven that \\(W_i=1\\) for treatment units and \\(W_i=0\\) for control units, we can calculate treatment group means by summing over all units and using \\(W_i\\) to “pick out” the relevant units for each treatment group so that we have: \\[\n\\begin{align}\n\\hat{\\tau}^{\\text{dm}}\n&=\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\\\[5pt]\n&=\n\\frac{1}{n_t}\\sum_{i=1}^{n}W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^{n}(1-W_i)Y_i\n\\end{align}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#note-1-details",
    "href": "chapters/variance.html#note-1-details",
    "title": "4  Variance",
    "section": "4.4 Note 1",
    "text": "4.4 Note 1\n\n\n\n\n\n\nNote 1\n\n\n\n\n\nGiven that \\(W_i=1\\) for treatment units and \\(W_i=0\\) for control units, we can calculate treatment group means by summing over all units and using \\(W_i\\) to “pick out” the relevant units for each treatment group so that we have: \\[\n\\begin{align}\n\\hat{\\tau}^{\\text{dm}}\n&=\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\\\[5pt]\n&=\n\\frac{1}{n_t}\\sum_{i=1}^{n}W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^{n}(1-W_i)Y_i\n\\end{align}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#lemma-1",
    "href": "chapters/variance.html#lemma-1",
    "title": "4  Variance",
    "section": "4.3 Lemma 1",
    "text": "4.3 Lemma 1\nGiven that \\(W_i=1\\) for treatment units and \\(W_i=0\\) for control units, we can calculate treatment group means by summing over all units and using \\(W_i\\) to “pick out” the relevant units for each treatment group so that we have: \\[\n\\begin{align}\n\\hat{\\tau}^{\\text{dm}}\n&=\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\\\[5pt]\n&=\n\\frac{1}{n_t}\\sum_{i=1}^{n}W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^{n}(1-W_i)Y_i\n\\end{align}\n\\] :::",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#lemma",
    "href": "chapters/variance.html#lemma",
    "title": "4  Variance",
    "section": "4.3 Lemma",
    "text": "4.3 Lemma\n\n4.3.1 Lemma 1\nGiven that \\(W_i=1\\) for treatment units and \\(W_i=0\\) for control units, we can calculate treatment group means by summing over all units and using \\(W_i\\) to “pick out” the relevant units for each treatment group so that we have: \\[\n\\begin{align}\n\\hat{\\tau}^{\\text{dm}}\n&=\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\\\[5pt]\n&=\n\\frac{1}{n_t}\\sum_{i=1}^{n}W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^{n}(1-W_i)Y_i\n\\end{align}\n\\] :::",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#lemmas",
    "href": "chapters/variance.html#lemmas",
    "title": "4  Variance",
    "section": "4.3 Lemmas",
    "text": "4.3 Lemmas\n\n4.3.1 Lemma 1\nGiven that \\(W_i=1\\) for treatment units and \\(W_i=0\\) for control units, we can calculate treatment group means by summing over all units and using \\(W_i\\) to “pick out” the relevant units for each treatment group so that we have: \\[\n\\begin{align}\n\\hat{\\tau}^{\\text{dm}}\n&=\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\\\[5pt]\n&=\n\\frac{1}{n_t}\\sum_{i=1}^{n}W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^{n}(1-W_i)Y_i\n\\end{align}\n\\] ↩︎️\n\n\n4.3.2 Lemma 2\nThis step uses SUTVA which – if it holds – implies that: \\[\nY_i = Y_i(W_i) = \\begin{cases}\n   Y_i(1) & \\text{if } W_i = 1 \\\\\n   Y_i(0)       & \\text{if } W_i = 0\n  \\end{cases}\n\\]↩︎️\n\n\n4.3.3 Lemma 3\nStep-by-step, we have: \\[\n\\begin{align}\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i (Y_i^+ - \\overline{Y}^+)\\right)\n&= \\text{Cov}\\left(\n\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\\right),\n\\sum_{j=1}^n W_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n\\\\[6pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(\nW_i \\left(Y_i^+ - \\overline{Y}^+\\right),\nW_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right) \\\\[6pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\end{align}\n\\] ↩︎️\n\n\n\n\nDing, Peng. 2023. “A First Course in Causal Inference.” https://arxiv.org/abs/2305.18793.\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#o",
    "href": "chapters/variance.html#o",
    "title": "4  Variance",
    "section": "4.3 O",
    "text": "4.3 O\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&\\text{\\href{#lemma-1}{Lemma 1}}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{\\href{#lemma-2}{Lemma 2}}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1)\n- \\frac{1}{n_c}\\sum_{i=1}^n Y_i(0)\n+ \\frac{1}{n_c}\\sum_{i=1}^n W_iY_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i\\frac{Y_i(1)}{n_t}\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n+ \\sum_{i=1}^n W_i\\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&\\text{Drop constant (variance unchanged)}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n\\right)\n\\\\[5pt]\n&\\text{Demean (variance unchanged)}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c} - \\left(\\frac{\\overline{Y}(1)}{n_t} + \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Using shorthands } Y_i^+ \\coloneqq Y_i(1)/n_t + Y_i(0)/n_c \\text{ and } \\overline{Y}^+ \\coloneqq \\overline{Y}(1)/n_t + \\overline{Y}(0)/n_c\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Rewriting variance in terms of covariance}\n\\\\[5pt]\n&=\n\\text{Cov}\\left(\n\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\\right),\n\\sum_{j=1}^n W_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(\nW_i \\left(Y_i^+ - \\overline{Y}^+\\right),\nW_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i^2\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 2}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 3}\n\\\\[5pt]\n&=\n\\sum_{i=1}^{n}\\left(\\frac{n_tn_c}{n^2}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\sum_{i=1}^{n}\\sum_{j \\neq i}\\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\\sum_{j \\neq i}\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&\\text{Lemma 4}\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+ \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2} + \\frac{n_tn_c}{n^2(n-1)}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c(n-1) + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{nn_tn_c - n_tn_c + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&\\text{Reverting to full notation and expanding square term}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c} - \\left(\\frac{\\overline{Y}(1)}{n_t} + \\frac{\\overline{Y}(0)}{n_c}\\right)\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\n- \\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\left(\\frac{Y_i(1)}{n_t} - \\frac{\\overline{Y}(1)}{n_t}\\right)\n+ \\left(\\frac{Y_i(0)}{n_c} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t}\\left(Y_i(1) - \\overline{Y}(1)\\right)\n+ \\frac{1}{n_c}\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t^2}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\frac{1}{n_t^2}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{n_t}{n n_c}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}2S_{0,1}\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 5}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}\\left(S_1^2 + S_0^2 - S_{\\tau_i}^2\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\left(\\frac{n_c}{n n_t} + \\frac{1}{n}\\right)S_1^2\n+ \\left(\\frac{n_t}{n n_c} + \\frac{1}{n}\\right) S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c + n_t}{n n_t} S_1^2\n+ \\frac{n_t + n_c}{n n_c} S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{S_1^2}{n_t}\n+ \\frac{S_0^2}{n_c}\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n\\end{align}\n\\tag{4.1}\\]\nThis is the sampling variance of \\(\\hat{\\tau}^{\\text{dm}}\\). It’s a theoretical quantity we cannot directly observe.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  },
  {
    "objectID": "chapters/variance.html#old-derivation",
    "href": "chapters/variance.html#old-derivation",
    "title": "4  Variance",
    "section": "4.3 Old derivation",
    "text": "4.3 Old derivation\n\\[\n\\begin{align}\n\\mathbb{V}\\left(\n\\hat{\\tau}^{\\text{dm}}\n\\right)\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{W_i=1}Y_i - \\frac{1}{n_c}\\sum_{W_i=0}Y_i\n\\right)\n\\\\[5pt]\n&\\text{\\href{#lemma-1}{Lemma 1}}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i\n\\right)\n\\\\[5pt]\n&\\text{\\href{#lemma-2}{Lemma 2}}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1) - \\frac{1}{n_c}\\sum_{i=1}^n (1-W_i)Y_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\frac{1}{n_t}\\sum_{i=1}^n W_iY_i(1)\n- \\frac{1}{n_c}\\sum_{i=1}^n Y_i(0)\n+ \\frac{1}{n_c}\\sum_{i=1}^n W_iY_i(0)\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i\\frac{Y_i(1)}{n_t}\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n+ \\sum_{i=1}^n W_i\\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n- \\sum_{i=1}^n \\frac{Y_i(0)}{n_c}\n\\right)\n\\\\[5pt]\n&\\text{Drop constant (variance unchanged)}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\n\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\\right)\n\\right)\n\\\\[5pt]\n&\\text{Demean (variance unchanged)}\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c} - \\left(\\frac{\\overline{Y}(1)}{n_t} + \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Using shorthands } Y_i^+ \\coloneqq Y_i(1)/n_t + Y_i(0)/n_c \\text{ and } \\overline{Y}^+ \\coloneqq \\overline{Y}(1)/n_t + \\overline{Y}(0)/n_c\n\\\\[5pt]\n&=\n\\mathbb{V}\\left(\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\n\\right)\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Rewriting variance in terms of covariance}\n\\\\[5pt]\n&=\n\\text{Cov}\\left(\n\\sum_{i=1}^n W_i \\left(Y_i^+ - \\overline{Y}^+\\right),\n\\sum_{j=1}^n W_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(\nW_i \\left(Y_i^+ - \\overline{Y}^+\\right),\nW_j \\left(Y_j^+ - \\overline{Y}^+\\right)\n\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n \\sum_{j=1}^n\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i^2\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 2}\n\\\\[5pt]\n&=\n\\sum_{i=1}^n\n\\mathbb{V}\\left(W_i\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+\n\\sum_{i=1}^n \\sum_{j \\neq i}\n\\text{Cov}\\left(W_i, W_j \\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\n\\left(Y_j^+ - \\overline{Y}^+\\right)\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 3}\n\\\\[5pt]\n&=\n\\sum_{i=1}^{n}\\left(\\frac{n_tn_c}{n^2}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\sum_{i=1}^{n}\\sum_{j \\neq i}\\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n- \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\\sum_{j \\neq i}\n\\left(Y_i^+ - \\overline{Y}^+\\right)\\left(Y_j^+ - \\overline{Y}^+\\right)\n\\\\[5pt]\n&\\text{Lemma 4}\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n+ \\left(\\frac{n_tn_c}{n^2(n-1)}\\right)\\sum_{i=1}^{n}\n\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n\\\\[5pt]\n&=\n\\left(\\frac{n_tn_c}{n^2} + \\frac{n_tn_c}{n^2(n-1)}\\right)\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c(n-1) + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{nn_tn_c - n_tn_c + n_tn_c}{n^2(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(Y_i^+ - \\overline{Y}^+\\right)^2\n&\\\\[5pt]\n&\\text{Reverting to full notation and expanding square term}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c} - \\left(\\frac{\\overline{Y}(1)}{n_t} + \\frac{\\overline{Y}(0)}{n_c}\\right)\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\\frac{Y_i(1)}{n_t} + \\frac{Y_i(0)}{n_c}\n- \\frac{\\overline{Y}(1)}{n_t} - \\frac{\\overline{Y}(0)}{n_c}\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\left(\\frac{Y_i(1)}{n_t} - \\frac{\\overline{Y}(1)}{n_t}\\right)\n+ \\left(\\frac{Y_i(0)}{n_c} - \\frac{\\overline{Y}(0)}{n_c}\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t}\\left(Y_i(1) - \\overline{Y}(1)\\right)\n+ \\frac{1}{n_c}\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)^2\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\sum_{i=1}^{n}\\left(\n\\frac{1}{n_t^2}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_tn_c}{n(n-1)}\\left[\n\\frac{1}{n_t^2}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{1}{n_c^2}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n_t n_c}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n\\right]\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)^2\n+ \\frac{n_t}{n n_c}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(0) - \\overline{Y}(0)\\right)^2\n+ \\frac{2}{n}\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(Y_i(1) - \\overline{Y}(1)\\right)\\left(Y_i(0) - \\overline{Y}(0)\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}2S_{0,1}\n&\\text{}\n\\\\[5pt]\n&\\text{Lemma 5}\n\\\\[5pt]\n&=\n\\frac{n_c}{n n_t}S_1^2\n+ \\frac{n_t}{n n_c}S_0^2\n+ \\frac{1}{n}\\left(S_1^2 + S_0^2 - S_{\\tau_i}^2\\right)\n&\\text{}\n\\\\[5pt]\n&=\n\\left(\\frac{n_c}{n n_t} + \\frac{1}{n}\\right)S_1^2\n+ \\left(\\frac{n_t}{n n_c} + \\frac{1}{n}\\right) S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{n_c + n_t}{n n_t} S_1^2\n+ \\frac{n_t + n_c}{n n_c} S_0^2\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n&=\n\\frac{S_1^2}{n_t}\n+ \\frac{S_0^2}{n_c}\n- \\frac{S_{\\tau_i}^2}{n}\n&\\text{}\n\\\\[5pt]\n\\end{align}\n\\tag{4.1}\\]\nThis is the sampling variance of \\(\\hat{\\tau}^{\\text{dm}}\\). It’s a theoretical quantity we cannot directly observe.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Variance</span>"
    ]
  }
]