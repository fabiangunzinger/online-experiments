<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>6&nbsp; Statistics foundations ‚Äì Online experiments</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/lemmas.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../custom.scss">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/stats_foundations.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Statistics foundations</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Online experiments</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/stats_of_online_experiments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The stats of online experiments</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/power.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Power</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/threats_to_validity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Threats to validity</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/experiment_setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Experiment setup</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/lemmas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Lemmas</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/stats_foundations.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Statistics foundations</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#other-assumptions-in-casusal-inference" id="toc-other-assumptions-in-casusal-inference" class="nav-link active" data-scroll-target="#other-assumptions-in-casusal-inference"><span class="header-section-number">6.1</span> Other assumptions in casusal inference</a></li>
  <li><a href="#modes-of-inference" id="toc-modes-of-inference" class="nav-link" data-scroll-target="#modes-of-inference"><span class="header-section-number">6.2</span> Modes of inference</a>
  <ul class="collapse">
  <li><a href="#good-chat-gpt-explanation" id="toc-good-chat-gpt-explanation" class="nav-link" data-scroll-target="#good-chat-gpt-explanation"><span class="header-section-number">6.2.1</span> Good chat GPT explanation</a></li>
  <li><a href="#other-chat-conversation-what-precisely-makes-the-approach-in-the-main-text-design-based" id="toc-other-chat-conversation-what-precisely-makes-the-approach-in-the-main-text-design-based" class="nav-link" data-scroll-target="#other-chat-conversation-what-precisely-makes-the-approach-in-the-main-text-design-based"><span class="header-section-number">6.2.2</span> Other chat conversation: What <em>precisely</em> makes the approach in the main text <strong>design-based</strong>?</a></li>
  <li><a href="#expectation-taken-over-assignment-mechanism" id="toc-expectation-taken-over-assignment-mechanism" class="nav-link" data-scroll-target="#expectation-taken-over-assignment-mechanism"><span class="header-section-number">6.2.3</span> üîπ 1. Expectation taken over assignment mechanism</a></li>
  <li><a href="#unbiasedness-is-shown-by-averaging-over-random-assignments" id="toc-unbiasedness-is-shown-by-averaging-over-random-assignments" class="nav-link" data-scroll-target="#unbiasedness-is-shown-by-averaging-over-random-assignments"><span class="header-section-number">6.2.4</span> üîπ 2. Unbiasedness is shown by averaging over random assignments</a></li>
  <li><a href="#no-assumptions-about-ignorability-or-conditional-independence" id="toc-no-assumptions-about-ignorability-or-conditional-independence" class="nav-link" data-scroll-target="#no-assumptions-about-ignorability-or-conditional-independence"><span class="header-section-number">6.2.5</span> üîπ 3. No assumptions about ignorability or conditional independence</a></li>
  <li><a href="#in-contrast-identification-based-observational-approach" id="toc-in-contrast-identification-based-observational-approach" class="nav-link" data-scroll-target="#in-contrast-identification-based-observational-approach"><span class="header-section-number">6.2.6</span> üß≠ In contrast: Identification-based (observational) approach</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">6.2.7</span> üìå Summary</a></li>
  </ul></li>
  <li><a href="#sampling" id="toc-sampling" class="nav-link" data-scroll-target="#sampling"><span class="header-section-number">6.3</span> Sampling</a></li>
  <li><a href="#selection-bias" id="toc-selection-bias" class="nav-link" data-scroll-target="#selection-bias"><span class="header-section-number">6.4</span> Selection bias</a>
  <ul class="collapse">
  <li><a href="#sampling-distribution" id="toc-sampling-distribution" class="nav-link" data-scroll-target="#sampling-distribution"><span class="header-section-number">6.4.1</span> Sampling distribution</a></li>
  <li><a href="#variance-and-standard-error" id="toc-variance-and-standard-error" class="nav-link" data-scroll-target="#variance-and-standard-error"><span class="header-section-number">6.4.2</span> Variance and standard error</a></li>
  <li><a href="#example-code" id="toc-example-code" class="nav-link" data-scroll-target="#example-code"><span class="header-section-number">6.4.3</span> Example code</a></li>
  </ul></li>
  <li><a href="#law-of-large-numbers-and-central-limit-theorems" id="toc-law-of-large-numbers-and-central-limit-theorems" class="nav-link" data-scroll-target="#law-of-large-numbers-and-central-limit-theorems"><span class="header-section-number">6.5</span> Law of large numbers and central limit theorems</a></li>
  <li><a href="#degrees-of-freedom" id="toc-degrees-of-freedom" class="nav-link" data-scroll-target="#degrees-of-freedom"><span class="header-section-number">6.6</span> Degrees of freedom</a></li>
  <li><a href="#the-bootstrap" id="toc-the-bootstrap" class="nav-link" data-scroll-target="#the-bootstrap"><span class="header-section-number">6.7</span> The bootstrap</a></li>
  <li><a href="#combination-vs-permutation" id="toc-combination-vs-permutation" class="nav-link" data-scroll-target="#combination-vs-permutation"><span class="header-section-number">6.8</span> Combination vs Permutation</a></li>
  <li><a href="#moments-of-random-variables" id="toc-moments-of-random-variables" class="nav-link" data-scroll-target="#moments-of-random-variables"><span class="header-section-number">6.9</span> Moments of random variables</a></li>
  <li><a href="#variance-and-covariance-properties" id="toc-variance-and-covariance-properties" class="nav-link" data-scroll-target="#variance-and-covariance-properties"><span class="header-section-number">6.10</span> Variance and covariance properties</a></li>
  <li><a href="#confidence-intervals" id="toc-confidence-intervals" class="nav-link" data-scroll-target="#confidence-intervals"><span class="header-section-number">6.11</span> Confidence intervals</a></li>
  <li><a href="#commonly-used-distributions" id="toc-commonly-used-distributions" class="nav-link" data-scroll-target="#commonly-used-distributions"><span class="header-section-number">6.12</span> Commonly used distributions</a>
  <ul class="collapse">
  <li><a href="#commonly-used-probability-distributions" id="toc-commonly-used-probability-distributions" class="nav-link" data-scroll-target="#commonly-used-probability-distributions"><span class="header-section-number">6.12.1</span> Commonly used probability distributions</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Statistics foundations</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="other-assumptions-in-casusal-inference" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="other-assumptions-in-casusal-inference"><span class="header-section-number">6.1</span> Other assumptions in casusal inference</h2>
</section>
<section id="modes-of-inference" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="modes-of-inference"><span class="header-section-number">6.2</span> Modes of inference</h2>
<ul>
<li>see abadie2020sampling ### From athey2017econometrics (my notes)</li>
</ul>
<p>Sampling based: - Also model-based (why?) - This is the classical mode of inference in statistics and observational studies - Randomness results from random sampling. - We assume that the population at hand is a random subsample of a (much) larger population, so that individual values are random. - For instance, in <span class="math inline">\(\bar{X} = \frac{1}{n}\sum_{i=1}^{n}X_i\)</span> we treat each <span class="math inline">\(X_i\)</span> as a random variable. - In the context of experimentation, where we can write the treatment group mean as <span class="math inline">\(\bar{Y}_t = \frac{1}{n_t}\sum_{i=1}^{n}W_iY_i\)</span>, we treat the <span class="math inline">\(W_i\)</span>s as fixed and <span class="math inline">\(Y_i\)</span>s as random (‚Äúfor each reserved slot in the treatment group, what is the value of the unit we randomly selected for that slot?‚Äù) Randomisation based:</p>
<section id="good-chat-gpt-explanation" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="good-chat-gpt-explanation"><span class="header-section-number">6.2.1</span> Good chat GPT explanation</h3>
<p><em>Written by ChatGPT (OpenAI), March 2025.</em></p>
<p>Why Do the Terms <em>Design-Based</em> and <em>Model-Based</em> Make Sense?</p>
<ul>
<li>Great question ‚Äî the terms <strong>design-based</strong> and <strong>model-based</strong> refer to <strong>where the uncertainty comes from</strong> and <strong>what justifies your inference</strong> in a causal or statistical analysis. The names make intuitive sense once you understand their core logic:</li>
</ul>
<p><strong>Design-Based Inference</strong>: Uncertainty from the Design</p>
<p>Why ‚Äúdesign-based‚Äù? - Because <strong>inference is justified by the experimental design itself</strong> ‚Äî specifically, the <strong>randomization</strong>. - The potential outcomes are assumed <strong>fixed</strong> (part of the ‚Äúscience‚Äù in Rubin‚Äôs terms). - The only randomness comes from <strong>how the treatment was assigned</strong>, which is determined by the <strong>experimental design</strong> (e.g., flipping a fair coin).</p>
<blockquote class="blockquote">
<p>üìå The inference relies solely on the known <strong>design of the experiment</strong>, not on any model of the outcomes.</p>
</blockquote>
<p>Analogy: - You‚Äôre not modeling anything ‚Äî you‚Äôre just using the fact that ‚Äúwe randomly assigned treatment, so any observed differences must be causally interpretable.‚Äù</p>
<p><strong>Model-Based Inference</strong>: Uncertainty from a Statistical Model</p>
<p>Why ‚Äúmodel-based‚Äù? - Because <strong>inference is justified by a statistical model</strong> for the data-generating process ‚Äî not just the design. - Units are thought of as drawn <strong>randomly from a population</strong>. - Potential outcomes are <strong>random variables</strong>. - You specify models for those outcomes: ( Y_i(1), Y_i(0) )</p>
<blockquote class="blockquote">
<p>üìå The validity of your inference depends on the <strong>correctness of the model</strong>, not just the study design.</p>
</blockquote>
<p>Analogy: - You‚Äôre saying: ‚ÄúLet me make assumptions about how the data are generated, and then use probability to estimate causal effects based on those assumptions.‚Äù</p>
<p>Summary Table</p>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 43%">
<col style="width: 22%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th>Term</th>
<th>Why It Makes Sense</th>
<th>Where Uncertainty Comes From</th>
<th>Key Assumption</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Design-Based</strong></td>
<td>Relies on <strong>experimental design</strong> (e.g.&nbsp;randomization)</td>
<td>Assignment mechanism</td>
<td>Randomized treatment</td>
</tr>
<tr class="even">
<td><strong>Model-Based</strong></td>
<td>Relies on <strong>statistical models</strong> of outcomes</td>
<td>Sampling or model error</td>
<td>Correct model specification</td>
</tr>
</tbody>
</table>
<p>Why These Terms Are Intuitive - <strong>Design-based</strong>: You get inference ‚Äúfor free‚Äù from the <strong>structure of your design</strong>, without modeling outcomes. - <strong>Model-based</strong>: You infer causal effects <strong>by assuming a model</strong> ‚Äî inference comes from the model, not the design.</p>
</section>
<section id="other-chat-conversation-what-precisely-makes-the-approach-in-the-main-text-design-based" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2" class="anchored" data-anchor-id="other-chat-conversation-what-precisely-makes-the-approach-in-the-main-text-design-based"><span class="header-section-number">6.2.2</span> Other chat conversation: What <em>precisely</em> makes the approach in the main text <strong>design-based</strong>?</h3>
<p>The key is that your derivation conditions on the <strong>randomization mechanism</strong> ‚Äî that is, the known process by which treatment is assigned.</p>
</section>
<section id="expectation-taken-over-assignment-mechanism" class="level3" data-number="6.2.3">
<h3 data-number="6.2.3" class="anchored" data-anchor-id="expectation-taken-over-assignment-mechanism"><span class="header-section-number">6.2.3</span> üîπ 1. Expectation taken over assignment mechanism</h3>
<p>You compute:</p>
<p><span class="math display">\[
\mathbb{E}\left[
\hat{\tau}^{\text{dm}} \mid \mathbf{n}, \mathbf{Y(w)}
\right]
\]</span></p>
<ul>
<li>The randomness here is over the <strong>assignment vector</strong> ( ) ‚Äî i.e., how units are assigned to treatment or control.</li>
<li>The potential outcomes ( ) are treated as <strong>fixed</strong> (non-random).</li>
<li>This reflects the design of the experiment: if we re-ran the randomization, we‚Äôd get a different estimate ( ^{} ), but the outcomes under treatment and control for each unit would remain the same.</li>
</ul>
<blockquote class="blockquote">
<p><strong>This is the hallmark of the design-based approach</strong>:<br>
It treats assignment as the source of randomness, and all other aspects (units, outcomes, covariates) as fixed.</p>
</blockquote>
<hr>
</section>
<section id="unbiasedness-is-shown-by-averaging-over-random-assignments" class="level3" data-number="6.2.4">
<h3 data-number="6.2.4" class="anchored" data-anchor-id="unbiasedness-is-shown-by-averaging-over-random-assignments"><span class="header-section-number">6.2.4</span> üîπ 2. Unbiasedness is shown by averaging over random assignments</h3>
<p>You show:</p>
<p><span class="math display">\[
\mathbb{E}[\hat{\tau}^{\text{dm}} \mid \mathbf{n}, \mathbf{Y(w)}] = \tau
\]</span></p>
<p>This tells us that: - The estimator is <strong>unbiased</strong> <em>because of how the assignment was randomized</em>, not because of any assumptions about functional forms, ignorability, or data-generating processes. - That is: <strong>randomization justifies the inference</strong>, not a model of selection or outcome behavior.</p>
<hr>
</section>
<section id="no-assumptions-about-ignorability-or-conditional-independence" class="level3" data-number="6.2.5">
<h3 data-number="6.2.5" class="anchored" data-anchor-id="no-assumptions-about-ignorability-or-conditional-independence"><span class="header-section-number">6.2.5</span> üîπ 3. No assumptions about ignorability or conditional independence</h3>
<p>You do <strong>not</strong> assume: - ( W_i (Y_i(0), Y_i(1)) X_i ) (as in observational methods), - or any structural model of selection or behavior.</p>
<p>Instead, your inference relies solely on the <strong>known randomization scheme</strong> ‚Äî e.g., Bernoulli or complete random assignment.</p>
<hr>
</section>
<section id="in-contrast-identification-based-observational-approach" class="level3" data-number="6.2.6">
<h3 data-number="6.2.6" class="anchored" data-anchor-id="in-contrast-identification-based-observational-approach"><span class="header-section-number">6.2.6</span> üß≠ In contrast: Identification-based (observational) approach</h3>
<ul>
<li>Takes the data as generated by an <strong>unknown, possibly non-random assignment</strong>.</li>
<li>Makes assumptions (e.g., unconfoundedness) to justify:</li>
</ul>
<p><span class="math display">\[
\mathbb{E}[Y_i(1) - Y_i(0)] = \mathbb{E}[Y_i \mid W_i = 1] - \mathbb{E}[Y_i \mid W_i = 0]
\]</span></p>
<ul>
<li>Assumes assignment is as good as random <strong>after controlling for covariates</strong>.</li>
</ul>
<hr>
</section>
<section id="summary" class="level3" data-number="6.2.7">
<h3 data-number="6.2.7" class="anchored" data-anchor-id="summary"><span class="header-section-number">6.2.7</span> üìå Summary</h3>
<blockquote class="blockquote">
<p>The approach in the main text is <strong>design-based</strong> because it: - Treats potential outcomes as fixed,<br>
- Takes expectations <strong>only over the random assignment</strong>,<br>
- Shows unbiasedness of the estimator purely from the <strong>known experimental design</strong>,<br>
- Requires <strong>no modeling of selection</strong>.</p>
</blockquote>
<p>This is fundamentally different from the identification-based approach, which models or assumes ignorability to equate observed and counterfactual outcomes.</p>
</section>
</section>
<section id="sampling" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="sampling"><span class="header-section-number">6.3</span> Sampling</h2>
<ul>
<li><p>We rely on a sample to learn about a larger population.</p></li>
<li><p>We thus need to make sure that the sampling procedure is free of bias, so that units in the sample are representative of those in the population.</p></li>
<li><p>While representativeness cannot be achieved perfectly, it‚Äôs important to ensure that non-representativeness is due to random error and not due to systematic bias.</p></li>
<li><p>Random errors produce deviations that vary over repeated samples, while systematic bias persists. Such selection bias can lead to misleading and ephemeral conclusions.</p></li>
<li><p>Sampling procedures:</p>
<ul>
<li>[[Simple random sampling]]</li>
<li>[[Completely random sampling]]</li>
<li>[[Stratified random sampling]]</li>
<li>Randomly select <span class="math inline">\(n_s\)</span> from each stratum <span class="math inline">\(S\)</span> of a population of <span class="math inline">\(N\)</span></li>
<li>On stratification: why does it reduce variance? Imagine an extreme case, where the number of strata were equal to the number of different units in the sample. In this case, the variance would be zero. Number of diff units here needs be individuals, but groups of units that share all relevant characteristics</li>
<li>The mean outcome of the sample is denoted <span class="math inline">\(\bar{x}\)</span>; that of the population, <span class="math inline">\(\mu\)</span>.</li>
</ul></li>
<li><p>Repeated sampling creates a [<a href="#sampling-distribution">Sampling distribution</a>]</p></li>
</ul>
</section>
<section id="selection-bias" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="selection-bias"><span class="header-section-number">6.4</span> Selection bias</h2>
<p>Common types of selection bias in data science: - The vast search effect (using the data to answer many questions will eventually reveal something interesting by mere chance ‚Äì if 20,000 people flip a coin 10 times, some will have 10 straight heads) - Nonrandom sampling - Cherry-picking data - Selecting specific time-intervals - Stopping experiments prematurely - Regression to the mean (occurs in settings where we measure outcomes repeatedly over time and where luck and skill combine to determine outcomes, since winners of one period will be less lucky next period and perform closer to the mean performer)</p>
<p>Ways to guard against selection bias: - have one or many holdout datasets to confirm your results.</p>
<section id="sampling-distribution" class="level3" data-number="6.4.1">
<h3 data-number="6.4.1" class="anchored" data-anchor-id="sampling-distribution"><span class="header-section-number">6.4.1</span> Sampling distribution</h3>
<ul>
<li><p>A sampling distribution is the distribution of a statistic (e.g.&nbsp;the mean) over many repeated samples. Classical statistics is much concerned with making inferences from samples about the population based on such statistics.</p></li>
<li><p>When we measure an attribute of the population based on a sample using a statistic, the result will vary over repeated samples. To capture by how much it varies, we are concerned with the sampling variability.</p></li>
<li><p>Key distinctions:</p>
<ul>
<li><p>The data distribution is the distribution of the data in the sample, and its spread is measured by the variance or its square root, the standard deviation.</p></li>
<li><p>The sampling distribution is the distribution of the sample statistic, and its spread is measured by the sampling variance or its square root, the standard error.</p></li>
</ul></li>
<li><p>Plots below show that:</p>
<ul>
<li>Data distribution has larger spread than sampling distributions (each data point is a special case of a sample with n = 1)</li>
<li>The spread of sampling distributions decreases with increasing sample size</li>
</ul></li>
</ul>
<pre><code>rng = np.random.default_rng(2312)


def means(data, sample_size, num_means=1000):
    return rng.choice(data, (sample_size, num_means)).mean(0)


# Create dataset with population and sample data
data = pd.DataFrame({"Population": rng.normal(size=1_000_000)})
for n in [10, 100, 1000]:
    data = data.join(
        pd.Series(means(data.Population, n), name=f"Means of samples of {n}")
    )
data = data.melt()


g = sns.FacetGrid(data, col="variable")
g.map(sns.histplot, "value", bins=40, stat="percent")
g.set_axis_labels("Value", "Count")
g.set_titles("{col_name}");</code></pre>
</section>
<section id="variance-and-standard-error" class="level3" data-number="6.4.2">
<h3 data-number="6.4.2" class="anchored" data-anchor-id="variance-and-standard-error"><span class="header-section-number">6.4.2</span> Variance and standard error</h3>
<ul>
<li><p>The standard error is a measure for the variability of the sampling distribution.</p></li>
<li><p>It is related to the standard deviation of the observations, <span class="math inline">\(\sigma\)</span> and the sample size <span class="math inline">\(n\)</span> in the following way:</p></li>
</ul>
<p><span class="math display">\[
se = \frac{\sigma}{\sqrt{n}}
\]</span> - The relationship between sample size and se is sometimes called the ‚ÄúSquare-root of n rule‚Äù, since reducing the <span class="math inline">\(se\)</span> by a factor of 2 requires an increase in the sample size by a factor of 4.</p>
<p>Derivation:</p>
<p>The sum of a sequence of independent random variables is: <span class="math display">\[
T = (x_1 + x_2 + ... + x_n)
\]</span></p>
<p>Which has variance</p>
<p><span class="math display">\[
Var(T) = Var(x_1) + Var(x_2) + ... + Var(x_n) = n\sigma^2
\]</span></p>
<p>and mean</p>
<p><span class="math display">\[
\bar{x} = T/n.
\]</span></p>
<p>The variance of <span class="math inline">\(\bar{x}\)</span> is then given by:</p>
<p><span class="math display">\[
Var(\bar{x}) = Var\left(\frac{T}{n}\right) = \frac{1}{n^2}Var(T) = \frac{1}{n^2}n\sigma^2 = \frac{\sigma^2}{n}.
\]</span></p>
<p>The standard error is defined as the standard deviation of <span class="math inline">\(\bar{x}\)</span>, and is thus</p>
<p><span class="math display">\[
se(\bar{x}) = \sqrt{Var(\bar{x})} = \frac{\sigma}{\sqrt{n}}.
\]</span></p>
</section>
<section id="example-code" class="level3" data-number="6.4.3">
<h3 data-number="6.4.3" class="anchored" data-anchor-id="example-code"><span class="header-section-number">6.4.3</span> Example code</h3>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(<span class="dv">2312</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> means(data, sample_size, num_means<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> rng.choice(data, (sample_size, num_means)).mean(<span class="dv">0</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create dataset with population and sample data</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({<span class="st">"Population"</span>: rng.normal(size<span class="op">=</span><span class="dv">1_000_000</span>)})</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> [<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>]:</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> data.join(</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        pd.Series(means(data.Population, n),</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        name<span class="op">=</span><span class="ss">f"Means of samples of </span><span class="sc">{</span>n<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.melt()</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.FacetGrid(data, col<span class="op">=</span><span class="st">"variable"</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>g.<span class="bu">map</span>(sns.histplot, <span class="st">"value"</span>, bins<span class="op">=</span><span class="dv">40</span>, stat<span class="op">=</span><span class="st">"percent"</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>g.set_axis_labels(<span class="st">"Value"</span>, <span class="st">"Count"</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>g.set_titles(<span class="st">"</span><span class="sc">{col_name}</span><span class="st">"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Figure shows that:</p>
<ul>
<li><p>The spread of sampling distributions decreases with increasing sample size</p></li>
<li><p>Data distribution has larger spread than sampling distributions (each data point is a special case of a sample with n = 1)</p></li>
</ul>
</section>
</section>
<section id="law-of-large-numbers-and-central-limit-theorems" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="law-of-large-numbers-and-central-limit-theorems"><span class="header-section-number">6.5</span> Law of large numbers and central limit theorems</h2>
<ul>
<li><p>Suppose that we have a sequence of independent and identically distributed (iid) random variables <span class="math inline">\(\{x_1, ..., x_n\}\)</span> drawn from a distribution with expected value <span class="math inline">\(\mu\)</span> and finite variance <span class="math inline">\(\sigma^2\)</span>, and we are interested in the mean value <span class="math inline">\(\bar{x} = \frac{x_1 + ... + x_n}{n}\)</span>.</p></li>
<li><p>The law or large numbers states that <span class="math inline">\(\bar{x}\)</span> converges to <span class="math inline">\(\mu\)</span> as we increase the sample size. Formally:</p></li>
</ul>
<p><span class="math display">\[
\bar{x} \rightarrow \mu \text{ as } n \rightarrow \infty.
\]</span></p>
<ul>
<li>The (classical, Lindeberg-L√©vy) central limit theorem describes the spread of the sampling distribution of <span class="math inline">\(\bar{x}\)</span> around <span class="math inline">\(\mu\)</span> during this convergence. In particular, it implies that for large enough <span class="math inline">\(n\)</span>, the distribution of <span class="math inline">\(\bar{x}\)</span> will be close to a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2/n\)</span>. The above figures are a visual representation of this. Formally:</li>
</ul>
<p><span class="math display">\[
\lim _{n\to\infty} \sqrt{n}(\bar{x} - \mu) \rightarrow \mathcal{N}\left(0,\sigma ^{2}\right).
\]</span></p>
<ul>
<li><p>This is useful because it means that irrespective of the underlying distribution (i.e.&nbsp;the distribution of the values in our sequence above), we can use the normal distribution and approximations to it (such as the t-distribution) to calculate sampling distributions when we do inference. Because of this, the CLT is at the heart of the theory of hypothesis testing and confidence intervals, and thus of much of classical statistics.</p></li>
<li><p>For experiments, this means that our estiamted treatment effect is normally distributed, which is what allows us to draw inferences from our experimental setting ot the population as a whole. The CLT is thus at the heart of the experimental approach.</p></li>
<li><p>The CLT also explains the prevalence of the normal distribution in the natural world. Many characteristics of living things we observe and measure are the sum of the additive effects of many genetic and environmental factors, so their distribution tends to be normal.</p></li>
</ul>
</section>
<section id="degrees-of-freedom" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="degrees-of-freedom"><span class="header-section-number">6.6</span> Degrees of freedom</h2>
<p>In statistics, degrees of freedom generally refers to the number of values in a calculation that can vary freely.</p>
<p>Examples:</p>
<ul>
<li><p>Variance calculation: given that we have a mean, once we know all but one value, we also know final value, since sum of mean deviations has to be zero.</p></li>
<li><p>Covariance calculation: given the two means, once we know the values for all but one x and y pair, we also know the values of the final pair. Hence, we loose one df (not clear to me why not two, given that both x and y are determined ‚Äì because we treat their product as a single value? but that seems arbitrary)</p></li>
<li><p>Also, why no correction when we have popultion means? See wikipedia article on variance for section on bias correction</p></li>
<li><p>There is lots of confusion out there when it comes to df. For instance, you sometimes hear people say that df is the number of parameters you had to calculate on route. But this is wrong. It happens to come to the same when calculating variance, but not if you calcualte covariance (where you calculate two means beforehand, but only loose one df).</p></li>
</ul>
</section>
<section id="the-bootstrap" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="the-bootstrap"><span class="header-section-number">6.7</span> The bootstrap</h2>
<ul>
<li><p>In practice, we often use the bootstrap to calculate standard errors of model parameters or statistics.</p></li>
<li><p>Conceptually, the bootstrap works as follows:</p></li>
</ul>
<ol type="1">
<li><p>we draw an original sample and calculate our statistic</p></li>
<li><p>we then create a blown-up version of that sample by duplicating it many times</p></li>
<li><p>we then draw repeated samples from the large sample, recalculate our statistic, and calculate the standard deviation of these statistics to get the standard error.</p></li>
</ol>
<ul>
<li><p>To achieve this easily, we can skip step 2) by simply sampling with replacement from the original distribution in step 3).</p></li>
<li><p>The full procedure makes clear what the bootstrap results tell us, however: they tell us how lots of additional samples would behave if they were drawn from a population like our original sample.</p></li>
<li><p>Hence, if the original sample is not representative of the population of interest, then bootstrap results are not informative about that population either.</p></li>
<li><p>The bootstrap can also be used to improve the performance of classification or regression trees by fitting multiple trees on bootstrapped sample and then averaging their predictions. This is called ‚Äúbagging‚Äù, short for ‚Äúbootstrap aggregating‚Äù.</p></li>
<li><p>We can use to boostrap also to calculate CIs following this algorithm:</p></li>
</ul>
<ol type="1">
<li><p>Draw a large number of bootstrap samples and calculate the statistic of interest</p></li>
<li><p>Trim [(100-x)/2] percent of the bootstrap results on either end of the distribution</p></li>
<li><p>The trim points are the end point of the CI.</p></li>
</ol>
<!-- ```{python}

from sklearn.utils import resample

  

rng = np.random.default_rng(2312)

  

population = rng.normal(3, 5, 1_000_000)

sample = rng.choice(population, 1000)

resample_means = pd.Series(resample(sample).mean() for _ in range(1000))

  

print(f"{'Population mean:':20} {np.mean(population):.3f}")

print(f"{'Sample mean:':20} {np.mean(sample):.3f}")

print(f"{'Bootstrap mean:':20} {np.mean(resample_means.mean()):.3f}")

print(f"{'Bootstrap se:':20} {np.mean(resample_means.std()):.3f}")

``` -->
</section>
<section id="combination-vs-permutation" class="level2" data-number="6.8">
<h2 data-number="6.8" class="anchored" data-anchor-id="combination-vs-permutation"><span class="header-section-number">6.8</span> Combination vs Permutation</h2>
<p><strong>Permutation (Order Matters)</strong></p>
<p>If we have <span class="math inline">\(n\)</span> items and we want to pick <span class="math inline">\(r\)</span> in a specific order, the formula is:</p>
<p><span class="math display">\[
P(n, r) = \frac{n!}{(n - r)!}
\]</span> Example: Arranging 3 letters (A, B, C) in 2 positions.<br>
- Possible orders: AB, AC, BA, BC, CA, CB ‚Üí 6 ways<br>
- Formula:<br>
<span class="math display">\[
  P(3,2) = \frac{3!}{(3 - 2)!} = \frac{3!}{1!} = \frac{3 \times 2 \times 1}{1} = 6
  \]</span></p>
<p><strong>Combination (Order Doesn‚Äôt Matter)</strong></p>
<p>If we have <span class="math inline">\(n\)</span> items and we want to pick <span class="math inline">\(r\)</span>, but order does not matter, the formula is:</p>
<p><span class="math display">\[
C(n, r) = \frac{n!}{r!(n - r)!}
\]</span></p>
<p>Example:</p>
<p>Choosing 2 letters from (A, B, C), where order does not matter.<br>
- Possible groups: {A, B}, {A, C}, {B, C} ‚Üí 3 ways<br>
- Formula:<br>
<span class="math display">\[
  C(3,2) = \frac{3!}{2!(3 - 2)!} = \frac{3!}{(2! \times 1!)} = \frac{3 \times 2 \times 1}{(2 \times 1) \times 1} = 3
  \]</span></p>
<p><strong>Key Difference:</strong> - <strong>Permutation:</strong> ABC and BAC are different<br>
- <strong>Combination:</strong> ABC and BAC are the same</p>
<p><strong>Shortcut:</strong><br>
<span class="math display">\[
P(n, r) = C(n, r) \times r!
\]</span><br>
(Since for every combination, there are <span class="math inline">\(r!\)</span> ways to arrange it.)</p>
</section>
<section id="moments-of-random-variables" class="level2" data-number="6.9">
<h2 data-number="6.9" class="anchored" data-anchor-id="moments-of-random-variables"><span class="header-section-number">6.9</span> Moments of random variables</h2>
<p>In general, the kth uncentered moment of a discrete random variable X is defined by</p>
<p><span class="math display">\[
E(X^k) = \sum_{i=1}^n p(x_i)x_i^k,
\]</span></p>
<p>and the kth centered moment as</p>
<p><span class="math display">\[
E\left(X-E(X)\right)^k = \sum_{i=1}^n p(x_i)(x_i - \mu)^k,
\]</span></p>
<p>Hence, the mean of a random variable is the first uncentered momement, and the variance is the second centered moment.</p>
</section>
<section id="variance-and-covariance-properties" class="level2" data-number="6.10">
<h2 data-number="6.10" class="anchored" data-anchor-id="variance-and-covariance-properties"><span class="header-section-number">6.10</span> Variance and covariance properties</h2>
<p>Building blocks for advanced manipulations.</p>
<p><span class="math display">\[
\begin{align}
Var(X + c) &amp;= Var(X) \\
Var(X + Y + c) &amp;= Var(X + Y)
\end{align}
\]</span></p>
<p>Add here covariance properties that show that</p>
<p>cov(X + a, Y + b) = cov(X ,Y)</p>
<p>$$ <span class="math display">\[\begin{align}
Cov(\bar{c}, \bar{d})

&amp;=\mathbb{E}\left[(\bar{c} - \mathbb{E}[\bar{c}])
(\bar{d} - \mathbb{E}[\bar{d}])\right]
&amp;\text{}
\\[5pt]

&amp;=\mathbb{E}\left[
\bar{c}\bar{d}
- \mathbb{E}[\bar{d}]\bar{c}
- \mathbb{E}[\bar{c}]\bar{d}
+ \mathbb{E}[\bar{c}]\mathbb{E}[\bar{d}]
\right]
&amp;\text{}
\\[5pt]

&amp;=
\mathbb{E}\left[\bar{c}\bar{d}\right]
- \mathbb{E}[\bar{d}]\mathbb{E}[\bar{c}]
- \mathbb{E}[\bar{c}]\mathbb{E}[\bar{d}]
+ \mathbb{E}[\bar{c}]\mathbb{E}[\bar{d}]
&amp;\text{}
\\[5pt]

&amp;=\mathbb{E}\left[\bar{c}\bar{d}\right] - \mathbb{E}[\bar{c}]\mathbb{E}[\bar{d}]
&amp;\text{}
\\[5pt]
\end{align}\]</span> $$</p>
<p>In general:</p>
<p><span class="math display">\[
\mathbb{E}[XY] = \mathbb{E}[X]\mathbb{E}[Y] + \text{Cov}(X, Y)
\]</span></p>
</section>
<section id="confidence-intervals" class="level2" data-number="6.11">
<h2 data-number="6.11" class="anchored" data-anchor-id="confidence-intervals"><span class="header-section-number">6.11</span> Confidence intervals</h2>
<ul>
<li><p>A CI is another way to learn about the variability of a test statistic.</p></li>
<li><p>It can be calculated using the (standard) normal distribution or the t-distribution (if sample sizes are small).</p></li>
<li><p>But for data science purposes we can compute an x-percent CI from the bootstrap, following this algorithm: 1) Draw a large number of bootstrap samples and calculate the statistic of interest, 2) Trim [(100-x)/2] percent of the bootstrap results on either end of the distribution, 3) the trim points are the end point of the CI.</p></li>
</ul>
</section>
<section id="commonly-used-distributions" class="level2" data-number="6.12">
<h2 data-number="6.12" class="anchored" data-anchor-id="commonly-used-distributions"><span class="header-section-number">6.12</span> Commonly used distributions</h2>
<p>from <a href="https://en.wikipedia.org/wiki/Variance">here</a></p>
<section id="commonly-used-probability-distributions" class="level3" data-number="6.12.1">
<h3 data-number="6.12.1" class="anchored" data-anchor-id="commonly-used-probability-distributions"><span class="header-section-number">6.12.1</span> Commonly used probability distributions</h3>
<p>The following table lists the variance for some commonly used probability distributions.</p>
<div class="line-block">Name of the probability distribution | Probability distribution function | Mean | Variance |</div>
<p>|‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äì|‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äì|‚Äî‚Äî|‚Äî‚Äî‚Äî-|</p>
<div class="line-block">Binomial distribution | <span class="math inline">\(\Pr\,(X=k) = \binom{n}{k}p^k(1 - p)^{n-k}\)</span> | <span class="math inline">\(np\)</span> | <span class="math inline">\(np(1 - p)\)</span> |</div>
<div class="line-block">Geometric distribution | <span class="math inline">\(\Pr\,(X=k) = (1 - p)^{k-1}p\)</span> | <span class="math inline">\(\frac{1}{p}\)</span> | <span class="math inline">\(\frac{1 - p}{p^2}\)</span> |</div>
<div class="line-block">Normal distribution | <span class="math inline">\(f(x \mid \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x - \mu)^2}{2\sigma^2}}\)</span> | <span class="math inline">\(\mu\)</span> | <span class="math inline">\(\sigma^2\)</span> |</div>
<div class="line-block">Uniform distribution (continuous) | <span class="math inline">\(f(x \mid a, b) = \begin{cases} \frac{1}{b - a} &amp; \text{for } a \le x \le b, \\[3pt] 0 &amp; \text{for } x &lt; a \text{ or } x &gt; b \end{cases}\)</span> | <span class="math inline">\(\frac{a + b}{2}\)</span> | <span class="math inline">\(\frac{(b - a)^2}{12}\)</span> |</div>
<div class="line-block">Exponential distribution | <span class="math inline">\(f(x \mid \lambda) = \lambda e^{-\lambda x}\)</span> | <span class="math inline">\(\frac{1}{\lambda}\)</span> | <span class="math inline">\(\frac{1}{\lambda^2}\)</span> |</div>
<div class="line-block">Poisson distribution | <span class="math inline">\(f(k \mid \lambda) = \frac{e^{-\lambda}\lambda^{k}}{k!}\)</span> | <span class="math inline">\(\lambda\)</span> | <span class="math inline">\(\lambda\)</span> |</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/lemmas.html" class="pagination-link" aria-label="Lemmas">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Lemmas</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->




</body></html>